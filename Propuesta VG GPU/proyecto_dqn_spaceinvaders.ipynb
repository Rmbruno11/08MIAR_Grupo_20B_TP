{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c82216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de TensorFlow: 2.10.0\n",
      "¿Soporte CUDA?: True\n",
      "¿GPU detectada?: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Versión de TensorFlow:\", tf.__version__)\n",
    "print(\"¿Soporte CUDA?:\", tf.test.is_built_with_cuda())\n",
    "print(\"¿GPU detectada?:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3861ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import ObservationWrapper\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092aeb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "ENV_NAME = 'SpaceInvaders-v0'\n",
    "\n",
    "# Wrapper para corregir salida de env.reset() en versiones recientes de Gym\n",
    "class GymV21ObservationWrapper(ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        if isinstance(obs, tuple):\n",
    "            return obs[0]\n",
    "        return obs\n",
    "\n",
    "# Crear entorno con wrapper y semilla\n",
    "env = GymV21ObservationWrapper(gym.make(ENV_NAME))\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69258c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        # ✅ Desempaquetar si observation es una tupla\n",
    "        if isinstance(observation, tuple):\n",
    "            observation = observation[0]\n",
    "\n",
    "        assert observation.ndim == 3  # (H, W, C)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')  # Escala de grises\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        return batch.astype('float32') / 255.\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cf5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Definición de la red neuronal\n",
    "def build_model(nb_actions):\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 3, 1), input_shape=(WINDOW_LENGTH,) + INPUT_SHAPE))\n",
    "    model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu'))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(nb_actions, activation='linear'))\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3114a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " permute (Permute)           (None, 84, 84, 4)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,687,206\n",
      "Trainable params: 1,687,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#%% Inicialización de modelo y agente DQN\n",
    "model = build_model(nb_actions)\n",
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
    "                              value_max=1.0, value_min=0.1, value_test=0.05,\n",
    "                              nb_steps=1000000)\n",
    "\n",
    "processor = AtariProcessor()\n",
    "\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy,\n",
    "               memory=memory, processor=processor,\n",
    "               nb_steps_warmup=50000, gamma=0.99,\n",
    "               target_model_update=10000, train_interval=4,\n",
    "               delta_clip=1.0)\n",
    "\n",
    "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5395dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Configuración de callbacks\n",
    "weights_filename = f'dqn_{ENV_NAME}_weights.h5f'\n",
    "checkpoint_weights_filename = f'dqn_{ENV_NAME}_weights_step_{{step}}.h5f'\n",
    "log_filename = f'dqn_{ENV_NAME}_log.json'\n",
    "\n",
    "callbacks = [\n",
    "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
    "    FileLogger(log_filename, interval=100)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5725619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 500000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\anaconda3\\envs\\dqn_gpu\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    420/500000: episode: 1, duration: 2.129s, episode steps: 420, steps per second: 197, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   1131/500000: episode: 2, duration: 2.007s, episode steps: 711, steps per second: 354, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   1941/500000: episode: 3, duration: 2.333s, episode steps: 810, steps per second: 347, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   2827/500000: episode: 4, duration: 3.358s, episode steps: 886, steps per second: 264, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   3345/500000: episode: 5, duration: 2.380s, episode steps: 518, steps per second: 218, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   3990/500000: episode: 6, duration: 2.695s, episode steps: 645, steps per second: 239, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   4451/500000: episode: 7, duration: 1.974s, episode steps: 461, steps per second: 234, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   5248/500000: episode: 8, duration: 3.382s, episode steps: 797, steps per second: 236, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   5733/500000: episode: 9, duration: 2.016s, episode steps: 485, steps per second: 241, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   6372/500000: episode: 10, duration: 2.654s, episode steps: 639, steps per second: 241, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   7096/500000: episode: 11, duration: 3.091s, episode steps: 724, steps per second: 234, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   7701/500000: episode: 12, duration: 2.742s, episode steps: 605, steps per second: 221, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   8349/500000: episode: 13, duration: 2.876s, episode steps: 648, steps per second: 225, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   9241/500000: episode: 14, duration: 3.891s, episode steps: 892, steps per second: 229, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   9696/500000: episode: 15, duration: 2.020s, episode steps: 455, steps per second: 225, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  10587/500000: episode: 16, duration: 3.322s, episode steps: 891, steps per second: 268, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  11110/500000: episode: 17, duration: 1.740s, episode steps: 523, steps per second: 301, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  11885/500000: episode: 18, duration: 2.673s, episode steps: 775, steps per second: 290, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  12744/500000: episode: 19, duration: 3.303s, episode steps: 859, steps per second: 260, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  13376/500000: episode: 20, duration: 2.734s, episode steps: 632, steps per second: 231, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  14142/500000: episode: 21, duration: 3.370s, episode steps: 766, steps per second: 227, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  14772/500000: episode: 22, duration: 3.030s, episode steps: 630, steps per second: 208, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  15488/500000: episode: 23, duration: 3.331s, episode steps: 716, steps per second: 215, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  15905/500000: episode: 24, duration: 1.952s, episode steps: 417, steps per second: 214, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  16580/500000: episode: 25, duration: 3.004s, episode steps: 675, steps per second: 225, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  17242/500000: episode: 26, duration: 2.937s, episode steps: 662, steps per second: 225, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  17821/500000: episode: 27, duration: 2.585s, episode steps: 579, steps per second: 224, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  18591/500000: episode: 28, duration: 3.313s, episode steps: 770, steps per second: 232, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  19308/500000: episode: 29, duration: 3.229s, episode steps: 717, steps per second: 222, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  20356/500000: episode: 30, duration: 4.915s, episode steps: 1048, steps per second: 213, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  21513/500000: episode: 31, duration: 4.177s, episode steps: 1157, steps per second: 277, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  21911/500000: episode: 32, duration: 1.187s, episode steps: 398, steps per second: 335, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  22289/500000: episode: 33, duration: 1.133s, episode steps: 378, steps per second: 334, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  22988/500000: episode: 34, duration: 2.114s, episode steps: 699, steps per second: 331, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  23743/500000: episode: 35, duration: 2.949s, episode steps: 755, steps per second: 256, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  24277/500000: episode: 36, duration: 2.308s, episode steps: 534, steps per second: 231, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  24781/500000: episode: 37, duration: 2.246s, episode steps: 504, steps per second: 224, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  25433/500000: episode: 38, duration: 2.899s, episode steps: 652, steps per second: 225, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  25855/500000: episode: 39, duration: 1.837s, episode steps: 422, steps per second: 230, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  26265/500000: episode: 40, duration: 1.788s, episode steps: 410, steps per second: 229, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  27181/500000: episode: 41, duration: 4.028s, episode steps: 916, steps per second: 227, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  27600/500000: episode: 42, duration: 1.826s, episode steps: 419, steps per second: 229, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  28323/500000: episode: 43, duration: 3.125s, episode steps: 723, steps per second: 231, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  28847/500000: episode: 44, duration: 2.387s, episode steps: 524, steps per second: 220, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  29490/500000: episode: 45, duration: 2.923s, episode steps: 643, steps per second: 220, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  29884/500000: episode: 46, duration: 1.733s, episode steps: 394, steps per second: 227, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  30710/500000: episode: 47, duration: 3.595s, episode steps: 826, steps per second: 230, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  31374/500000: episode: 48, duration: 2.883s, episode steps: 664, steps per second: 230, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  31967/500000: episode: 49, duration: 2.844s, episode steps: 593, steps per second: 208, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  33001/500000: episode: 50, duration: 4.691s, episode steps: 1034, steps per second: 220, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  33786/500000: episode: 51, duration: 3.582s, episode steps: 785, steps per second: 219, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  34187/500000: episode: 52, duration: 1.813s, episode steps: 401, steps per second: 221, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  34935/500000: episode: 53, duration: 3.329s, episode steps: 748, steps per second: 225, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  35510/500000: episode: 54, duration: 2.600s, episode steps: 575, steps per second: 221, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  36128/500000: episode: 55, duration: 2.703s, episode steps: 618, steps per second: 229, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  36644/500000: episode: 56, duration: 2.185s, episode steps: 516, steps per second: 236, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  37452/500000: episode: 57, duration: 3.432s, episode steps: 808, steps per second: 235, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  38114/500000: episode: 58, duration: 2.803s, episode steps: 662, steps per second: 236, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  38930/500000: episode: 59, duration: 3.407s, episode steps: 816, steps per second: 240, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  39471/500000: episode: 60, duration: 2.289s, episode steps: 541, steps per second: 236, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  40929/500000: episode: 61, duration: 6.139s, episode steps: 1458, steps per second: 237, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  41856/500000: episode: 62, duration: 3.963s, episode steps: 927, steps per second: 234, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  42465/500000: episode: 63, duration: 2.777s, episode steps: 609, steps per second: 219, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  43137/500000: episode: 64, duration: 3.319s, episode steps: 672, steps per second: 202, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  44068/500000: episode: 65, duration: 4.354s, episode steps: 931, steps per second: 214, episode reward: 26.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  45029/500000: episode: 66, duration: 4.380s, episode steps: 961, steps per second: 219, episode reward: 10.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  45733/500000: episode: 67, duration: 3.183s, episode steps: 704, steps per second: 221, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  46784/500000: episode: 68, duration: 4.591s, episode steps: 1051, steps per second: 229, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  47775/500000: episode: 69, duration: 4.149s, episode steps: 991, steps per second: 239, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  48645/500000: episode: 70, duration: 3.721s, episode steps: 870, steps per second: 234, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  49057/500000: episode: 71, duration: 1.903s, episode steps: 412, steps per second: 216, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  49596/500000: episode: 72, duration: 2.417s, episode steps: 539, steps per second: 223, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\anaconda3\\envs\\dqn_gpu\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50138/500000: episode: 73, duration: 18.012s, episode steps: 542, steps per second:  30, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.009444, mae: 0.038396, mean_q: 0.072628, mean_eps: 0.954937\n",
      "  50517/500000: episode: 74, duration: 9.565s, episode steps: 379, steps per second:  40, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.004285, mae: 0.034846, mean_q: 0.052399, mean_eps: 0.954705\n",
      "  51155/500000: episode: 75, duration: 16.065s, episode steps: 638, steps per second:  40, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.008045, mae: 0.039779, mean_q: 0.056710, mean_eps: 0.954248\n",
      "  52111/500000: episode: 76, duration: 24.374s, episode steps: 956, steps per second:  39, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006749, mae: 0.039748, mean_q: 0.053251, mean_eps: 0.953531\n",
      "  53152/500000: episode: 77, duration: 27.360s, episode steps: 1041, steps per second:  38, episode reward: 10.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006195, mae: 0.038204, mean_q: 0.052277, mean_eps: 0.952633\n",
      "  54284/500000: episode: 78, duration: 28.832s, episode steps: 1132, steps per second:  39, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.006396, mae: 0.039287, mean_q: 0.054101, mean_eps: 0.951656\n",
      "  54797/500000: episode: 79, duration: 12.860s, episode steps: 513, steps per second:  40, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.007400, mae: 0.042095, mean_q: 0.056757, mean_eps: 0.950914\n",
      "  55192/500000: episode: 80, duration: 9.882s, episode steps: 395, steps per second:  40, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.005978, mae: 0.038405, mean_q: 0.048679, mean_eps: 0.950505\n",
      "  55671/500000: episode: 81, duration: 12.038s, episode steps: 479, steps per second:  40, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.008590, mae: 0.043892, mean_q: 0.057163, mean_eps: 0.950113\n",
      "  56320/500000: episode: 82, duration: 16.362s, episode steps: 649, steps per second:  40, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.007888, mae: 0.041723, mean_q: 0.053276, mean_eps: 0.949605\n",
      "  57154/500000: episode: 83, duration: 21.334s, episode steps: 834, steps per second:  39, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.006618, mae: 0.040236, mean_q: 0.054211, mean_eps: 0.948938\n",
      "  57921/500000: episode: 84, duration: 19.390s, episode steps: 767, steps per second:  40, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.007808, mae: 0.042775, mean_q: 0.054271, mean_eps: 0.948216\n",
      "  58682/500000: episode: 85, duration: 19.110s, episode steps: 761, steps per second:  40, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.005947, mae: 0.039625, mean_q: 0.052272, mean_eps: 0.947528\n",
      "  59747/500000: episode: 86, duration: 26.880s, episode steps: 1065, steps per second:  40, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.007569, mae: 0.041722, mean_q: 0.053450, mean_eps: 0.946707\n",
      "  60280/500000: episode: 87, duration: 13.679s, episode steps: 533, steps per second:  39, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.006969, mae: 0.045029, mean_q: 0.056739, mean_eps: 0.945989\n",
      "  61016/500000: episode: 88, duration: 18.590s, episode steps: 736, steps per second:  40, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.005453, mae: 0.051529, mean_q: 0.067639, mean_eps: 0.945419\n",
      "  61925/500000: episode: 89, duration: 22.956s, episode steps: 909, steps per second:  40, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.007762, mae: 0.055601, mean_q: 0.069525, mean_eps: 0.944677\n",
      "  62840/500000: episode: 90, duration: 22.952s, episode steps: 915, steps per second:  40, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.006879, mae: 0.055751, mean_q: 0.070752, mean_eps: 0.943856\n",
      "  63275/500000: episode: 91, duration: 11.003s, episode steps: 435, steps per second:  40, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.005800, mae: 0.052100, mean_q: 0.064520, mean_eps: 0.943250\n",
      "  64074/500000: episode: 92, duration: 20.167s, episode steps: 799, steps per second:  40, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.006609, mae: 0.054704, mean_q: 0.070390, mean_eps: 0.942693\n",
      "  65315/500000: episode: 93, duration: 31.132s, episode steps: 1241, steps per second:  40, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006208, mae: 0.053196, mean_q: 0.068203, mean_eps: 0.941775\n",
      "  65960/500000: episode: 94, duration: 16.344s, episode steps: 645, steps per second:  39, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.007970, mae: 0.058329, mean_q: 0.072059, mean_eps: 0.940928\n",
      "  66807/500000: episode: 95, duration: 21.552s, episode steps: 847, steps per second:  39, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.005877, mae: 0.052982, mean_q: 0.068100, mean_eps: 0.940256\n",
      "  67364/500000: episode: 96, duration: 14.411s, episode steps: 557, steps per second:  39, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007163, mae: 0.054753, mean_q: 0.069068, mean_eps: 0.939624\n",
      "  67764/500000: episode: 97, duration: 10.261s, episode steps: 400, steps per second:  39, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.006278, mae: 0.053792, mean_q: 0.071625, mean_eps: 0.939194\n",
      "  68152/500000: episode: 98, duration: 10.169s, episode steps: 388, steps per second:  38, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.007248, mae: 0.054874, mean_q: 0.068600, mean_eps: 0.938840\n",
      "  68739/500000: episode: 99, duration: 15.473s, episode steps: 587, steps per second:  38, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.007701, mae: 0.057390, mean_q: 0.072597, mean_eps: 0.938400\n",
      "  69768/500000: episode: 100, duration: 26.671s, episode steps: 1029, steps per second:  39, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.006446, mae: 0.053421, mean_q: 0.067730, mean_eps: 0.937673\n",
      "  70284/500000: episode: 101, duration: 13.341s, episode steps: 516, steps per second:  39, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.006630, mae: 0.064313, mean_q: 0.083374, mean_eps: 0.936978\n",
      "  70629/500000: episode: 102, duration: 8.990s, episode steps: 345, steps per second:  38, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.006207, mae: 0.075673, mean_q: 0.098980, mean_eps: 0.936590\n",
      "  71178/500000: episode: 103, duration: 14.058s, episode steps: 549, steps per second:  39, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.007408, mae: 0.077127, mean_q: 0.098397, mean_eps: 0.936186\n",
      "  71601/500000: episode: 104, duration: 10.670s, episode steps: 423, steps per second:  40, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.005869, mae: 0.074449, mean_q: 0.093707, mean_eps: 0.935749\n",
      "  72060/500000: episode: 105, duration: 11.702s, episode steps: 459, steps per second:  39, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.006367, mae: 0.075229, mean_q: 0.096244, mean_eps: 0.935353\n",
      "  72793/500000: episode: 106, duration: 18.434s, episode steps: 733, steps per second:  40, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.005789, mae: 0.075572, mean_q: 0.095757, mean_eps: 0.934817\n",
      "  73538/500000: episode: 107, duration: 18.875s, episode steps: 745, steps per second:  39, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.006446, mae: 0.076113, mean_q: 0.095633, mean_eps: 0.934151\n",
      "  74186/500000: episode: 108, duration: 16.301s, episode steps: 648, steps per second:  40, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007838, mae: 0.079233, mean_q: 0.098533, mean_eps: 0.933524\n",
      "  74574/500000: episode: 109, duration: 9.884s, episode steps: 388, steps per second:  39, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.006384, mae: 0.077142, mean_q: 0.098472, mean_eps: 0.933058\n",
      "  75421/500000: episode: 110, duration: 21.477s, episode steps: 847, steps per second:  39, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.007328, mae: 0.077661, mean_q: 0.097970, mean_eps: 0.932502\n",
      "  76104/500000: episode: 111, duration: 17.560s, episode steps: 683, steps per second:  39, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006643, mae: 0.077668, mean_q: 0.099603, mean_eps: 0.931814\n",
      "  76777/500000: episode: 112, duration: 17.229s, episode steps: 673, steps per second:  39, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.006868, mae: 0.077190, mean_q: 0.095928, mean_eps: 0.931204\n",
      "  77474/500000: episode: 113, duration: 17.409s, episode steps: 697, steps per second:  40, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.007842, mae: 0.078883, mean_q: 0.100166, mean_eps: 0.930587\n",
      "  78337/500000: episode: 114, duration: 21.923s, episode steps: 863, steps per second:  39, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.005933, mae: 0.076236, mean_q: 0.095663, mean_eps: 0.929885\n",
      "  78970/500000: episode: 115, duration: 15.926s, episode steps: 633, steps per second:  40, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.006345, mae: 0.076574, mean_q: 0.099436, mean_eps: 0.929211\n",
      "  79350/500000: episode: 116, duration: 9.733s, episode steps: 380, steps per second:  39, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.008023, mae: 0.080828, mean_q: 0.100916, mean_eps: 0.928756\n",
      "  79946/500000: episode: 117, duration: 15.084s, episode steps: 596, steps per second:  40, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006207, mae: 0.075800, mean_q: 0.096273, mean_eps: 0.928317\n",
      "  80728/500000: episode: 118, duration: 20.822s, episode steps: 782, steps per second:  38, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.006262, mae: 0.096822, mean_q: 0.122563, mean_eps: 0.927698\n",
      "  81487/500000: episode: 119, duration: 20.811s, episode steps: 759, steps per second:  36, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.005859, mae: 0.097630, mean_q: 0.124952, mean_eps: 0.927005\n",
      "  82012/500000: episode: 120, duration: 13.684s, episode steps: 525, steps per second:  38, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006945, mae: 0.099662, mean_q: 0.126437, mean_eps: 0.926427\n",
      "  82567/500000: episode: 121, duration: 14.555s, episode steps: 555, steps per second:  38, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.006418, mae: 0.100376, mean_q: 0.127775, mean_eps: 0.925941\n",
      "  83197/500000: episode: 122, duration: 16.120s, episode steps: 630, steps per second:  39, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.005575, mae: 0.096350, mean_q: 0.121134, mean_eps: 0.925406\n",
      "  83864/500000: episode: 123, duration: 17.489s, episode steps: 667, steps per second:  38, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006278, mae: 0.100146, mean_q: 0.125283, mean_eps: 0.924823\n",
      "  84418/500000: episode: 124, duration: 14.162s, episode steps: 554, steps per second:  39, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.006596, mae: 0.100318, mean_q: 0.126978, mean_eps: 0.924274\n",
      "  85094/500000: episode: 125, duration: 17.652s, episode steps: 676, steps per second:  38, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.006559, mae: 0.101208, mean_q: 0.128314, mean_eps: 0.923720\n",
      "  85486/500000: episode: 126, duration: 10.049s, episode steps: 392, steps per second:  39, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006079, mae: 0.099105, mean_q: 0.123723, mean_eps: 0.923239\n",
      "  86093/500000: episode: 127, duration: 15.901s, episode steps: 607, steps per second:  38, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006118, mae: 0.099624, mean_q: 0.124368, mean_eps: 0.922789\n",
      "  86612/500000: episode: 128, duration: 13.256s, episode steps: 519, steps per second:  39, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.006184, mae: 0.100544, mean_q: 0.125368, mean_eps: 0.922283\n",
      "  87542/500000: episode: 129, duration: 22.953s, episode steps: 930, steps per second:  41, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.006446, mae: 0.099584, mean_q: 0.125523, mean_eps: 0.921632\n",
      "  88365/500000: episode: 130, duration: 21.460s, episode steps: 823, steps per second:  38, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.006800, mae: 0.100932, mean_q: 0.126324, mean_eps: 0.920841\n",
      "  88818/500000: episode: 131, duration: 11.684s, episode steps: 453, steps per second:  39, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.007047, mae: 0.103941, mean_q: 0.130258, mean_eps: 0.920267\n",
      "  89391/500000: episode: 132, duration: 14.949s, episode steps: 573, steps per second:  38, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.006271, mae: 0.098911, mean_q: 0.124497, mean_eps: 0.919806\n",
      "  89951/500000: episode: 133, duration: 14.646s, episode steps: 560, steps per second:  38, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.005749, mae: 0.098579, mean_q: 0.121873, mean_eps: 0.919297\n",
      "  90499/500000: episode: 134, duration: 14.341s, episode steps: 548, steps per second:  38, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.007283, mae: 0.115434, mean_q: 0.142762, mean_eps: 0.918798\n",
      "  91297/500000: episode: 135, duration: 20.830s, episode steps: 798, steps per second:  38, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.005591, mae: 0.114191, mean_q: 0.142221, mean_eps: 0.918192\n",
      "  91920/500000: episode: 136, duration: 16.661s, episode steps: 623, steps per second:  37, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.006806, mae: 0.118560, mean_q: 0.149055, mean_eps: 0.917553\n",
      "  92554/500000: episode: 137, duration: 16.353s, episode steps: 634, steps per second:  39, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.006843, mae: 0.117721, mean_q: 0.147230, mean_eps: 0.916988\n",
      "  93341/500000: episode: 138, duration: 20.401s, episode steps: 787, steps per second:  39, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.005902, mae: 0.116675, mean_q: 0.146565, mean_eps: 0.916347\n",
      "  94528/500000: episode: 139, duration: 30.410s, episode steps: 1187, steps per second:  39, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.005698, mae: 0.115223, mean_q: 0.145350, mean_eps: 0.915459\n",
      "  95498/500000: episode: 140, duration: 25.264s, episode steps: 970, steps per second:  38, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.007230, mae: 0.118864, mean_q: 0.149711, mean_eps: 0.914489\n",
      "  96261/500000: episode: 141, duration: 19.577s, episode steps: 763, steps per second:  39, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.006383, mae: 0.116515, mean_q: 0.146217, mean_eps: 0.913708\n",
      "  96879/500000: episode: 142, duration: 15.873s, episode steps: 618, steps per second:  39, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.006438, mae: 0.117493, mean_q: 0.146906, mean_eps: 0.913087\n",
      "  98019/500000: episode: 143, duration: 29.043s, episode steps: 1140, steps per second:  39, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.005936, mae: 0.116572, mean_q: 0.146921, mean_eps: 0.912297\n",
      "  98794/500000: episode: 144, duration: 20.456s, episode steps: 775, steps per second:  38, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.007341, mae: 0.119697, mean_q: 0.152269, mean_eps: 0.911435\n",
      "  99319/500000: episode: 145, duration: 13.365s, episode steps: 525, steps per second:  39, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.007086, mae: 0.117806, mean_q: 0.145901, mean_eps: 0.910850\n",
      "  99784/500000: episode: 146, duration: 11.764s, episode steps: 465, steps per second:  40, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.005881, mae: 0.114486, mean_q: 0.143435, mean_eps: 0.910405\n",
      " 100410/500000: episode: 147, duration: 15.946s, episode steps: 626, steps per second:  39, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.006250, mae: 0.133064, mean_q: 0.168232, mean_eps: 0.909914\n",
      " 101170/500000: episode: 148, duration: 19.274s, episode steps: 760, steps per second:  39, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.006332, mae: 0.142682, mean_q: 0.180007, mean_eps: 0.909289\n",
      " 101949/500000: episode: 149, duration: 19.789s, episode steps: 779, steps per second:  39, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.006826, mae: 0.143577, mean_q: 0.181202, mean_eps: 0.908596\n",
      " 102335/500000: episode: 150, duration: 10.249s, episode steps: 386, steps per second:  38, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.006705, mae: 0.145453, mean_q: 0.185920, mean_eps: 0.908072\n",
      " 103001/500000: episode: 151, duration: 16.939s, episode steps: 666, steps per second:  39, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.006045, mae: 0.142886, mean_q: 0.181040, mean_eps: 0.907599\n",
      " 103569/500000: episode: 152, duration: 14.626s, episode steps: 568, steps per second:  39, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.801 [0.000, 5.000],  loss: 0.005728, mae: 0.139863, mean_q: 0.176709, mean_eps: 0.907043\n",
      " 104096/500000: episode: 153, duration: 13.280s, episode steps: 527, steps per second:  40, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006145, mae: 0.144188, mean_q: 0.182809, mean_eps: 0.906551\n",
      " 104491/500000: episode: 154, duration: 9.950s, episode steps: 395, steps per second:  40, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.007592, mae: 0.146328, mean_q: 0.181504, mean_eps: 0.906137\n",
      " 105129/500000: episode: 155, duration: 16.187s, episode steps: 638, steps per second:  39, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.007054, mae: 0.142555, mean_q: 0.176326, mean_eps: 0.905671\n",
      " 105814/500000: episode: 156, duration: 17.304s, episode steps: 685, steps per second:  40, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.006649, mae: 0.142703, mean_q: 0.177556, mean_eps: 0.905075\n",
      " 106241/500000: episode: 157, duration: 10.867s, episode steps: 427, steps per second:  39, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.007208, mae: 0.146791, mean_q: 0.184357, mean_eps: 0.904575\n",
      " 107119/500000: episode: 158, duration: 22.638s, episode steps: 878, steps per second:  39, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.006668, mae: 0.145343, mean_q: 0.180971, mean_eps: 0.903988\n",
      " 107749/500000: episode: 159, duration: 16.992s, episode steps: 630, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006790, mae: 0.146084, mean_q: 0.181307, mean_eps: 0.903309\n",
      " 108347/500000: episode: 160, duration: 15.420s, episode steps: 598, steps per second:  39, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.006821, mae: 0.143290, mean_q: 0.178319, mean_eps: 0.902757\n",
      " 109161/500000: episode: 161, duration: 21.965s, episode steps: 814, steps per second:  37, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.006126, mae: 0.142083, mean_q: 0.178855, mean_eps: 0.902121\n",
      " 109953/500000: episode: 162, duration: 19.980s, episode steps: 792, steps per second:  40, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.007679, mae: 0.146866, mean_q: 0.183609, mean_eps: 0.901398\n",
      " 110665/500000: episode: 163, duration: 18.646s, episode steps: 712, steps per second:  38, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.007312, mae: 0.167387, mean_q: 0.208351, mean_eps: 0.900721\n",
      " 111657/500000: episode: 164, duration: 26.133s, episode steps: 992, steps per second:  38, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.007124, mae: 0.169673, mean_q: 0.211292, mean_eps: 0.899954\n",
      " 112950/500000: episode: 165, duration: 32.753s, episode steps: 1293, steps per second:  39, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.006391, mae: 0.169311, mean_q: 0.210968, mean_eps: 0.898926\n",
      " 113687/500000: episode: 166, duration: 18.536s, episode steps: 737, steps per second:  40, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.006373, mae: 0.168229, mean_q: 0.208629, mean_eps: 0.898014\n",
      " 114175/500000: episode: 167, duration: 12.491s, episode steps: 488, steps per second:  39, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.006561, mae: 0.168559, mean_q: 0.208670, mean_eps: 0.897463\n",
      " 115385/500000: episode: 168, duration: 30.947s, episode steps: 1210, steps per second:  39, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.005969, mae: 0.170066, mean_q: 0.211085, mean_eps: 0.896698\n",
      " 115906/500000: episode: 169, duration: 13.628s, episode steps: 521, steps per second:  38, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.005587, mae: 0.165462, mean_q: 0.207064, mean_eps: 0.895919\n",
      " 116613/500000: episode: 170, duration: 18.700s, episode steps: 707, steps per second:  38, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.005627, mae: 0.166981, mean_q: 0.208292, mean_eps: 0.895366\n",
      " 117421/500000: episode: 171, duration: 20.656s, episode steps: 808, steps per second:  39, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.006974, mae: 0.169777, mean_q: 0.208838, mean_eps: 0.894684\n",
      " 118030/500000: episode: 172, duration: 16.022s, episode steps: 609, steps per second:  38, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.006583, mae: 0.167863, mean_q: 0.210769, mean_eps: 0.894047\n",
      " 118679/500000: episode: 173, duration: 17.226s, episode steps: 649, steps per second:  38, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.006317, mae: 0.168040, mean_q: 0.209341, mean_eps: 0.893481\n",
      " 119288/500000: episode: 174, duration: 15.962s, episode steps: 609, steps per second:  38, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.005594, mae: 0.167617, mean_q: 0.208030, mean_eps: 0.892916\n",
      " 120239/500000: episode: 175, duration: 24.584s, episode steps: 951, steps per second:  39, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.006430, mae: 0.172043, mean_q: 0.213225, mean_eps: 0.892214\n",
      " 121209/500000: episode: 176, duration: 25.147s, episode steps: 970, steps per second:  39, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.006681, mae: 0.177990, mean_q: 0.219747, mean_eps: 0.891348\n",
      " 121756/500000: episode: 177, duration: 14.215s, episode steps: 547, steps per second:  38, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006156, mae: 0.179565, mean_q: 0.222297, mean_eps: 0.890666\n",
      " 122564/500000: episode: 178, duration: 21.158s, episode steps: 808, steps per second:  38, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007155, mae: 0.181793, mean_q: 0.226338, mean_eps: 0.890058\n",
      " 123195/500000: episode: 179, duration: 16.292s, episode steps: 631, steps per second:  39, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.006489, mae: 0.179102, mean_q: 0.222376, mean_eps: 0.889410\n",
      " 123934/500000: episode: 180, duration: 19.390s, episode steps: 739, steps per second:  38, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.007086, mae: 0.180130, mean_q: 0.223587, mean_eps: 0.888792\n",
      " 124943/500000: episode: 181, duration: 26.285s, episode steps: 1009, steps per second:  38, episode reward: 10.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.005997, mae: 0.177404, mean_q: 0.220637, mean_eps: 0.888006\n",
      " 125886/500000: episode: 182, duration: 24.353s, episode steps: 943, steps per second:  39, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006399, mae: 0.179468, mean_q: 0.222249, mean_eps: 0.887127\n",
      " 126399/500000: episode: 183, duration: 13.278s, episode steps: 513, steps per second:  39, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.005204, mae: 0.174522, mean_q: 0.216999, mean_eps: 0.886472\n",
      " 126898/500000: episode: 184, duration: 12.815s, episode steps: 499, steps per second:  39, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.006173, mae: 0.178057, mean_q: 0.220764, mean_eps: 0.886017\n",
      " 127537/500000: episode: 185, duration: 16.631s, episode steps: 639, steps per second:  38, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.007460, mae: 0.181019, mean_q: 0.223933, mean_eps: 0.885504\n",
      " 128017/500000: episode: 186, duration: 12.414s, episode steps: 480, steps per second:  39, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.006771, mae: 0.179073, mean_q: 0.221692, mean_eps: 0.885000\n",
      " 129111/500000: episode: 187, duration: 28.693s, episode steps: 1094, steps per second:  38, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.005453, mae: 0.176386, mean_q: 0.218622, mean_eps: 0.884292\n",
      " 129987/500000: episode: 188, duration: 22.831s, episode steps: 876, steps per second:  38, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.005985, mae: 0.177061, mean_q: 0.219051, mean_eps: 0.883407\n",
      " 130484/500000: episode: 189, duration: 12.736s, episode steps: 497, steps per second:  39, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: 0.009325, mae: 0.211333, mean_q: 0.261325, mean_eps: 0.882789\n",
      " 131771/500000: episode: 190, duration: 32.634s, episode steps: 1287, steps per second:  39, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006607, mae: 0.205291, mean_q: 0.254708, mean_eps: 0.881987\n",
      " 132718/500000: episode: 191, duration: 23.940s, episode steps: 947, steps per second:  40, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.006795, mae: 0.204862, mean_q: 0.253987, mean_eps: 0.880980\n",
      " 133113/500000: episode: 192, duration: 10.151s, episode steps: 395, steps per second:  39, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006735, mae: 0.206674, mean_q: 0.258379, mean_eps: 0.880376\n",
      " 133854/500000: episode: 193, duration: 18.993s, episode steps: 741, steps per second:  39, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.005646, mae: 0.201055, mean_q: 0.249462, mean_eps: 0.879864\n",
      " 134454/500000: episode: 194, duration: 15.898s, episode steps: 600, steps per second:  38, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007263, mae: 0.207356, mean_q: 0.254976, mean_eps: 0.879261\n",
      " 135541/500000: episode: 195, duration: 28.221s, episode steps: 1087, steps per second:  39, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.006601, mae: 0.205829, mean_q: 0.253891, mean_eps: 0.878502\n",
      " 136181/500000: episode: 196, duration: 16.341s, episode steps: 640, steps per second:  39, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.005637, mae: 0.204687, mean_q: 0.252377, mean_eps: 0.877724\n",
      " 136668/500000: episode: 197, duration: 12.472s, episode steps: 487, steps per second:  39, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007309, mae: 0.207560, mean_q: 0.254204, mean_eps: 0.877218\n",
      " 137283/500000: episode: 198, duration: 15.561s, episode steps: 615, steps per second:  40, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.005952, mae: 0.204266, mean_q: 0.252569, mean_eps: 0.876723\n",
      " 137918/500000: episode: 199, duration: 16.139s, episode steps: 635, steps per second:  39, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.006623, mae: 0.205114, mean_q: 0.254278, mean_eps: 0.876160\n",
      " 138575/500000: episode: 200, duration: 16.955s, episode steps: 657, steps per second:  39, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.005751, mae: 0.204736, mean_q: 0.253725, mean_eps: 0.875579\n",
      " 139485/500000: episode: 201, duration: 23.417s, episode steps: 910, steps per second:  39, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.007153, mae: 0.208880, mean_q: 0.257450, mean_eps: 0.874873\n",
      " 140277/500000: episode: 202, duration: 21.018s, episode steps: 792, steps per second:  38, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.006273, mae: 0.213559, mean_q: 0.264356, mean_eps: 0.874106\n",
      " 140893/500000: episode: 203, duration: 16.091s, episode steps: 616, steps per second:  38, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.006754, mae: 0.229823, mean_q: 0.284414, mean_eps: 0.873473\n",
      " 141547/500000: episode: 204, duration: 17.098s, episode steps: 654, steps per second:  38, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.007884, mae: 0.236725, mean_q: 0.292736, mean_eps: 0.872902\n",
      " 142243/500000: episode: 205, duration: 18.261s, episode steps: 696, steps per second:  38, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.007604, mae: 0.235524, mean_q: 0.292157, mean_eps: 0.872295\n",
      " 142904/500000: episode: 206, duration: 17.124s, episode steps: 661, steps per second:  39, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.006931, mae: 0.226638, mean_q: 0.278793, mean_eps: 0.871685\n",
      " 143624/500000: episode: 207, duration: 18.772s, episode steps: 720, steps per second:  38, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.008364, mae: 0.233352, mean_q: 0.288079, mean_eps: 0.871064\n",
      " 144392/500000: episode: 208, duration: 19.893s, episode steps: 768, steps per second:  39, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006810, mae: 0.233393, mean_q: 0.287832, mean_eps: 0.870395\n",
      " 145326/500000: episode: 209, duration: 24.241s, episode steps: 934, steps per second:  39, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007594, mae: 0.234114, mean_q: 0.286723, mean_eps: 0.869628\n",
      " 146309/500000: episode: 210, duration: 25.558s, episode steps: 983, steps per second:  38, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.007815, mae: 0.236386, mean_q: 0.290544, mean_eps: 0.868764\n",
      " 147723/500000: episode: 211, duration: 37.977s, episode steps: 1414, steps per second:  37, episode reward: 23.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007483, mae: 0.231823, mean_q: 0.285620, mean_eps: 0.867686\n",
      " 148578/500000: episode: 212, duration: 23.043s, episode steps: 855, steps per second:  37, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007918, mae: 0.234868, mean_q: 0.289086, mean_eps: 0.866665\n",
      " 149234/500000: episode: 213, duration: 17.279s, episode steps: 656, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.006866, mae: 0.231613, mean_q: 0.286672, mean_eps: 0.865985\n",
      " 149835/500000: episode: 214, duration: 15.628s, episode steps: 601, steps per second:  38, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.007552, mae: 0.235855, mean_q: 0.289281, mean_eps: 0.865419\n",
      " 150525/500000: episode: 215, duration: 18.353s, episode steps: 690, steps per second:  38, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.008087, mae: 0.260372, mean_q: 0.319719, mean_eps: 0.864838\n",
      " 150944/500000: episode: 216, duration: 11.060s, episode steps: 419, steps per second:  38, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.007077, mae: 0.265494, mean_q: 0.329596, mean_eps: 0.864339\n",
      " 151613/500000: episode: 217, duration: 17.598s, episode steps: 669, steps per second:  38, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.007408, mae: 0.257684, mean_q: 0.316714, mean_eps: 0.863850\n",
      " 152345/500000: episode: 218, duration: 18.913s, episode steps: 732, steps per second:  39, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.007922, mae: 0.265671, mean_q: 0.325452, mean_eps: 0.863218\n",
      " 153275/500000: episode: 219, duration: 24.058s, episode steps: 930, steps per second:  39, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.007955, mae: 0.266747, mean_q: 0.328537, mean_eps: 0.862471\n",
      " 153879/500000: episode: 220, duration: 15.497s, episode steps: 604, steps per second:  39, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.006238, mae: 0.255676, mean_q: 0.314040, mean_eps: 0.861782\n",
      " 154250/500000: episode: 221, duration: 9.355s, episode steps: 371, steps per second:  40, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.006545, mae: 0.264479, mean_q: 0.325345, mean_eps: 0.861342\n",
      " 154898/500000: episode: 222, duration: 16.413s, episode steps: 648, steps per second:  39, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.006541, mae: 0.264218, mean_q: 0.325409, mean_eps: 0.860883\n",
      " 155793/500000: episode: 223, duration: 22.700s, episode steps: 895, steps per second:  39, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.006638, mae: 0.261633, mean_q: 0.320969, mean_eps: 0.860189\n",
      " 156346/500000: episode: 224, duration: 14.627s, episode steps: 553, steps per second:  38, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007285, mae: 0.264027, mean_q: 0.325406, mean_eps: 0.859537\n",
      " 157210/500000: episode: 225, duration: 22.017s, episode steps: 864, steps per second:  39, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007469, mae: 0.266441, mean_q: 0.327694, mean_eps: 0.858900\n",
      " 157714/500000: episode: 226, duration: 12.867s, episode steps: 504, steps per second:  39, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.006780, mae: 0.259999, mean_q: 0.319544, mean_eps: 0.858284\n",
      " 158110/500000: episode: 227, duration: 10.046s, episode steps: 396, steps per second:  39, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.007952, mae: 0.261687, mean_q: 0.322925, mean_eps: 0.857879\n",
      " 158543/500000: episode: 228, duration: 11.125s, episode steps: 433, steps per second:  39, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.006707, mae: 0.261692, mean_q: 0.323597, mean_eps: 0.857507\n",
      " 159370/500000: episode: 229, duration: 21.412s, episode steps: 827, steps per second:  39, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.007235, mae: 0.261022, mean_q: 0.320065, mean_eps: 0.856940\n",
      " 160093/500000: episode: 230, duration: 19.002s, episode steps: 723, steps per second:  38, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.006273, mae: 0.266214, mean_q: 0.328751, mean_eps: 0.856241\n",
      " 160718/500000: episode: 231, duration: 16.547s, episode steps: 625, steps per second:  38, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.008713, mae: 0.292426, mean_q: 0.359614, mean_eps: 0.855635\n",
      " 161125/500000: episode: 232, duration: 10.439s, episode steps: 407, steps per second:  39, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.007562, mae: 0.292961, mean_q: 0.361929, mean_eps: 0.855170\n",
      " 161680/500000: episode: 233, duration: 14.202s, episode steps: 555, steps per second:  39, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.007897, mae: 0.292285, mean_q: 0.359348, mean_eps: 0.854738\n",
      " 162178/500000: episode: 234, duration: 12.906s, episode steps: 498, steps per second:  39, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.007931, mae: 0.293107, mean_q: 0.360367, mean_eps: 0.854265\n",
      " 162573/500000: episode: 235, duration: 10.075s, episode steps: 395, steps per second:  39, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007468, mae: 0.290268, mean_q: 0.356835, mean_eps: 0.853862\n",
      " 163731/500000: episode: 236, duration: 29.775s, episode steps: 1158, steps per second:  39, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.007582, mae: 0.288051, mean_q: 0.353754, mean_eps: 0.853163\n",
      " 164452/500000: episode: 237, duration: 19.047s, episode steps: 721, steps per second:  38, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.007024, mae: 0.284355, mean_q: 0.348789, mean_eps: 0.852319\n",
      " 165243/500000: episode: 238, duration: 20.743s, episode steps: 791, steps per second:  38, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007019, mae: 0.287824, mean_q: 0.353866, mean_eps: 0.851639\n",
      " 166079/500000: episode: 239, duration: 21.321s, episode steps: 836, steps per second:  39, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.007865, mae: 0.285910, mean_q: 0.352375, mean_eps: 0.850906\n",
      " 166875/500000: episode: 240, duration: 20.247s, episode steps: 796, steps per second:  39, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.006242, mae: 0.287891, mean_q: 0.354969, mean_eps: 0.850172\n",
      " 167725/500000: episode: 241, duration: 21.990s, episode steps: 850, steps per second:  39, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.007237, mae: 0.284988, mean_q: 0.350998, mean_eps: 0.849430\n",
      " 168821/500000: episode: 242, duration: 28.751s, episode steps: 1096, steps per second:  38, episode reward: 10.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.007146, mae: 0.288992, mean_q: 0.354556, mean_eps: 0.848553\n",
      " 169365/500000: episode: 243, duration: 14.509s, episode steps: 544, steps per second:  37, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.006683, mae: 0.287174, mean_q: 0.354193, mean_eps: 0.847815\n",
      " 170322/500000: episode: 244, duration: 24.798s, episode steps: 957, steps per second:  39, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.007383, mae: 0.298404, mean_q: 0.366432, mean_eps: 0.847140\n",
      " 171117/500000: episode: 245, duration: 21.099s, episode steps: 795, steps per second:  38, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.008856, mae: 0.324703, mean_q: 0.398013, mean_eps: 0.846352\n",
      " 171479/500000: episode: 246, duration: 9.598s, episode steps: 362, steps per second:  38, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.008311, mae: 0.317499, mean_q: 0.389309, mean_eps: 0.845832\n",
      " 171912/500000: episode: 247, duration: 11.477s, episode steps: 433, steps per second:  38, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.008738, mae: 0.319776, mean_q: 0.393709, mean_eps: 0.845475\n",
      " 172324/500000: episode: 248, duration: 10.607s, episode steps: 412, steps per second:  39, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.008023, mae: 0.323895, mean_q: 0.399033, mean_eps: 0.845096\n",
      " 173111/500000: episode: 249, duration: 20.216s, episode steps: 787, steps per second:  39, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.007360, mae: 0.321412, mean_q: 0.394125, mean_eps: 0.844556\n",
      " 174154/500000: episode: 250, duration: 26.946s, episode steps: 1043, steps per second:  39, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.008299, mae: 0.321934, mean_q: 0.395939, mean_eps: 0.843731\n",
      " 174864/500000: episode: 251, duration: 18.223s, episode steps: 710, steps per second:  39, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.007804, mae: 0.317880, mean_q: 0.391249, mean_eps: 0.842943\n",
      " 175497/500000: episode: 252, duration: 16.315s, episode steps: 633, steps per second:  39, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.007874, mae: 0.320036, mean_q: 0.393553, mean_eps: 0.842338\n",
      " 176712/500000: episode: 253, duration: 30.983s, episode steps: 1215, steps per second:  39, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.008405, mae: 0.323680, mean_q: 0.395571, mean_eps: 0.841506\n",
      " 177072/500000: episode: 254, duration: 9.443s, episode steps: 360, steps per second:  38, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.008436, mae: 0.327587, mean_q: 0.401025, mean_eps: 0.840799\n",
      " 177960/500000: episode: 255, duration: 23.074s, episode steps: 888, steps per second:  38, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007585, mae: 0.318418, mean_q: 0.389438, mean_eps: 0.840237\n",
      " 178770/500000: episode: 256, duration: 20.812s, episode steps: 810, steps per second:  39, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: 0.007742, mae: 0.322816, mean_q: 0.395500, mean_eps: 0.839472\n",
      " 179461/500000: episode: 257, duration: 17.820s, episode steps: 691, steps per second:  39, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.007998, mae: 0.326310, mean_q: 0.401488, mean_eps: 0.838796\n",
      " 180119/500000: episode: 258, duration: 16.997s, episode steps: 658, steps per second:  39, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006936, mae: 0.322917, mean_q: 0.395458, mean_eps: 0.838189\n",
      " 181015/500000: episode: 259, duration: 24.427s, episode steps: 896, steps per second:  37, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.008358, mae: 0.341507, mean_q: 0.419719, mean_eps: 0.837491\n",
      " 181716/500000: episode: 260, duration: 19.243s, episode steps: 701, steps per second:  36, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007311, mae: 0.340928, mean_q: 0.418142, mean_eps: 0.836772\n",
      " 182437/500000: episode: 261, duration: 20.182s, episode steps: 721, steps per second:  36, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.007923, mae: 0.336893, mean_q: 0.414221, mean_eps: 0.836132\n",
      " 183592/500000: episode: 262, duration: 30.917s, episode steps: 1155, steps per second:  37, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.007682, mae: 0.333809, mean_q: 0.409721, mean_eps: 0.835287\n",
      " 184092/500000: episode: 263, duration: 13.142s, episode steps: 500, steps per second:  38, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.009343, mae: 0.345207, mean_q: 0.424969, mean_eps: 0.834544\n",
      " 185280/500000: episode: 264, duration: 31.308s, episode steps: 1188, steps per second:  38, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.008028, mae: 0.342910, mean_q: 0.421912, mean_eps: 0.833784\n",
      " 185777/500000: episode: 265, duration: 13.033s, episode steps: 497, steps per second:  38, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.007242, mae: 0.344094, mean_q: 0.422144, mean_eps: 0.833025\n",
      " 186798/500000: episode: 266, duration: 26.660s, episode steps: 1021, steps per second:  38, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.007699, mae: 0.335102, mean_q: 0.411898, mean_eps: 0.832341\n",
      " 187463/500000: episode: 267, duration: 17.318s, episode steps: 665, steps per second:  38, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.007437, mae: 0.336448, mean_q: 0.414063, mean_eps: 0.831583\n",
      " 188174/500000: episode: 268, duration: 18.895s, episode steps: 711, steps per second:  38, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.008521, mae: 0.340609, mean_q: 0.417497, mean_eps: 0.830964\n",
      " 188925/500000: episode: 269, duration: 20.828s, episode steps: 751, steps per second:  36, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.007204, mae: 0.337432, mean_q: 0.414359, mean_eps: 0.830305\n",
      " 189845/500000: episode: 270, duration: 24.214s, episode steps: 920, steps per second:  38, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007978, mae: 0.342768, mean_q: 0.420805, mean_eps: 0.829553\n",
      " 190445/500000: episode: 271, duration: 15.409s, episode steps: 600, steps per second:  39, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.008871, mae: 0.356219, mean_q: 0.437674, mean_eps: 0.828869\n",
      " 191081/500000: episode: 272, duration: 17.740s, episode steps: 636, steps per second:  36, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.008380, mae: 0.368483, mean_q: 0.456409, mean_eps: 0.828312\n",
      " 191719/500000: episode: 273, duration: 17.366s, episode steps: 638, steps per second:  37, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.009313, mae: 0.370192, mean_q: 0.455795, mean_eps: 0.827740\n",
      " 192376/500000: episode: 274, duration: 18.160s, episode steps: 657, steps per second:  36, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.007576, mae: 0.354687, mean_q: 0.437280, mean_eps: 0.827159\n",
      " 193054/500000: episode: 275, duration: 18.632s, episode steps: 678, steps per second:  36, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.010165, mae: 0.373386, mean_q: 0.459627, mean_eps: 0.826557\n",
      " 193741/500000: episode: 276, duration: 18.204s, episode steps: 687, steps per second:  38, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.009252, mae: 0.366281, mean_q: 0.451220, mean_eps: 0.825942\n",
      " 194301/500000: episode: 277, duration: 16.107s, episode steps: 560, steps per second:  35, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.008072, mae: 0.365558, mean_q: 0.449237, mean_eps: 0.825380\n",
      " 195309/500000: episode: 278, duration: 33.501s, episode steps: 1008, steps per second:  30, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.008226, mae: 0.368996, mean_q: 0.454111, mean_eps: 0.824675\n",
      " 195679/500000: episode: 279, duration: 11.787s, episode steps: 370, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.008870, mae: 0.373443, mean_q: 0.462057, mean_eps: 0.824055\n",
      " 196354/500000: episode: 280, duration: 28.477s, episode steps: 675, steps per second:  24, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.007662, mae: 0.363062, mean_q: 0.446582, mean_eps: 0.823586\n",
      " 196841/500000: episode: 281, duration: 29.700s, episode steps: 487, steps per second:  16, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.007229, mae: 0.357691, mean_q: 0.438882, mean_eps: 0.823062\n",
      " 197518/500000: episode: 282, duration: 30.562s, episode steps: 677, steps per second:  22, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.008217, mae: 0.365866, mean_q: 0.449955, mean_eps: 0.822538\n",
      " 198136/500000: episode: 283, duration: 16.529s, episode steps: 618, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.007924, mae: 0.359708, mean_q: 0.441919, mean_eps: 0.821957\n",
      " 198829/500000: episode: 284, duration: 17.498s, episode steps: 693, steps per second:  40, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.008132, mae: 0.372026, mean_q: 0.457092, mean_eps: 0.821366\n",
      " 199180/500000: episode: 285, duration: 8.871s, episode steps: 351, steps per second:  40, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.007614, mae: 0.359103, mean_q: 0.441702, mean_eps: 0.820896\n",
      " 199811/500000: episode: 286, duration: 16.122s, episode steps: 631, steps per second:  39, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.008737, mae: 0.368212, mean_q: 0.452825, mean_eps: 0.820455\n",
      " 200201/500000: episode: 287, duration: 10.574s, episode steps: 390, steps per second:  37, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.008109, mae: 0.381713, mean_q: 0.469841, mean_eps: 0.819995\n",
      " 200563/500000: episode: 288, duration: 9.920s, episode steps: 362, steps per second:  36, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.007816, mae: 0.373580, mean_q: 0.459575, mean_eps: 0.819656\n",
      " 201157/500000: episode: 289, duration: 15.323s, episode steps: 594, steps per second:  39, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: 0.010070, mae: 0.385017, mean_q: 0.475592, mean_eps: 0.819226\n",
      " 201991/500000: episode: 290, duration: 21.316s, episode steps: 834, steps per second:  39, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007976, mae: 0.376123, mean_q: 0.464308, mean_eps: 0.818583\n",
      " 202690/500000: episode: 291, duration: 17.899s, episode steps: 699, steps per second:  39, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.009195, mae: 0.379533, mean_q: 0.468070, mean_eps: 0.817894\n",
      " 203076/500000: episode: 292, duration: 9.898s, episode steps: 386, steps per second:  39, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.008954, mae: 0.384595, mean_q: 0.472432, mean_eps: 0.817406\n",
      " 203607/500000: episode: 293, duration: 13.592s, episode steps: 531, steps per second:  39, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.008930, mae: 0.383879, mean_q: 0.471428, mean_eps: 0.816994\n",
      " 204286/500000: episode: 294, duration: 17.491s, episode steps: 679, steps per second:  39, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: 0.009462, mae: 0.379427, mean_q: 0.466522, mean_eps: 0.816449\n",
      " 204824/500000: episode: 295, duration: 13.864s, episode steps: 538, steps per second:  39, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.009128, mae: 0.377183, mean_q: 0.462809, mean_eps: 0.815901\n",
      " 205788/500000: episode: 296, duration: 25.238s, episode steps: 964, steps per second:  38, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.007894, mae: 0.375670, mean_q: 0.462540, mean_eps: 0.815226\n",
      " 206430/500000: episode: 297, duration: 16.422s, episode steps: 642, steps per second:  39, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.007557, mae: 0.380862, mean_q: 0.469853, mean_eps: 0.814503\n",
      " 206870/500000: episode: 298, duration: 11.237s, episode steps: 440, steps per second:  39, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.009087, mae: 0.380398, mean_q: 0.468577, mean_eps: 0.814015\n",
      " 207675/500000: episode: 299, duration: 20.619s, episode steps: 805, steps per second:  39, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.008144, mae: 0.380764, mean_q: 0.470631, mean_eps: 0.813455\n",
      " 208197/500000: episode: 300, duration: 13.423s, episode steps: 522, steps per second:  39, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.009185, mae: 0.378156, mean_q: 0.467034, mean_eps: 0.812858\n",
      " 208826/500000: episode: 301, duration: 16.172s, episode steps: 629, steps per second:  39, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.009853, mae: 0.380343, mean_q: 0.468030, mean_eps: 0.812339\n",
      " 209510/500000: episode: 302, duration: 17.589s, episode steps: 684, steps per second:  39, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.008521, mae: 0.383405, mean_q: 0.472910, mean_eps: 0.811749\n",
      " 210051/500000: episode: 303, duration: 13.941s, episode steps: 541, steps per second:  39, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.008678, mae: 0.385070, mean_q: 0.475310, mean_eps: 0.811198\n",
      " 210712/500000: episode: 304, duration: 17.084s, episode steps: 661, steps per second:  39, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.009240, mae: 0.425132, mean_q: 0.526047, mean_eps: 0.810658\n",
      " 211275/500000: episode: 305, duration: 14.641s, episode steps: 563, steps per second:  38, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.008827, mae: 0.416676, mean_q: 0.513971, mean_eps: 0.810107\n",
      " 211941/500000: episode: 306, duration: 17.222s, episode steps: 666, steps per second:  39, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.009721, mae: 0.428550, mean_q: 0.528566, mean_eps: 0.809553\n",
      " 212470/500000: episode: 307, duration: 13.735s, episode steps: 529, steps per second:  39, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.009241, mae: 0.419759, mean_q: 0.518851, mean_eps: 0.809015\n",
      " 213039/500000: episode: 308, duration: 14.753s, episode steps: 569, steps per second:  39, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.009939, mae: 0.430278, mean_q: 0.530208, mean_eps: 0.808521\n",
      " 213676/500000: episode: 309, duration: 16.639s, episode steps: 637, steps per second:  38, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.009298, mae: 0.425188, mean_q: 0.524788, mean_eps: 0.807980\n",
      " 214312/500000: episode: 310, duration: 16.529s, episode steps: 636, steps per second:  38, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008526, mae: 0.424656, mean_q: 0.522189, mean_eps: 0.807407\n",
      " 214698/500000: episode: 311, duration: 10.011s, episode steps: 386, steps per second:  39, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.009307, mae: 0.430434, mean_q: 0.528221, mean_eps: 0.806946\n",
      " 215194/500000: episode: 312, duration: 13.026s, episode steps: 496, steps per second:  38, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.009243, mae: 0.421480, mean_q: 0.517230, mean_eps: 0.806549\n",
      " 216022/500000: episode: 313, duration: 21.724s, episode steps: 828, steps per second:  38, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.009002, mae: 0.419814, mean_q: 0.518078, mean_eps: 0.805953\n",
      " 216835/500000: episode: 314, duration: 21.779s, episode steps: 813, steps per second:  37, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.009024, mae: 0.421366, mean_q: 0.518902, mean_eps: 0.805215\n",
      " 217723/500000: episode: 315, duration: 24.233s, episode steps: 888, steps per second:  37, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.008889, mae: 0.422520, mean_q: 0.520821, mean_eps: 0.804450\n",
      " 218368/500000: episode: 316, duration: 18.401s, episode steps: 645, steps per second:  35, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.008663, mae: 0.426637, mean_q: 0.526255, mean_eps: 0.803760\n",
      " 219039/500000: episode: 317, duration: 19.338s, episode steps: 671, steps per second:  35, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.008931, mae: 0.427976, mean_q: 0.526484, mean_eps: 0.803168\n",
      " 219985/500000: episode: 318, duration: 25.356s, episode steps: 946, steps per second:  37, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.009644, mae: 0.430675, mean_q: 0.530102, mean_eps: 0.802439\n",
      " 220619/500000: episode: 319, duration: 16.542s, episode steps: 634, steps per second:  38, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.008784, mae: 0.443245, mean_q: 0.546143, mean_eps: 0.801728\n",
      " 221140/500000: episode: 320, duration: 14.043s, episode steps: 521, steps per second:  37, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.009142, mae: 0.441711, mean_q: 0.542634, mean_eps: 0.801210\n",
      " 221788/500000: episode: 321, duration: 17.083s, episode steps: 648, steps per second:  38, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.009798, mae: 0.437908, mean_q: 0.539777, mean_eps: 0.800684\n",
      " 222423/500000: episode: 322, duration: 17.033s, episode steps: 635, steps per second:  37, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.010895, mae: 0.450724, mean_q: 0.556410, mean_eps: 0.800106\n",
      " 222978/500000: episode: 323, duration: 14.647s, episode steps: 555, steps per second:  38, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.008682, mae: 0.445039, mean_q: 0.549778, mean_eps: 0.799570\n",
      " 223376/500000: episode: 324, duration: 10.880s, episode steps: 398, steps per second:  37, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.009680, mae: 0.446438, mean_q: 0.550123, mean_eps: 0.799142\n",
      " 224015/500000: episode: 325, duration: 16.882s, episode steps: 639, steps per second:  38, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.009011, mae: 0.441467, mean_q: 0.542656, mean_eps: 0.798675\n",
      " 224719/500000: episode: 326, duration: 18.815s, episode steps: 704, steps per second:  37, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.009541, mae: 0.439994, mean_q: 0.540220, mean_eps: 0.798071\n",
      " 225838/500000: episode: 327, duration: 30.181s, episode steps: 1119, steps per second:  37, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.010161, mae: 0.444650, mean_q: 0.547392, mean_eps: 0.797250\n",
      " 226517/500000: episode: 328, duration: 17.942s, episode steps: 679, steps per second:  38, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.009379, mae: 0.449051, mean_q: 0.554486, mean_eps: 0.796440\n",
      " 227691/500000: episode: 329, duration: 31.220s, episode steps: 1174, steps per second:  38, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.009215, mae: 0.440446, mean_q: 0.544012, mean_eps: 0.795606\n",
      " 228161/500000: episode: 330, duration: 12.891s, episode steps: 470, steps per second:  36, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.008131, mae: 0.444659, mean_q: 0.548149, mean_eps: 0.794867\n",
      " 229081/500000: episode: 331, duration: 24.353s, episode steps: 920, steps per second:  38, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.009101, mae: 0.441528, mean_q: 0.542881, mean_eps: 0.794240\n",
      " 229616/500000: episode: 332, duration: 14.061s, episode steps: 535, steps per second:  38, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.008305, mae: 0.440700, mean_q: 0.541853, mean_eps: 0.793587\n",
      " 230114/500000: episode: 333, duration: 13.311s, episode steps: 498, steps per second:  37, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.009450, mae: 0.445441, mean_q: 0.549200, mean_eps: 0.793122\n",
      " 230896/500000: episode: 334, duration: 20.497s, episode steps: 782, steps per second:  38, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.009930, mae: 0.487368, mean_q: 0.602462, mean_eps: 0.792546\n",
      " 231271/500000: episode: 335, duration: 10.198s, episode steps: 375, steps per second:  37, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.009222, mae: 0.497693, mean_q: 0.613042, mean_eps: 0.792026\n",
      " 231649/500000: episode: 336, duration: 9.982s, episode steps: 378, steps per second:  38, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.009183, mae: 0.491508, mean_q: 0.607542, mean_eps: 0.791686\n",
      " 232307/500000: episode: 337, duration: 17.429s, episode steps: 658, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.009956, mae: 0.482302, mean_q: 0.595972, mean_eps: 0.791220\n",
      " 232710/500000: episode: 338, duration: 10.602s, episode steps: 403, steps per second:  38, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.011340, mae: 0.499056, mean_q: 0.614088, mean_eps: 0.790743\n",
      " 233432/500000: episode: 339, duration: 18.967s, episode steps: 722, steps per second:  38, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.009479, mae: 0.484351, mean_q: 0.594536, mean_eps: 0.790237\n",
      " 234095/500000: episode: 340, duration: 17.311s, episode steps: 663, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.008875, mae: 0.490206, mean_q: 0.603706, mean_eps: 0.789614\n",
      " 235103/500000: episode: 341, duration: 27.107s, episode steps: 1008, steps per second:  37, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.008931, mae: 0.484040, mean_q: 0.596194, mean_eps: 0.788862\n",
      " 236018/500000: episode: 342, duration: 24.374s, episode steps: 915, steps per second:  38, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.010008, mae: 0.490972, mean_q: 0.604965, mean_eps: 0.787996\n",
      " 236709/500000: episode: 343, duration: 18.234s, episode steps: 691, steps per second:  38, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.008456, mae: 0.489462, mean_q: 0.603634, mean_eps: 0.787272\n",
      " 237272/500000: episode: 344, duration: 15.017s, episode steps: 563, steps per second:  37, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.010265, mae: 0.488172, mean_q: 0.602533, mean_eps: 0.786709\n",
      " 237666/500000: episode: 345, duration: 10.489s, episode steps: 394, steps per second:  38, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.008491, mae: 0.498230, mean_q: 0.612544, mean_eps: 0.786279\n",
      " 238301/500000: episode: 346, duration: 16.963s, episode steps: 635, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.009370, mae: 0.491222, mean_q: 0.604137, mean_eps: 0.785814\n",
      " 238666/500000: episode: 347, duration: 9.511s, episode steps: 365, steps per second:  38, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.009267, mae: 0.478771, mean_q: 0.590210, mean_eps: 0.785364\n",
      " 239612/500000: episode: 348, duration: 25.124s, episode steps: 946, steps per second:  38, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.010267, mae: 0.488294, mean_q: 0.599913, mean_eps: 0.784776\n",
      " 240474/500000: episode: 349, duration: 23.032s, episode steps: 862, steps per second:  37, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.008884, mae: 0.506382, mean_q: 0.624455, mean_eps: 0.783962\n",
      " 240859/500000: episode: 350, duration: 10.262s, episode steps: 385, steps per second:  38, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.009552, mae: 0.531162, mean_q: 0.654856, mean_eps: 0.783401\n",
      " 241254/500000: episode: 351, duration: 10.532s, episode steps: 395, steps per second:  38, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.838 [0.000, 5.000],  loss: 0.008187, mae: 0.530885, mean_q: 0.656089, mean_eps: 0.783050\n",
      " 241632/500000: episode: 352, duration: 10.197s, episode steps: 378, steps per second:  37, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.008678, mae: 0.524748, mean_q: 0.649760, mean_eps: 0.782702\n",
      " 242696/500000: episode: 353, duration: 28.231s, episode steps: 1064, steps per second:  38, episode reward: 10.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.010587, mae: 0.533693, mean_q: 0.657133, mean_eps: 0.782054\n",
      " 243072/500000: episode: 354, duration: 10.028s, episode steps: 376, steps per second:  37, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.010569, mae: 0.540574, mean_q: 0.665305, mean_eps: 0.781406\n",
      " 243579/500000: episode: 355, duration: 13.687s, episode steps: 507, steps per second:  37, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.740 [0.000, 5.000],  loss: 0.010047, mae: 0.531252, mean_q: 0.655326, mean_eps: 0.781008\n",
      " 244213/500000: episode: 356, duration: 16.714s, episode steps: 634, steps per second:  38, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.009471, mae: 0.524766, mean_q: 0.644729, mean_eps: 0.780494\n",
      " 244999/500000: episode: 357, duration: 20.972s, episode steps: 786, steps per second:  37, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.009459, mae: 0.520675, mean_q: 0.640523, mean_eps: 0.779855\n",
      " 245389/500000: episode: 358, duration: 10.415s, episode steps: 390, steps per second:  37, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.009397, mae: 0.518331, mean_q: 0.637314, mean_eps: 0.779325\n",
      " 246335/500000: episode: 359, duration: 25.538s, episode steps: 946, steps per second:  37, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.010670, mae: 0.525036, mean_q: 0.647207, mean_eps: 0.778724\n",
      " 246725/500000: episode: 360, duration: 10.613s, episode steps: 390, steps per second:  37, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.008330, mae: 0.517966, mean_q: 0.640019, mean_eps: 0.778123\n",
      " 247680/500000: episode: 361, duration: 26.092s, episode steps: 955, steps per second:  37, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.010329, mae: 0.531142, mean_q: 0.653981, mean_eps: 0.777518\n",
      " 248696/500000: episode: 362, duration: 27.893s, episode steps: 1016, steps per second:  36, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.010402, mae: 0.521682, mean_q: 0.641987, mean_eps: 0.776633\n",
      " 249468/500000: episode: 363, duration: 21.200s, episode steps: 772, steps per second:  36, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.010105, mae: 0.532116, mean_q: 0.654594, mean_eps: 0.775828\n",
      " 250221/500000: episode: 364, duration: 20.891s, episode steps: 753, steps per second:  36, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.008923, mae: 0.530869, mean_q: 0.652095, mean_eps: 0.775140\n",
      " 251200/500000: episode: 365, duration: 26.285s, episode steps: 979, steps per second:  37, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.010109, mae: 0.561111, mean_q: 0.691777, mean_eps: 0.774361\n",
      " 251711/500000: episode: 366, duration: 13.776s, episode steps: 511, steps per second:  37, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.010583, mae: 0.567633, mean_q: 0.700173, mean_eps: 0.773691\n",
      " 252354/500000: episode: 367, duration: 16.907s, episode steps: 643, steps per second:  38, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.010854, mae: 0.566709, mean_q: 0.700349, mean_eps: 0.773171\n",
      " 253721/500000: episode: 368, duration: 36.274s, episode steps: 1367, steps per second:  38, episode reward: 23.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.011048, mae: 0.560877, mean_q: 0.691552, mean_eps: 0.772266\n",
      " 254495/500000: episode: 369, duration: 20.252s, episode steps: 774, steps per second:  38, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.010147, mae: 0.561254, mean_q: 0.694195, mean_eps: 0.771303\n",
      " 255438/500000: episode: 370, duration: 25.194s, episode steps: 943, steps per second:  37, episode reward: 28.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.010821, mae: 0.553060, mean_q: 0.680144, mean_eps: 0.770531\n",
      " 256587/500000: episode: 371, duration: 30.685s, episode steps: 1149, steps per second:  37, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.010309, mae: 0.561750, mean_q: 0.690981, mean_eps: 0.769589\n",
      " 257261/500000: episode: 372, duration: 17.974s, episode steps: 674, steps per second:  37, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.009099, mae: 0.561292, mean_q: 0.690860, mean_eps: 0.768768\n",
      " 257704/500000: episode: 373, duration: 11.647s, episode steps: 443, steps per second:  38, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.012982, mae: 0.573716, mean_q: 0.702521, mean_eps: 0.768266\n",
      " 258930/500000: episode: 374, duration: 32.515s, episode steps: 1226, steps per second:  38, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.011439, mae: 0.559733, mean_q: 0.688602, mean_eps: 0.767516\n",
      " 259452/500000: episode: 375, duration: 14.006s, episode steps: 522, steps per second:  37, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.010666, mae: 0.551357, mean_q: 0.679148, mean_eps: 0.766729\n",
      " 260116/500000: episode: 376, duration: 17.247s, episode steps: 664, steps per second:  38, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.009765, mae: 0.561261, mean_q: 0.692638, mean_eps: 0.766196\n",
      " 260811/500000: episode: 377, duration: 18.233s, episode steps: 695, steps per second:  38, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.010735, mae: 0.606352, mean_q: 0.747578, mean_eps: 0.765584\n",
      " 261485/500000: episode: 378, duration: 17.714s, episode steps: 674, steps per second:  38, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.009496, mae: 0.604673, mean_q: 0.744315, mean_eps: 0.764967\n",
      " 262101/500000: episode: 379, duration: 16.422s, episode steps: 616, steps per second:  38, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.009396, mae: 0.609345, mean_q: 0.751759, mean_eps: 0.764385\n",
      " 262897/500000: episode: 380, duration: 21.481s, episode steps: 796, steps per second:  37, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.010236, mae: 0.609314, mean_q: 0.749476, mean_eps: 0.763750\n",
      " 263401/500000: episode: 381, duration: 13.358s, episode steps: 504, steps per second:  38, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.011804, mae: 0.607776, mean_q: 0.747605, mean_eps: 0.763165\n",
      " 263948/500000: episode: 382, duration: 14.455s, episode steps: 547, steps per second:  38, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.010149, mae: 0.596434, mean_q: 0.735759, mean_eps: 0.762693\n",
      " 264485/500000: episode: 383, duration: 13.990s, episode steps: 537, steps per second:  38, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.739 [0.000, 5.000],  loss: 0.011067, mae: 0.613979, mean_q: 0.755232, mean_eps: 0.762206\n",
      " 265291/500000: episode: 384, duration: 21.803s, episode steps: 806, steps per second:  37, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.010879, mae: 0.605481, mean_q: 0.743277, mean_eps: 0.761601\n",
      " 265851/500000: episode: 385, duration: 15.516s, episode steps: 560, steps per second:  36, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.011164, mae: 0.611573, mean_q: 0.751519, mean_eps: 0.760987\n",
      " 266364/500000: episode: 386, duration: 14.355s, episode steps: 513, steps per second:  36, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.011199, mae: 0.604192, mean_q: 0.741874, mean_eps: 0.760505\n",
      " 266856/500000: episode: 387, duration: 13.596s, episode steps: 492, steps per second:  36, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.009465, mae: 0.605121, mean_q: 0.743162, mean_eps: 0.760053\n",
      " 267478/500000: episode: 388, duration: 17.163s, episode steps: 622, steps per second:  36, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: 0.010008, mae: 0.598706, mean_q: 0.734160, mean_eps: 0.759551\n",
      " 267990/500000: episode: 389, duration: 13.907s, episode steps: 512, steps per second:  37, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.012355, mae: 0.609529, mean_q: 0.749171, mean_eps: 0.759039\n",
      " 268847/500000: episode: 390, duration: 23.704s, episode steps: 857, steps per second:  36, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.010019, mae: 0.607558, mean_q: 0.746250, mean_eps: 0.758424\n",
      " 269755/500000: episode: 391, duration: 24.875s, episode steps: 908, steps per second:  37, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.009832, mae: 0.613200, mean_q: 0.755604, mean_eps: 0.757630\n",
      " 270250/500000: episode: 392, duration: 13.605s, episode steps: 495, steps per second:  36, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.010713, mae: 0.620414, mean_q: 0.763827, mean_eps: 0.756998\n",
      " 270726/500000: episode: 393, duration: 13.261s, episode steps: 476, steps per second:  36, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.010862, mae: 0.651602, mean_q: 0.800916, mean_eps: 0.756561\n",
      " 271311/500000: episode: 394, duration: 15.988s, episode steps: 585, steps per second:  37, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.009385, mae: 0.633458, mean_q: 0.779105, mean_eps: 0.756084\n",
      " 272264/500000: episode: 395, duration: 26.528s, episode steps: 953, steps per second:  36, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.009691, mae: 0.637854, mean_q: 0.786001, mean_eps: 0.755393\n",
      " 272790/500000: episode: 396, duration: 14.612s, episode steps: 526, steps per second:  36, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.009875, mae: 0.631841, mean_q: 0.777786, mean_eps: 0.754727\n",
      " 273614/500000: episode: 397, duration: 21.855s, episode steps: 824, steps per second:  38, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.011286, mae: 0.641480, mean_q: 0.788398, mean_eps: 0.754118\n",
      " 274293/500000: episode: 398, duration: 18.099s, episode steps: 679, steps per second:  38, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.009467, mae: 0.638655, mean_q: 0.785041, mean_eps: 0.753441\n",
      " 275284/500000: episode: 399, duration: 26.500s, episode steps: 991, steps per second:  37, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.010799, mae: 0.645764, mean_q: 0.794332, mean_eps: 0.752691\n",
      " 275936/500000: episode: 400, duration: 17.549s, episode steps: 652, steps per second:  37, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.010569, mae: 0.639941, mean_q: 0.786233, mean_eps: 0.751953\n",
      " 276509/500000: episode: 401, duration: 15.224s, episode steps: 573, steps per second:  38, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.009991, mae: 0.635090, mean_q: 0.779467, mean_eps: 0.751400\n",
      " 277029/500000: episode: 402, duration: 14.117s, episode steps: 520, steps per second:  37, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.009690, mae: 0.627156, mean_q: 0.771473, mean_eps: 0.750907\n",
      " 277932/500000: episode: 403, duration: 24.425s, episode steps: 903, steps per second:  37, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.010049, mae: 0.638375, mean_q: 0.784934, mean_eps: 0.750268\n",
      " 278741/500000: episode: 404, duration: 22.426s, episode steps: 809, steps per second:  36, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.010343, mae: 0.642068, mean_q: 0.789467, mean_eps: 0.749498\n",
      " 279283/500000: episode: 405, duration: 15.022s, episode steps: 542, steps per second:  36, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.009133, mae: 0.629377, mean_q: 0.774930, mean_eps: 0.748889\n",
      " 279682/500000: episode: 406, duration: 10.771s, episode steps: 399, steps per second:  37, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.011151, mae: 0.645826, mean_q: 0.793638, mean_eps: 0.748466\n",
      " 280284/500000: episode: 407, duration: 15.991s, episode steps: 602, steps per second:  38, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.010177, mae: 0.646424, mean_q: 0.794706, mean_eps: 0.748016\n",
      " 280942/500000: episode: 408, duration: 18.450s, episode steps: 658, steps per second:  36, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.009736, mae: 0.665479, mean_q: 0.818738, mean_eps: 0.747449\n",
      " 281556/500000: episode: 409, duration: 17.657s, episode steps: 614, steps per second:  35, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.011030, mae: 0.668640, mean_q: 0.823125, mean_eps: 0.746877\n",
      " 282375/500000: episode: 410, duration: 22.638s, episode steps: 819, steps per second:  36, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.010265, mae: 0.666144, mean_q: 0.817881, mean_eps: 0.746232\n",
      " 283185/500000: episode: 411, duration: 22.373s, episode steps: 810, steps per second:  36, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.010825, mae: 0.670700, mean_q: 0.824661, mean_eps: 0.745498\n",
      " 283682/500000: episode: 412, duration: 13.729s, episode steps: 497, steps per second:  36, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.235 [0.000, 5.000],  loss: 0.010429, mae: 0.656508, mean_q: 0.805904, mean_eps: 0.744909\n",
      " 284230/500000: episode: 413, duration: 15.196s, episode steps: 548, steps per second:  36, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.752 [0.000, 5.000],  loss: 0.010976, mae: 0.666155, mean_q: 0.815817, mean_eps: 0.744440\n",
      " 284801/500000: episode: 414, duration: 15.511s, episode steps: 571, steps per second:  37, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.010455, mae: 0.669301, mean_q: 0.822978, mean_eps: 0.743936\n",
      " 285626/500000: episode: 415, duration: 21.836s, episode steps: 825, steps per second:  38, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.012120, mae: 0.664481, mean_q: 0.815501, mean_eps: 0.743307\n",
      " 286191/500000: episode: 416, duration: 15.211s, episode steps: 565, steps per second:  37, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.010400, mae: 0.674543, mean_q: 0.827365, mean_eps: 0.742683\n",
      " 287398/500000: episode: 417, duration: 32.441s, episode steps: 1207, steps per second:  37, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.009991, mae: 0.667863, mean_q: 0.820552, mean_eps: 0.741885\n",
      " 288218/500000: episode: 418, duration: 22.070s, episode steps: 820, steps per second:  37, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.010063, mae: 0.664220, mean_q: 0.817573, mean_eps: 0.740973\n",
      " 288753/500000: episode: 419, duration: 14.183s, episode steps: 535, steps per second:  38, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.011210, mae: 0.661560, mean_q: 0.815186, mean_eps: 0.740363\n",
      " 289561/500000: episode: 420, duration: 21.595s, episode steps: 808, steps per second:  37, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.010759, mae: 0.667062, mean_q: 0.823484, mean_eps: 0.739758\n",
      " 290419/500000: episode: 421, duration: 22.891s, episode steps: 858, steps per second:  37, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.010615, mae: 0.679758, mean_q: 0.839050, mean_eps: 0.739009\n",
      " 291116/500000: episode: 422, duration: 18.401s, episode steps: 697, steps per second:  38, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.009661, mae: 0.690815, mean_q: 0.850910, mean_eps: 0.738311\n",
      " 291634/500000: episode: 423, duration: 13.906s, episode steps: 518, steps per second:  37, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.010861, mae: 0.693566, mean_q: 0.851523, mean_eps: 0.737763\n",
      " 292887/500000: episode: 424, duration: 32.792s, episode steps: 1253, steps per second:  38, episode reward: 24.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.010528, mae: 0.690478, mean_q: 0.848722, mean_eps: 0.736966\n",
      " 293688/500000: episode: 425, duration: 21.025s, episode steps: 801, steps per second:  38, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.010431, mae: 0.694474, mean_q: 0.853176, mean_eps: 0.736043\n",
      " 294525/500000: episode: 426, duration: 21.992s, episode steps: 837, steps per second:  38, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.011686, mae: 0.700781, mean_q: 0.859925, mean_eps: 0.735305\n",
      " 295175/500000: episode: 427, duration: 17.304s, episode steps: 650, steps per second:  38, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.009793, mae: 0.700644, mean_q: 0.863473, mean_eps: 0.734635\n",
      " 295940/500000: episode: 428, duration: 20.453s, episode steps: 765, steps per second:  37, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.009843, mae: 0.687348, mean_q: 0.846336, mean_eps: 0.734000\n",
      " 296577/500000: episode: 429, duration: 17.512s, episode steps: 637, steps per second:  36, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.010231, mae: 0.699541, mean_q: 0.858339, mean_eps: 0.733368\n",
      " 297453/500000: episode: 430, duration: 23.551s, episode steps: 876, steps per second:  37, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.011026, mae: 0.697579, mean_q: 0.855147, mean_eps: 0.732686\n",
      " 298411/500000: episode: 431, duration: 26.000s, episode steps: 958, steps per second:  37, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.011131, mae: 0.696875, mean_q: 0.856630, mean_eps: 0.731861\n",
      " 298958/500000: episode: 432, duration: 14.952s, episode steps: 547, steps per second:  37, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.010621, mae: 0.685875, mean_q: 0.845878, mean_eps: 0.731184\n",
      " 299913/500000: episode: 433, duration: 26.206s, episode steps: 955, steps per second:  36, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.009877, mae: 0.692034, mean_q: 0.852806, mean_eps: 0.730508\n",
      " 300415/500000: episode: 434, duration: 13.861s, episode steps: 502, steps per second:  36, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: 0.010589, mae: 0.717184, mean_q: 0.882759, mean_eps: 0.729852\n",
      " 301118/500000: episode: 435, duration: 19.300s, episode steps: 703, steps per second:  36, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.009421, mae: 0.719366, mean_q: 0.885746, mean_eps: 0.729311\n",
      " 301613/500000: episode: 436, duration: 13.658s, episode steps: 495, steps per second:  36, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.009611, mae: 0.709336, mean_q: 0.872994, mean_eps: 0.728771\n",
      " 302371/500000: episode: 437, duration: 20.826s, episode steps: 758, steps per second:  36, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.009557, mae: 0.702105, mean_q: 0.863428, mean_eps: 0.728207\n",
      " 303001/500000: episode: 438, duration: 17.488s, episode steps: 630, steps per second:  36, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.010979, mae: 0.720019, mean_q: 0.887309, mean_eps: 0.727583\n",
      " 303688/500000: episode: 439, duration: 19.192s, episode steps: 687, steps per second:  36, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.010320, mae: 0.694671, mean_q: 0.854645, mean_eps: 0.726990\n",
      " 304328/500000: episode: 440, duration: 18.228s, episode steps: 640, steps per second:  35, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.011392, mae: 0.708272, mean_q: 0.868709, mean_eps: 0.726395\n",
      " 304756/500000: episode: 441, duration: 12.539s, episode steps: 428, steps per second:  34, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.011156, mae: 0.709040, mean_q: 0.870655, mean_eps: 0.725914\n",
      " 305128/500000: episode: 442, duration: 10.589s, episode steps: 372, steps per second:  35, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.010493, mae: 0.721845, mean_q: 0.884556, mean_eps: 0.725554\n",
      " 305780/500000: episode: 443, duration: 17.992s, episode steps: 652, steps per second:  36, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.010332, mae: 0.718226, mean_q: 0.881907, mean_eps: 0.725093\n",
      " 306454/500000: episode: 444, duration: 17.957s, episode steps: 674, steps per second:  38, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.010701, mae: 0.723410, mean_q: 0.888800, mean_eps: 0.724496\n",
      " 307099/500000: episode: 445, duration: 17.148s, episode steps: 645, steps per second:  38, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: 0.010173, mae: 0.700913, mean_q: 0.860628, mean_eps: 0.723902\n",
      " 308050/500000: episode: 446, duration: 24.976s, episode steps: 951, steps per second:  38, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.011311, mae: 0.708331, mean_q: 0.870315, mean_eps: 0.723183\n",
      " 308697/500000: episode: 447, duration: 17.121s, episode steps: 647, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.011057, mae: 0.716137, mean_q: 0.880158, mean_eps: 0.722463\n",
      " 309469/500000: episode: 448, duration: 20.441s, episode steps: 772, steps per second:  38, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.010859, mae: 0.719532, mean_q: 0.883209, mean_eps: 0.721824\n",
      " 310060/500000: episode: 449, duration: 15.709s, episode steps: 591, steps per second:  38, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.010022, mae: 0.717212, mean_q: 0.878779, mean_eps: 0.721212\n",
      " 310795/500000: episode: 450, duration: 20.217s, episode steps: 735, steps per second:  36, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.009187, mae: 0.738650, mean_q: 0.905822, mean_eps: 0.720617\n",
      " 311535/500000: episode: 451, duration: 20.593s, episode steps: 740, steps per second:  36, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.010460, mae: 0.740754, mean_q: 0.908333, mean_eps: 0.719952\n",
      " 312182/500000: episode: 452, duration: 17.733s, episode steps: 647, steps per second:  36, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.011379, mae: 0.746825, mean_q: 0.914788, mean_eps: 0.719328\n",
      " 313218/500000: episode: 453, duration: 27.493s, episode steps: 1036, steps per second:  38, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.009931, mae: 0.744323, mean_q: 0.913696, mean_eps: 0.718570\n",
      " 313752/500000: episode: 454, duration: 14.199s, episode steps: 534, steps per second:  38, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.010439, mae: 0.747481, mean_q: 0.916641, mean_eps: 0.717864\n",
      " 314392/500000: episode: 455, duration: 16.940s, episode steps: 640, steps per second:  38, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.009832, mae: 0.747007, mean_q: 0.916913, mean_eps: 0.717337\n",
      " 315032/500000: episode: 456, duration: 17.126s, episode steps: 640, steps per second:  37, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.010882, mae: 0.736571, mean_q: 0.904040, mean_eps: 0.716761\n",
      " 315576/500000: episode: 457, duration: 14.837s, episode steps: 544, steps per second:  37, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.010831, mae: 0.739541, mean_q: 0.910414, mean_eps: 0.716228\n",
      " 316014/500000: episode: 458, duration: 12.650s, episode steps: 438, steps per second:  35, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.011091, mae: 0.740955, mean_q: 0.908062, mean_eps: 0.715785\n",
      " 316660/500000: episode: 459, duration: 18.437s, episode steps: 646, steps per second:  35, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.009798, mae: 0.749495, mean_q: 0.922066, mean_eps: 0.715298\n",
      " 317441/500000: episode: 460, duration: 21.849s, episode steps: 781, steps per second:  36, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.010802, mae: 0.744982, mean_q: 0.913768, mean_eps: 0.714655\n",
      " 318387/500000: episode: 461, duration: 25.488s, episode steps: 946, steps per second:  37, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.009797, mae: 0.735419, mean_q: 0.903156, mean_eps: 0.713877\n",
      " 318878/500000: episode: 462, duration: 13.025s, episode steps: 491, steps per second:  38, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.010176, mae: 0.746326, mean_q: 0.917683, mean_eps: 0.713231\n",
      " 319595/500000: episode: 463, duration: 19.069s, episode steps: 717, steps per second:  38, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.009459, mae: 0.743286, mean_q: 0.912197, mean_eps: 0.712688\n",
      " 320093/500000: episode: 464, duration: 13.310s, episode steps: 498, steps per second:  37, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.011712, mae: 0.756470, mean_q: 0.927579, mean_eps: 0.712140\n",
      " 320797/500000: episode: 465, duration: 18.858s, episode steps: 704, steps per second:  37, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.010855, mae: 0.796497, mean_q: 0.978212, mean_eps: 0.711599\n",
      " 321719/500000: episode: 466, duration: 24.755s, episode steps: 922, steps per second:  37, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.011838, mae: 0.790198, mean_q: 0.973623, mean_eps: 0.710868\n",
      " 322233/500000: episode: 467, duration: 13.840s, episode steps: 514, steps per second:  37, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.010674, mae: 0.778927, mean_q: 0.956641, mean_eps: 0.710222\n",
      " 323188/500000: episode: 468, duration: 25.695s, episode steps: 955, steps per second:  37, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.011608, mae: 0.794880, mean_q: 0.976583, mean_eps: 0.709561\n",
      " 323904/500000: episode: 469, duration: 19.521s, episode steps: 716, steps per second:  37, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.839 [0.000, 5.000],  loss: 0.009390, mae: 0.785200, mean_q: 0.965728, mean_eps: 0.708810\n",
      " 324539/500000: episode: 470, duration: 17.012s, episode steps: 635, steps per second:  37, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.010122, mae: 0.771915, mean_q: 0.947286, mean_eps: 0.708202\n",
      " 325304/500000: episode: 471, duration: 20.624s, episode steps: 765, steps per second:  37, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.010954, mae: 0.781329, mean_q: 0.959880, mean_eps: 0.707572\n",
      " 325693/500000: episode: 472, duration: 10.424s, episode steps: 389, steps per second:  37, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.011544, mae: 0.776949, mean_q: 0.951740, mean_eps: 0.707052\n",
      " 326135/500000: episode: 473, duration: 11.818s, episode steps: 442, steps per second:  37, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.010926, mae: 0.804029, mean_q: 0.986334, mean_eps: 0.706677\n",
      " 326754/500000: episode: 474, duration: 16.827s, episode steps: 619, steps per second:  37, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.010838, mae: 0.776715, mean_q: 0.951998, mean_eps: 0.706200\n",
      " 327397/500000: episode: 475, duration: 17.983s, episode steps: 643, steps per second:  36, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.010385, mae: 0.793782, mean_q: 0.976103, mean_eps: 0.705632\n",
      " 327950/500000: episode: 476, duration: 15.067s, episode steps: 553, steps per second:  37, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.010439, mae: 0.782641, mean_q: 0.960447, mean_eps: 0.705093\n",
      " 328451/500000: episode: 477, duration: 13.919s, episode steps: 501, steps per second:  36, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.011343, mae: 0.781504, mean_q: 0.958059, mean_eps: 0.704620\n",
      " 329398/500000: episode: 478, duration: 25.500s, episode steps: 947, steps per second:  37, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.011369, mae: 0.792374, mean_q: 0.972562, mean_eps: 0.703968\n",
      " 330254/500000: episode: 479, duration: 24.130s, episode steps: 856, steps per second:  35, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.011308, mae: 0.787272, mean_q: 0.965658, mean_eps: 0.703157\n",
      " 331018/500000: episode: 480, duration: 31.505s, episode steps: 764, steps per second:  24, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.011409, mae: 0.819490, mean_q: 1.005288, mean_eps: 0.702428\n",
      " 331986/500000: episode: 481, duration: 25.358s, episode steps: 968, steps per second:  38, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.010777, mae: 0.810873, mean_q: 0.995233, mean_eps: 0.701648\n",
      " 333134/500000: episode: 482, duration: 31.033s, episode steps: 1148, steps per second:  37, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.011447, mae: 0.816975, mean_q: 1.003117, mean_eps: 0.700696\n",
      " 333548/500000: episode: 483, duration: 10.939s, episode steps: 414, steps per second:  38, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.012427, mae: 0.818035, mean_q: 1.001869, mean_eps: 0.699994\n",
      " 334162/500000: episode: 484, duration: 16.126s, episode steps: 614, steps per second:  38, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.010683, mae: 0.834736, mean_q: 1.025415, mean_eps: 0.699531\n",
      " 334882/500000: episode: 485, duration: 19.078s, episode steps: 720, steps per second:  38, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.009904, mae: 0.800006, mean_q: 0.982078, mean_eps: 0.698930\n",
      " 335405/500000: episode: 486, duration: 13.710s, episode steps: 523, steps per second:  38, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.010804, mae: 0.808445, mean_q: 0.991075, mean_eps: 0.698370\n",
      " 335790/500000: episode: 487, duration: 10.025s, episode steps: 385, steps per second:  38, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.010541, mae: 0.829722, mean_q: 1.015196, mean_eps: 0.697962\n",
      " 336587/500000: episode: 488, duration: 20.766s, episode steps: 797, steps per second:  38, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.010298, mae: 0.819306, mean_q: 1.004698, mean_eps: 0.697431\n",
      " 337140/500000: episode: 489, duration: 14.453s, episode steps: 553, steps per second:  38, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.011745, mae: 0.819047, mean_q: 1.003140, mean_eps: 0.696824\n",
      " 337830/500000: episode: 490, duration: 18.088s, episode steps: 690, steps per second:  38, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.010401, mae: 0.815042, mean_q: 0.997135, mean_eps: 0.696264\n",
      " 338605/500000: episode: 491, duration: 20.489s, episode steps: 775, steps per second:  38, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.011632, mae: 0.807380, mean_q: 0.988865, mean_eps: 0.695604\n",
      " 339042/500000: episode: 492, duration: 11.729s, episode steps: 437, steps per second:  37, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.010805, mae: 0.806091, mean_q: 0.987484, mean_eps: 0.695058\n",
      " 339702/500000: episode: 493, duration: 17.593s, episode steps: 660, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.010492, mae: 0.809967, mean_q: 0.992509, mean_eps: 0.694565\n",
      " 340320/500000: episode: 494, duration: 16.619s, episode steps: 618, steps per second:  37, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.009283, mae: 0.835165, mean_q: 1.025380, mean_eps: 0.693991\n",
      " 340763/500000: episode: 495, duration: 11.784s, episode steps: 443, steps per second:  38, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.010149, mae: 0.849635, mean_q: 1.045102, mean_eps: 0.693514\n",
      " 341290/500000: episode: 496, duration: 14.130s, episode steps: 527, steps per second:  37, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.011063, mae: 0.844456, mean_q: 1.038542, mean_eps: 0.693077\n",
      " 341678/500000: episode: 497, duration: 10.387s, episode steps: 388, steps per second:  37, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.010832, mae: 0.855917, mean_q: 1.050145, mean_eps: 0.692664\n",
      " 342165/500000: episode: 498, duration: 13.396s, episode steps: 487, steps per second:  36, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.009994, mae: 0.835954, mean_q: 1.027181, mean_eps: 0.692270\n",
      " 342833/500000: episode: 499, duration: 18.098s, episode steps: 668, steps per second:  37, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.011345, mae: 0.845516, mean_q: 1.040290, mean_eps: 0.691750\n",
      " 343288/500000: episode: 500, duration: 12.639s, episode steps: 455, steps per second:  36, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.010547, mae: 0.843536, mean_q: 1.037521, mean_eps: 0.691246\n",
      " 343724/500000: episode: 501, duration: 12.490s, episode steps: 436, steps per second:  35, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.011816, mae: 0.854179, mean_q: 1.052727, mean_eps: 0.690846\n",
      " 344776/500000: episode: 502, duration: 29.648s, episode steps: 1052, steps per second:  35, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.011135, mae: 0.845348, mean_q: 1.038428, mean_eps: 0.690177\n",
      " 345426/500000: episode: 503, duration: 17.559s, episode steps: 650, steps per second:  37, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.011313, mae: 0.838603, mean_q: 1.029940, mean_eps: 0.689410\n",
      " 345943/500000: episode: 504, duration: 27.593s, episode steps: 517, steps per second:  19, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.011607, mae: 0.848607, mean_q: 1.042716, mean_eps: 0.688884\n",
      " 346606/500000: episode: 505, duration: 42.427s, episode steps: 663, steps per second:  16, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.011989, mae: 0.855804, mean_q: 1.051742, mean_eps: 0.688353\n",
      " 347210/500000: episode: 506, duration: 19.983s, episode steps: 604, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.012151, mae: 0.847664, mean_q: 1.041544, mean_eps: 0.687783\n",
      " 347605/500000: episode: 507, duration: 10.513s, episode steps: 395, steps per second:  38, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.011021, mae: 0.845205, mean_q: 1.036660, mean_eps: 0.687333\n",
      " 348382/500000: episode: 508, duration: 20.476s, episode steps: 777, steps per second:  38, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.009618, mae: 0.855153, mean_q: 1.050248, mean_eps: 0.686805\n",
      " 349071/500000: episode: 509, duration: 18.223s, episode steps: 689, steps per second:  38, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.012246, mae: 0.849762, mean_q: 1.045027, mean_eps: 0.686147\n",
      " 349814/500000: episode: 510, duration: 19.507s, episode steps: 743, steps per second:  38, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.011236, mae: 0.844835, mean_q: 1.038284, mean_eps: 0.685502\n",
      " 350557/500000: episode: 511, duration: 19.743s, episode steps: 743, steps per second:  38, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.010509, mae: 0.869475, mean_q: 1.068900, mean_eps: 0.684833\n",
      " 351198/500000: episode: 512, duration: 18.286s, episode steps: 641, steps per second:  35, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.011177, mae: 0.889415, mean_q: 1.094102, mean_eps: 0.684210\n",
      " 351734/500000: episode: 513, duration: 14.412s, episode steps: 536, steps per second:  37, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.011503, mae: 0.890025, mean_q: 1.093227, mean_eps: 0.683681\n",
      " 352791/500000: episode: 514, duration: 28.624s, episode steps: 1057, steps per second:  37, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.011084, mae: 0.891867, mean_q: 1.096361, mean_eps: 0.682964\n",
      " 353567/500000: episode: 515, duration: 20.988s, episode steps: 776, steps per second:  37, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.010210, mae: 0.872319, mean_q: 1.069104, mean_eps: 0.682140\n",
      " 354223/500000: episode: 516, duration: 17.475s, episode steps: 656, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.011347, mae: 0.888437, mean_q: 1.089459, mean_eps: 0.681495\n",
      " 355278/500000: episode: 517, duration: 28.252s, episode steps: 1055, steps per second:  37, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.011326, mae: 0.880046, mean_q: 1.078407, mean_eps: 0.680725\n",
      " 356001/500000: episode: 518, duration: 19.424s, episode steps: 723, steps per second:  37, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.011300, mae: 0.899436, mean_q: 1.103104, mean_eps: 0.679924\n",
      " 356382/500000: episode: 519, duration: 10.379s, episode steps: 381, steps per second:  37, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.010707, mae: 0.895873, mean_q: 1.096155, mean_eps: 0.679427\n",
      " 356920/500000: episode: 520, duration: 14.996s, episode steps: 538, steps per second:  36, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.010541, mae: 0.882533, mean_q: 1.081949, mean_eps: 0.679015\n",
      " 357491/500000: episode: 521, duration: 15.187s, episode steps: 571, steps per second:  38, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.011750, mae: 0.900586, mean_q: 1.106611, mean_eps: 0.678516\n",
      " 357929/500000: episode: 522, duration: 11.517s, episode steps: 438, steps per second:  38, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.011614, mae: 0.884280, mean_q: 1.083516, mean_eps: 0.678061\n",
      " 358433/500000: episode: 523, duration: 13.167s, episode steps: 504, steps per second:  38, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.010646, mae: 0.875160, mean_q: 1.072858, mean_eps: 0.677636\n",
      " 359131/500000: episode: 524, duration: 18.320s, episode steps: 698, steps per second:  38, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.012485, mae: 0.892339, mean_q: 1.094523, mean_eps: 0.677096\n",
      " 359762/500000: episode: 525, duration: 17.167s, episode steps: 631, steps per second:  37, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.011363, mae: 0.892365, mean_q: 1.092828, mean_eps: 0.676499\n",
      " 360526/500000: episode: 526, duration: 20.548s, episode steps: 764, steps per second:  37, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.009757, mae: 0.887569, mean_q: 1.088507, mean_eps: 0.675870\n",
      " 361389/500000: episode: 527, duration: 23.781s, episode steps: 863, steps per second:  36, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.011530, mae: 0.919570, mean_q: 1.128346, mean_eps: 0.675138\n",
      " 362036/500000: episode: 528, duration: 18.203s, episode steps: 647, steps per second:  36, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.011866, mae: 0.921113, mean_q: 1.131797, mean_eps: 0.674459\n",
      " 362470/500000: episode: 529, duration: 12.254s, episode steps: 434, steps per second:  35, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.013961, mae: 0.920711, mean_q: 1.131318, mean_eps: 0.673973\n",
      " 363213/500000: episode: 530, duration: 20.424s, episode steps: 743, steps per second:  36, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.012676, mae: 0.908172, mean_q: 1.116554, mean_eps: 0.673442\n",
      " 363817/500000: episode: 531, duration: 32.667s, episode steps: 604, steps per second:  18, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.011779, mae: 0.910749, mean_q: 1.117019, mean_eps: 0.672836\n",
      " 364674/500000: episode: 532, duration: 34.699s, episode steps: 857, steps per second:  25, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.013166, mae: 0.924756, mean_q: 1.135448, mean_eps: 0.672179\n",
      " 365385/500000: episode: 533, duration: 19.877s, episode steps: 711, steps per second:  36, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.011999, mae: 0.921896, mean_q: 1.132101, mean_eps: 0.671473\n",
      " 365865/500000: episode: 534, duration: 12.925s, episode steps: 480, steps per second:  37, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.011122, mae: 0.922361, mean_q: 1.128615, mean_eps: 0.670937\n",
      " 366601/500000: episode: 535, duration: 20.353s, episode steps: 736, steps per second:  36, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.012660, mae: 0.919771, mean_q: 1.128347, mean_eps: 0.670389\n",
      " 367232/500000: episode: 536, duration: 17.050s, episode steps: 631, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.011475, mae: 0.904825, mean_q: 1.108880, mean_eps: 0.669776\n",
      " 367934/500000: episode: 537, duration: 19.366s, episode steps: 702, steps per second:  36, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.010967, mae: 0.920334, mean_q: 1.129027, mean_eps: 0.669176\n",
      " 368600/500000: episode: 538, duration: 18.866s, episode steps: 666, steps per second:  35, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.012295, mae: 0.918408, mean_q: 1.124606, mean_eps: 0.668561\n",
      " 369089/500000: episode: 539, duration: 13.080s, episode steps: 489, steps per second:  37, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.012684, mae: 0.899973, mean_q: 1.103158, mean_eps: 0.668040\n",
      " 369645/500000: episode: 540, duration: 14.663s, episode steps: 556, steps per second:  38, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.013214, mae: 0.937097, mean_q: 1.147906, mean_eps: 0.667569\n",
      " 370403/500000: episode: 541, duration: 19.947s, episode steps: 758, steps per second:  38, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.010772, mae: 0.917831, mean_q: 1.124158, mean_eps: 0.666978\n",
      " 371042/500000: episode: 542, duration: 17.017s, episode steps: 639, steps per second:  38, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.012292, mae: 0.928683, mean_q: 1.139271, mean_eps: 0.666350\n",
      " 371664/500000: episode: 543, duration: 16.382s, episode steps: 622, steps per second:  38, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.012307, mae: 0.922306, mean_q: 1.133322, mean_eps: 0.665783\n",
      " 372464/500000: episode: 544, duration: 21.343s, episode steps: 800, steps per second:  37, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.011875, mae: 0.937092, mean_q: 1.150479, mean_eps: 0.665144\n",
      " 373271/500000: episode: 545, duration: 21.198s, episode steps: 807, steps per second:  38, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.012408, mae: 0.936239, mean_q: 1.153470, mean_eps: 0.664421\n",
      " 373663/500000: episode: 546, duration: 10.232s, episode steps: 392, steps per second:  38, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.740 [0.000, 5.000],  loss: 0.011479, mae: 0.936026, mean_q: 1.152498, mean_eps: 0.663881\n",
      " 374380/500000: episode: 547, duration: 18.946s, episode steps: 717, steps per second:  38, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.012209, mae: 0.939535, mean_q: 1.153725, mean_eps: 0.663382\n",
      " 375111/500000: episode: 548, duration: 19.419s, episode steps: 731, steps per second:  38, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.011686, mae: 0.927037, mean_q: 1.136393, mean_eps: 0.662730\n",
      " 375730/500000: episode: 549, duration: 16.532s, episode steps: 619, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.011377, mae: 0.930458, mean_q: 1.141550, mean_eps: 0.662122\n",
      " 376803/500000: episode: 550, duration: 28.381s, episode steps: 1073, steps per second:  38, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.012536, mae: 0.939197, mean_q: 1.154484, mean_eps: 0.661361\n",
      " 377423/500000: episode: 551, duration: 16.413s, episode steps: 620, steps per second:  38, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.011407, mae: 0.943513, mean_q: 1.157600, mean_eps: 0.660599\n",
      " 378032/500000: episode: 552, duration: 16.623s, episode steps: 609, steps per second:  37, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.011176, mae: 0.927467, mean_q: 1.138023, mean_eps: 0.660047\n",
      " 378520/500000: episode: 553, duration: 13.162s, episode steps: 488, steps per second:  37, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.011505, mae: 0.929766, mean_q: 1.140428, mean_eps: 0.659553\n",
      " 379210/500000: episode: 554, duration: 19.371s, episode steps: 690, steps per second:  36, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.011445, mae: 0.939098, mean_q: 1.150212, mean_eps: 0.659022\n",
      " 380184/500000: episode: 555, duration: 29.075s, episode steps: 974, steps per second:  33, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.010776, mae: 0.928029, mean_q: 1.139025, mean_eps: 0.658274\n",
      " 380765/500000: episode: 556, duration: 16.351s, episode steps: 581, steps per second:  36, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.012351, mae: 0.974124, mean_q: 1.194650, mean_eps: 0.657573\n",
      " 381439/500000: episode: 557, duration: 17.981s, episode steps: 674, steps per second:  37, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.011119, mae: 0.966208, mean_q: 1.185139, mean_eps: 0.657008\n",
      " 382052/500000: episode: 558, duration: 16.975s, episode steps: 613, steps per second:  36, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.700 [0.000, 5.000],  loss: 0.011617, mae: 0.967030, mean_q: 1.185957, mean_eps: 0.656430\n",
      " 382670/500000: episode: 559, duration: 16.611s, episode steps: 618, steps per second:  37, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.012673, mae: 0.987611, mean_q: 1.210200, mean_eps: 0.655876\n",
      " 383348/500000: episode: 560, duration: 18.841s, episode steps: 678, steps per second:  36, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.011637, mae: 0.960428, mean_q: 1.179981, mean_eps: 0.655293\n",
      " 384072/500000: episode: 561, duration: 19.945s, episode steps: 724, steps per second:  36, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.235 [0.000, 5.000],  loss: 0.011623, mae: 0.958998, mean_q: 1.178545, mean_eps: 0.654663\n",
      " 384778/500000: episode: 562, duration: 19.579s, episode steps: 706, steps per second:  36, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.014339, mae: 0.972550, mean_q: 1.191983, mean_eps: 0.654018\n",
      " 385460/500000: episode: 563, duration: 20.235s, episode steps: 682, steps per second:  34, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.011007, mae: 0.951263, mean_q: 1.166463, mean_eps: 0.653394\n",
      " 385859/500000: episode: 564, duration: 10.715s, episode steps: 399, steps per second:  37, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.012364, mae: 0.960272, mean_q: 1.179017, mean_eps: 0.652908\n",
      " 386557/500000: episode: 565, duration: 18.486s, episode steps: 698, steps per second:  38, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.011914, mae: 0.967207, mean_q: 1.187248, mean_eps: 0.652413\n",
      " 387098/500000: episode: 566, duration: 15.097s, episode steps: 541, steps per second:  36, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.010864, mae: 0.949995, mean_q: 1.166274, mean_eps: 0.651855\n",
      " 387782/500000: episode: 567, duration: 19.463s, episode steps: 684, steps per second:  35, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.011878, mae: 0.968000, mean_q: 1.188302, mean_eps: 0.651304\n",
      " 388193/500000: episode: 568, duration: 18.875s, episode steps: 411, steps per second:  22, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.012225, mae: 0.969746, mean_q: 1.189934, mean_eps: 0.650811\n",
      " 388890/500000: episode: 569, duration: 18.428s, episode steps: 697, steps per second:  38, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.012776, mae: 0.969195, mean_q: 1.188720, mean_eps: 0.650312\n",
      " 389862/500000: episode: 570, duration: 26.112s, episode steps: 972, steps per second:  37, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.012608, mae: 0.964093, mean_q: 1.181691, mean_eps: 0.649562\n",
      " 390573/500000: episode: 571, duration: 18.906s, episode steps: 711, steps per second:  38, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.011302, mae: 1.008119, mean_q: 1.237806, mean_eps: 0.648804\n",
      " 391205/500000: episode: 572, duration: 16.756s, episode steps: 632, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.012421, mae: 1.035391, mean_q: 1.272222, mean_eps: 0.648199\n",
      " 392077/500000: episode: 573, duration: 23.516s, episode steps: 872, steps per second:  37, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.012979, mae: 1.016293, mean_q: 1.246437, mean_eps: 0.647522\n",
      " 392723/500000: episode: 574, duration: 17.475s, episode steps: 646, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.013043, mae: 1.032868, mean_q: 1.267403, mean_eps: 0.646840\n",
      " 393540/500000: episode: 575, duration: 32.168s, episode steps: 817, steps per second:  25, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.012427, mae: 1.019399, mean_q: 1.248565, mean_eps: 0.646183\n",
      " 394179/500000: episode: 576, duration: 17.006s, episode steps: 639, steps per second:  38, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.011962, mae: 1.003016, mean_q: 1.227637, mean_eps: 0.645528\n",
      " 394766/500000: episode: 577, duration: 15.718s, episode steps: 587, steps per second:  37, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.011991, mae: 1.006163, mean_q: 1.231622, mean_eps: 0.644975\n",
      " 395213/500000: episode: 578, duration: 11.960s, episode steps: 447, steps per second:  37, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.013748, mae: 1.014749, mean_q: 1.242320, mean_eps: 0.644509\n",
      " 396014/500000: episode: 579, duration: 21.447s, episode steps: 801, steps per second:  37, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.013167, mae: 1.020224, mean_q: 1.249170, mean_eps: 0.643947\n",
      " 396628/500000: episode: 580, duration: 16.303s, episode steps: 614, steps per second:  38, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.013262, mae: 1.022848, mean_q: 1.253509, mean_eps: 0.643312\n",
      " 397325/500000: episode: 581, duration: 18.827s, episode steps: 697, steps per second:  37, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.011153, mae: 1.011603, mean_q: 1.240819, mean_eps: 0.642722\n",
      " 398297/500000: episode: 582, duration: 27.166s, episode steps: 972, steps per second:  36, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.012831, mae: 1.026982, mean_q: 1.259361, mean_eps: 0.641969\n",
      " 398990/500000: episode: 583, duration: 19.080s, episode steps: 693, steps per second:  36, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.012169, mae: 1.014557, mean_q: 1.242842, mean_eps: 0.641220\n",
      " 399647/500000: episode: 584, duration: 21.060s, episode steps: 657, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.012504, mae: 1.024381, mean_q: 1.254332, mean_eps: 0.640614\n",
      " 400366/500000: episode: 585, duration: 29.424s, episode steps: 719, steps per second:  24, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.013219, mae: 1.037795, mean_q: 1.272741, mean_eps: 0.639995\n",
      " 400865/500000: episode: 586, duration: 17.724s, episode steps: 499, steps per second:  28, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.009358, mae: 1.042180, mean_q: 1.276546, mean_eps: 0.639446\n",
      " 401379/500000: episode: 587, duration: 14.699s, episode steps: 514, steps per second:  35, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.013498, mae: 1.048908, mean_q: 1.283553, mean_eps: 0.638990\n",
      " 402104/500000: episode: 588, duration: 19.677s, episode steps: 725, steps per second:  37, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.012554, mae: 1.060246, mean_q: 1.300515, mean_eps: 0.638434\n",
      " 402730/500000: episode: 589, duration: 17.220s, episode steps: 626, steps per second:  36, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.012673, mae: 1.045308, mean_q: 1.282122, mean_eps: 0.637826\n",
      " 403470/500000: episode: 590, duration: 20.867s, episode steps: 740, steps per second:  35, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.012638, mae: 1.050801, mean_q: 1.287255, mean_eps: 0.637210\n",
      " 404023/500000: episode: 591, duration: 15.869s, episode steps: 553, steps per second:  35, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.012771, mae: 1.053631, mean_q: 1.294046, mean_eps: 0.636629\n",
      " 404835/500000: episode: 592, duration: 22.226s, episode steps: 812, steps per second:  37, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: 0.011829, mae: 1.047553, mean_q: 1.283647, mean_eps: 0.636015\n",
      " 405499/500000: episode: 593, duration: 18.929s, episode steps: 664, steps per second:  35, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.242 [0.000, 5.000],  loss: 0.011039, mae: 1.053089, mean_q: 1.292692, mean_eps: 0.635351\n",
      " 405874/500000: episode: 594, duration: 11.190s, episode steps: 375, steps per second:  34, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.012139, mae: 1.039476, mean_q: 1.274571, mean_eps: 0.634883\n",
      " 406291/500000: episode: 595, duration: 11.999s, episode steps: 417, steps per second:  35, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.013885, mae: 1.045370, mean_q: 1.280862, mean_eps: 0.634526\n",
      " 406918/500000: episode: 596, duration: 17.015s, episode steps: 627, steps per second:  37, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.013702, mae: 1.068296, mean_q: 1.309852, mean_eps: 0.634056\n",
      " 407511/500000: episode: 597, duration: 29.001s, episode steps: 593, steps per second:  20, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.011953, mae: 1.060099, mean_q: 1.298034, mean_eps: 0.633507\n",
      " 407992/500000: episode: 598, duration: 23.973s, episode steps: 481, steps per second:  20, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.012014, mae: 1.043917, mean_q: 1.279141, mean_eps: 0.633025\n",
      " 408735/500000: episode: 599, duration: 27.272s, episode steps: 743, steps per second:  27, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.012426, mae: 1.057042, mean_q: 1.295223, mean_eps: 0.632474\n",
      " 409228/500000: episode: 600, duration: 13.682s, episode steps: 493, steps per second:  36, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.011338, mae: 1.047667, mean_q: 1.283179, mean_eps: 0.631918\n",
      " 409743/500000: episode: 601, duration: 13.699s, episode steps: 515, steps per second:  38, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.010951, mae: 1.052302, mean_q: 1.288285, mean_eps: 0.631464\n",
      " 410428/500000: episode: 602, duration: 18.354s, episode steps: 685, steps per second:  37, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.013570, mae: 1.094904, mean_q: 1.340706, mean_eps: 0.630924\n",
      " 410952/500000: episode: 603, duration: 13.872s, episode steps: 524, steps per second:  38, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.013017, mae: 1.104812, mean_q: 1.355146, mean_eps: 0.630381\n",
      " 411892/500000: episode: 604, duration: 24.811s, episode steps: 940, steps per second:  38, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.012500, mae: 1.104065, mean_q: 1.350355, mean_eps: 0.629722\n",
      " 412565/500000: episode: 605, duration: 17.734s, episode steps: 673, steps per second:  38, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.011588, mae: 1.096696, mean_q: 1.340608, mean_eps: 0.628995\n",
      " 413313/500000: episode: 606, duration: 19.745s, episode steps: 748, steps per second:  38, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.013058, mae: 1.104848, mean_q: 1.352094, mean_eps: 0.628354\n",
      " 413961/500000: episode: 607, duration: 17.021s, episode steps: 648, steps per second:  38, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.013338, mae: 1.111933, mean_q: 1.361400, mean_eps: 0.627726\n",
      " 414395/500000: episode: 608, duration: 11.384s, episode steps: 434, steps per second:  38, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.012238, mae: 1.086023, mean_q: 1.329844, mean_eps: 0.627240\n",
      " 415104/500000: episode: 609, duration: 18.934s, episode steps: 709, steps per second:  37, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.012850, mae: 1.096460, mean_q: 1.342960, mean_eps: 0.626727\n",
      " 416073/500000: episode: 610, duration: 25.809s, episode steps: 969, steps per second:  38, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.011852, mae: 1.098235, mean_q: 1.346718, mean_eps: 0.625971\n",
      " 416684/500000: episode: 611, duration: 16.230s, episode steps: 611, steps per second:  38, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.012711, mae: 1.096012, mean_q: 1.343618, mean_eps: 0.625260\n",
      " 417330/500000: episode: 612, duration: 17.247s, episode steps: 646, steps per second:  37, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.011517, mae: 1.086325, mean_q: 1.330642, mean_eps: 0.624695\n",
      " 418133/500000: episode: 613, duration: 21.405s, episode steps: 803, steps per second:  38, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.011362, mae: 1.100044, mean_q: 1.347775, mean_eps: 0.624041\n",
      " 418646/500000: episode: 614, duration: 13.760s, episode steps: 513, steps per second:  37, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.013061, mae: 1.120243, mean_q: 1.371878, mean_eps: 0.623449\n",
      " 419276/500000: episode: 615, duration: 16.992s, episode steps: 630, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.012238, mae: 1.097531, mean_q: 1.341512, mean_eps: 0.622936\n",
      " 419997/500000: episode: 616, duration: 19.360s, episode steps: 721, steps per second:  37, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.013729, mae: 1.099165, mean_q: 1.347255, mean_eps: 0.622328\n",
      " 420552/500000: episode: 617, duration: 14.967s, episode steps: 555, steps per second:  37, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.013567, mae: 1.158904, mean_q: 1.420854, mean_eps: 0.621753\n",
      " 421461/500000: episode: 618, duration: 24.301s, episode steps: 909, steps per second:  37, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.012514, mae: 1.157932, mean_q: 1.420534, mean_eps: 0.621095\n",
      " 422008/500000: episode: 619, duration: 14.813s, episode steps: 547, steps per second:  37, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.012120, mae: 1.148520, mean_q: 1.407084, mean_eps: 0.620439\n",
      " 422805/500000: episode: 620, duration: 22.627s, episode steps: 797, steps per second:  35, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.012527, mae: 1.143843, mean_q: 1.400718, mean_eps: 0.619835\n",
      " 423455/500000: episode: 621, duration: 18.405s, episode steps: 650, steps per second:  35, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.013658, mae: 1.153406, mean_q: 1.411504, mean_eps: 0.619183\n",
      " 424071/500000: episode: 622, duration: 17.749s, episode steps: 616, steps per second:  35, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.012175, mae: 1.150919, mean_q: 1.409813, mean_eps: 0.618614\n",
      " 425396/500000: episode: 623, duration: 38.330s, episode steps: 1325, steps per second:  35, episode reward: 26.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.012912, mae: 1.146509, mean_q: 1.403122, mean_eps: 0.617741\n",
      " 426043/500000: episode: 624, duration: 17.821s, episode steps: 647, steps per second:  36, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.012660, mae: 1.148505, mean_q: 1.406573, mean_eps: 0.616854\n",
      " 426544/500000: episode: 625, duration: 13.604s, episode steps: 501, steps per second:  37, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.012173, mae: 1.159028, mean_q: 1.421205, mean_eps: 0.616337\n",
      " 427378/500000: episode: 626, duration: 22.717s, episode steps: 834, steps per second:  37, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.012510, mae: 1.159010, mean_q: 1.416973, mean_eps: 0.615736\n",
      " 428077/500000: episode: 627, duration: 19.030s, episode steps: 699, steps per second:  37, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.012901, mae: 1.165376, mean_q: 1.422369, mean_eps: 0.615045\n",
      " 429432/500000: episode: 628, duration: 37.193s, episode steps: 1355, steps per second:  36, episode reward: 24.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.012403, mae: 1.137729, mean_q: 1.391376, mean_eps: 0.614121\n",
      " 429969/500000: episode: 629, duration: 14.911s, episode steps: 537, steps per second:  36, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.013163, mae: 1.155618, mean_q: 1.413541, mean_eps: 0.613270\n",
      " 430620/500000: episode: 630, duration: 17.710s, episode steps: 651, steps per second:  37, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.013427, mae: 1.203415, mean_q: 1.473301, mean_eps: 0.612735\n",
      " 431116/500000: episode: 631, duration: 13.581s, episode steps: 496, steps per second:  37, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.014069, mae: 1.178599, mean_q: 1.441528, mean_eps: 0.612221\n",
      " 431678/500000: episode: 632, duration: 15.250s, episode steps: 562, steps per second:  37, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.014798, mae: 1.194464, mean_q: 1.457849, mean_eps: 0.611744\n",
      " 432226/500000: episode: 633, duration: 14.760s, episode steps: 548, steps per second:  37, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.012501, mae: 1.195572, mean_q: 1.463443, mean_eps: 0.611243\n",
      " 433043/500000: episode: 634, duration: 21.974s, episode steps: 817, steps per second:  37, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.011956, mae: 1.186419, mean_q: 1.450965, mean_eps: 0.610629\n",
      " 434133/500000: episode: 635, duration: 29.206s, episode steps: 1090, steps per second:  37, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.013345, mae: 1.195839, mean_q: 1.462619, mean_eps: 0.609771\n",
      " 434833/500000: episode: 636, duration: 19.178s, episode steps: 700, steps per second:  36, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.013621, mae: 1.191734, mean_q: 1.458690, mean_eps: 0.608964\n",
      " 435428/500000: episode: 637, duration: 16.230s, episode steps: 595, steps per second:  37, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.012956, mae: 1.188441, mean_q: 1.453881, mean_eps: 0.608383\n",
      " 436192/500000: episode: 638, duration: 20.832s, episode steps: 764, steps per second:  37, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.012982, mae: 1.187155, mean_q: 1.451715, mean_eps: 0.607773\n",
      " 436619/500000: episode: 639, duration: 11.652s, episode steps: 427, steps per second:  37, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.013976, mae: 1.204100, mean_q: 1.471154, mean_eps: 0.607236\n",
      " 437302/500000: episode: 640, duration: 18.676s, episode steps: 683, steps per second:  37, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.129 [0.000, 5.000],  loss: 0.014099, mae: 1.203858, mean_q: 1.472216, mean_eps: 0.606736\n",
      " 437967/500000: episode: 641, duration: 17.907s, episode steps: 665, steps per second:  37, episode reward: 17.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.014874, mae: 1.200757, mean_q: 1.470508, mean_eps: 0.606129\n",
      " 439151/500000: episode: 642, duration: 32.395s, episode steps: 1184, steps per second:  37, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.013130, mae: 1.205521, mean_q: 1.477441, mean_eps: 0.605298\n",
      " 439750/500000: episode: 643, duration: 16.444s, episode steps: 599, steps per second:  36, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.012997, mae: 1.210195, mean_q: 1.481154, mean_eps: 0.604495\n",
      " 441013/500000: episode: 644, duration: 34.416s, episode steps: 1263, steps per second:  37, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.013142, mae: 1.234474, mean_q: 1.509641, mean_eps: 0.603656\n",
      " 441377/500000: episode: 645, duration: 10.015s, episode steps: 364, steps per second:  36, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.016311, mae: 1.266262, mean_q: 1.547969, mean_eps: 0.602924\n",
      " 442048/500000: episode: 646, duration: 18.474s, episode steps: 671, steps per second:  36, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.012401, mae: 1.233454, mean_q: 1.508199, mean_eps: 0.602459\n",
      " 442702/500000: episode: 647, duration: 18.302s, episode steps: 654, steps per second:  36, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.014034, mae: 1.239138, mean_q: 1.511966, mean_eps: 0.601863\n",
      " 443499/500000: episode: 648, duration: 21.849s, episode steps: 797, steps per second:  36, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.013268, mae: 1.247574, mean_q: 1.522586, mean_eps: 0.601210\n",
      " 443986/500000: episode: 649, duration: 13.833s, episode steps: 487, steps per second:  35, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.012991, mae: 1.230495, mean_q: 1.502027, mean_eps: 0.600632\n",
      " 445019/500000: episode: 650, duration: 28.498s, episode steps: 1033, steps per second:  36, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.014381, mae: 1.243025, mean_q: 1.517063, mean_eps: 0.599948\n",
      " 445628/500000: episode: 651, duration: 16.624s, episode steps: 609, steps per second:  37, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.013246, mae: 1.234746, mean_q: 1.507301, mean_eps: 0.599210\n",
      " 446473/500000: episode: 652, duration: 23.963s, episode steps: 845, steps per second:  35, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.014376, mae: 1.252299, mean_q: 1.529509, mean_eps: 0.598555\n",
      " 447093/500000: episode: 653, duration: 16.959s, episode steps: 620, steps per second:  37, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.013877, mae: 1.254760, mean_q: 1.530867, mean_eps: 0.597894\n",
      " 447702/500000: episode: 654, duration: 16.524s, episode steps: 609, steps per second:  37, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.016071, mae: 1.246557, mean_q: 1.522787, mean_eps: 0.597342\n",
      " 448565/500000: episode: 655, duration: 24.161s, episode steps: 863, steps per second:  36, episode reward: 24.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.013481, mae: 1.233995, mean_q: 1.506526, mean_eps: 0.596679\n",
      " 449445/500000: episode: 656, duration: 23.885s, episode steps: 880, steps per second:  37, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.013856, mae: 1.234700, mean_q: 1.506239, mean_eps: 0.595895\n",
      " 450189/500000: episode: 657, duration: 20.150s, episode steps: 744, steps per second:  37, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.012961, mae: 1.222390, mean_q: 1.492683, mean_eps: 0.595164\n",
      " 450691/500000: episode: 658, duration: 13.382s, episode steps: 502, steps per second:  38, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.779 [0.000, 5.000],  loss: 0.012256, mae: 1.274317, mean_q: 1.556209, mean_eps: 0.594604\n",
      " 451362/500000: episode: 659, duration: 18.180s, episode steps: 671, steps per second:  37, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.203 [0.000, 5.000],  loss: 0.012904, mae: 1.254118, mean_q: 1.531160, mean_eps: 0.594077\n",
      " 452066/500000: episode: 660, duration: 19.217s, episode steps: 704, steps per second:  37, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.012417, mae: 1.263995, mean_q: 1.542328, mean_eps: 0.593457\n",
      " 452792/500000: episode: 661, duration: 20.642s, episode steps: 726, steps per second:  35, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.013228, mae: 1.245162, mean_q: 1.518139, mean_eps: 0.592815\n",
      " 453351/500000: episode: 662, duration: 15.262s, episode steps: 559, steps per second:  37, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.013096, mae: 1.264059, mean_q: 1.543101, mean_eps: 0.592237\n",
      " 454014/500000: episode: 663, duration: 18.113s, episode steps: 663, steps per second:  37, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.013931, mae: 1.269714, mean_q: 1.550163, mean_eps: 0.591686\n",
      " 454847/500000: episode: 664, duration: 22.827s, episode steps: 833, steps per second:  36, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.013169, mae: 1.255710, mean_q: 1.533507, mean_eps: 0.591013\n",
      " 455553/500000: episode: 665, duration: 19.448s, episode steps: 706, steps per second:  36, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.013112, mae: 1.231661, mean_q: 1.502756, mean_eps: 0.590320\n",
      " 456207/500000: episode: 666, duration: 18.003s, episode steps: 654, steps per second:  36, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.013728, mae: 1.260995, mean_q: 1.535896, mean_eps: 0.589708\n",
      " 456761/500000: episode: 667, duration: 15.299s, episode steps: 554, steps per second:  36, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.843 [0.000, 5.000],  loss: 0.013287, mae: 1.267962, mean_q: 1.546789, mean_eps: 0.589164\n",
      " 457556/500000: episode: 668, duration: 21.715s, episode steps: 795, steps per second:  37, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.012705, mae: 1.246724, mean_q: 1.520116, mean_eps: 0.588558\n",
      " 458437/500000: episode: 669, duration: 24.408s, episode steps: 881, steps per second:  36, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.013595, mae: 1.268709, mean_q: 1.547396, mean_eps: 0.587804\n",
      " 458910/500000: episode: 670, duration: 13.061s, episode steps: 473, steps per second:  36, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.014614, mae: 1.252615, mean_q: 1.525199, mean_eps: 0.587193\n",
      " 459643/500000: episode: 671, duration: 19.948s, episode steps: 733, steps per second:  37, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.013229, mae: 1.252039, mean_q: 1.527202, mean_eps: 0.586652\n",
      " 460439/500000: episode: 672, duration: 21.958s, episode steps: 796, steps per second:  36, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.013789, mae: 1.270795, mean_q: 1.553726, mean_eps: 0.585964\n",
      " 461230/500000: episode: 673, duration: 21.750s, episode steps: 791, steps per second:  36, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.013812, mae: 1.288020, mean_q: 1.574271, mean_eps: 0.585249\n",
      " 461944/500000: episode: 674, duration: 19.513s, episode steps: 714, steps per second:  37, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.012874, mae: 1.294685, mean_q: 1.581322, mean_eps: 0.584573\n",
      " 463132/500000: episode: 675, duration: 32.610s, episode steps: 1188, steps per second:  36, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.015211, mae: 1.278742, mean_q: 1.561580, mean_eps: 0.583718\n",
      " 463654/500000: episode: 676, duration: 14.343s, episode steps: 522, steps per second:  36, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.014365, mae: 1.284962, mean_q: 1.569723, mean_eps: 0.582947\n",
      " 464293/500000: episode: 677, duration: 17.795s, episode steps: 639, steps per second:  36, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: 0.015183, mae: 1.284854, mean_q: 1.567696, mean_eps: 0.582423\n",
      " 464803/500000: episode: 678, duration: 14.271s, episode steps: 510, steps per second:  36, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.014091, mae: 1.284604, mean_q: 1.566805, mean_eps: 0.581907\n",
      " 465313/500000: episode: 679, duration: 14.162s, episode steps: 510, steps per second:  36, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.014874, mae: 1.281988, mean_q: 1.564473, mean_eps: 0.581448\n",
      " 466004/500000: episode: 680, duration: 19.285s, episode steps: 691, steps per second:  36, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.014518, mae: 1.322251, mean_q: 1.612596, mean_eps: 0.580908\n",
      " 467008/500000: episode: 681, duration: 27.754s, episode steps: 1004, steps per second:  36, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.016049, mae: 1.302069, mean_q: 1.588841, mean_eps: 0.580146\n",
      " 467461/500000: episode: 682, duration: 12.371s, episode steps: 453, steps per second:  37, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.013635, mae: 1.292989, mean_q: 1.577337, mean_eps: 0.579489\n",
      " 467818/500000: episode: 683, duration: 9.625s, episode steps: 357, steps per second:  37, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.015411, mae: 1.297209, mean_q: 1.583166, mean_eps: 0.579124\n",
      " 468445/500000: episode: 684, duration: 16.960s, episode steps: 627, steps per second:  37, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.012610, mae: 1.287690, mean_q: 1.570205, mean_eps: 0.578681\n",
      " 468968/500000: episode: 685, duration: 14.196s, episode steps: 523, steps per second:  37, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.014896, mae: 1.285802, mean_q: 1.567596, mean_eps: 0.578165\n",
      " 469618/500000: episode: 686, duration: 17.565s, episode steps: 650, steps per second:  37, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.014782, mae: 1.301017, mean_q: 1.584964, mean_eps: 0.577637\n",
      " 470100/500000: episode: 687, duration: 13.209s, episode steps: 482, steps per second:  36, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.012045, mae: 1.290460, mean_q: 1.574461, mean_eps: 0.577128\n",
      " 470827/500000: episode: 688, duration: 20.164s, episode steps: 727, steps per second:  36, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.012877, mae: 1.334084, mean_q: 1.626102, mean_eps: 0.576584\n",
      " 471343/500000: episode: 689, duration: 14.389s, episode steps: 516, steps per second:  36, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.014199, mae: 1.343472, mean_q: 1.636165, mean_eps: 0.576024\n",
      " 471876/500000: episode: 690, duration: 14.557s, episode steps: 533, steps per second:  37, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.014199, mae: 1.346103, mean_q: 1.639281, mean_eps: 0.575553\n",
      " 472755/500000: episode: 691, duration: 24.207s, episode steps: 879, steps per second:  36, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.013254, mae: 1.333679, mean_q: 1.626140, mean_eps: 0.574917\n",
      " 473423/500000: episode: 692, duration: 18.672s, episode steps: 668, steps per second:  36, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.013202, mae: 1.318019, mean_q: 1.606397, mean_eps: 0.574221\n",
      " 474199/500000: episode: 693, duration: 21.576s, episode steps: 776, steps per second:  36, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.133 [0.000, 5.000],  loss: 0.012829, mae: 1.326738, mean_q: 1.617408, mean_eps: 0.573571\n",
      " 474973/500000: episode: 694, duration: 21.478s, episode steps: 774, steps per second:  36, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.013860, mae: 1.341912, mean_q: 1.635036, mean_eps: 0.572873\n",
      " 475728/500000: episode: 695, duration: 21.491s, episode steps: 755, steps per second:  35, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.013573, mae: 1.321427, mean_q: 1.612711, mean_eps: 0.572185\n",
      " 476296/500000: episode: 696, duration: 16.419s, episode steps: 568, steps per second:  35, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.012092, mae: 1.307431, mean_q: 1.595092, mean_eps: 0.571591\n",
      " 477162/500000: episode: 697, duration: 24.135s, episode steps: 866, steps per second:  36, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.014732, mae: 1.339291, mean_q: 1.633526, mean_eps: 0.570945\n",
      " 478174/500000: episode: 698, duration: 27.879s, episode steps: 1012, steps per second:  36, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.013530, mae: 1.320849, mean_q: 1.606874, mean_eps: 0.570099\n",
      " 479111/500000: episode: 699, duration: 26.046s, episode steps: 937, steps per second:  36, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.014555, mae: 1.337570, mean_q: 1.628294, mean_eps: 0.569222\n",
      " 479848/500000: episode: 700, duration: 21.101s, episode steps: 737, steps per second:  35, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.013978, mae: 1.332781, mean_q: 1.625513, mean_eps: 0.568470\n",
      " 480509/500000: episode: 701, duration: 19.227s, episode steps: 661, steps per second:  34, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.012352, mae: 1.344505, mean_q: 1.639664, mean_eps: 0.567840\n",
      " 480980/500000: episode: 702, duration: 13.504s, episode steps: 471, steps per second:  35, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.017055, mae: 1.347759, mean_q: 1.644083, mean_eps: 0.567330\n",
      " 481603/500000: episode: 703, duration: 17.834s, episode steps: 623, steps per second:  35, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.013694, mae: 1.359018, mean_q: 1.657360, mean_eps: 0.566839\n",
      " 482102/500000: episode: 704, duration: 14.035s, episode steps: 499, steps per second:  36, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.015885, mae: 1.374189, mean_q: 1.675518, mean_eps: 0.566333\n",
      " 483158/500000: episode: 705, duration: 28.647s, episode steps: 1056, steps per second:  37, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.014766, mae: 1.342988, mean_q: 1.636050, mean_eps: 0.565633\n",
      " 483945/500000: episode: 706, duration: 21.586s, episode steps: 787, steps per second:  36, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.013875, mae: 1.354750, mean_q: 1.651756, mean_eps: 0.564803\n",
      " 484477/500000: episode: 707, duration: 14.422s, episode steps: 532, steps per second:  37, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.013645, mae: 1.331721, mean_q: 1.623029, mean_eps: 0.564209\n",
      " 485298/500000: episode: 708, duration: 22.797s, episode steps: 821, steps per second:  36, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.013291, mae: 1.362278, mean_q: 1.660084, mean_eps: 0.563601\n",
      " 485863/500000: episode: 709, duration: 15.790s, episode steps: 565, steps per second:  36, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.013500, mae: 1.344340, mean_q: 1.638476, mean_eps: 0.562978\n",
      " 486824/500000: episode: 710, duration: 27.195s, episode steps: 961, steps per second:  35, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.014095, mae: 1.356070, mean_q: 1.652714, mean_eps: 0.562292\n",
      " 487281/500000: episode: 711, duration: 12.903s, episode steps: 457, steps per second:  35, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.013965, mae: 1.361854, mean_q: 1.657606, mean_eps: 0.561653\n",
      " 487906/500000: episode: 712, duration: 17.442s, episode steps: 625, steps per second:  36, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.013406, mae: 1.354747, mean_q: 1.649686, mean_eps: 0.561165\n",
      " 488669/500000: episode: 713, duration: 21.186s, episode steps: 763, steps per second:  36, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.013639, mae: 1.371152, mean_q: 1.673868, mean_eps: 0.560541\n",
      " 489232/500000: episode: 714, duration: 15.814s, episode steps: 563, steps per second:  36, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.020 [0.000, 5.000],  loss: 0.014115, mae: 1.371138, mean_q: 1.671094, mean_eps: 0.559945\n",
      " 490063/500000: episode: 715, duration: 23.214s, episode steps: 831, steps per second:  36, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.014219, mae: 1.352626, mean_q: 1.651393, mean_eps: 0.559319\n",
      " 490790/500000: episode: 716, duration: 20.635s, episode steps: 727, steps per second:  35, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.013125, mae: 1.371446, mean_q: 1.673740, mean_eps: 0.558617\n",
      " 491585/500000: episode: 717, duration: 22.689s, episode steps: 795, steps per second:  35, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.014073, mae: 1.362555, mean_q: 1.663678, mean_eps: 0.557931\n",
      " 492003/500000: episode: 718, duration: 11.692s, episode steps: 418, steps per second:  36, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.014071, mae: 1.382026, mean_q: 1.685596, mean_eps: 0.557385\n",
      " 492556/500000: episode: 719, duration: 15.746s, episode steps: 553, steps per second:  35, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.013173, mae: 1.377945, mean_q: 1.679809, mean_eps: 0.556950\n",
      " 493068/500000: episode: 720, duration: 14.570s, episode steps: 512, steps per second:  35, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.889 [0.000, 5.000],  loss: 0.013258, mae: 1.381665, mean_q: 1.684727, mean_eps: 0.556471\n",
      " 493921/500000: episode: 721, duration: 24.414s, episode steps: 853, steps per second:  35, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.013729, mae: 1.352917, mean_q: 1.647806, mean_eps: 0.555855\n",
      " 494462/500000: episode: 722, duration: 15.433s, episode steps: 541, steps per second:  35, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.012510, mae: 1.371087, mean_q: 1.672015, mean_eps: 0.555227\n",
      " 495073/500000: episode: 723, duration: 17.405s, episode steps: 611, steps per second:  35, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.012629, mae: 1.372178, mean_q: 1.673432, mean_eps: 0.554709\n",
      " 496036/500000: episode: 724, duration: 27.400s, episode steps: 963, steps per second:  35, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.013234, mae: 1.353837, mean_q: 1.648017, mean_eps: 0.554001\n",
      " 496428/500000: episode: 725, duration: 11.084s, episode steps: 392, steps per second:  35, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.013591, mae: 1.353554, mean_q: 1.646801, mean_eps: 0.553393\n",
      " 497134/500000: episode: 726, duration: 19.636s, episode steps: 706, steps per second:  36, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.013227, mae: 1.375122, mean_q: 1.675077, mean_eps: 0.552898\n",
      " 497534/500000: episode: 727, duration: 11.278s, episode steps: 400, steps per second:  35, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.013329, mae: 1.346324, mean_q: 1.637929, mean_eps: 0.552399\n",
      " 497957/500000: episode: 728, duration: 12.104s, episode steps: 423, steps per second:  35, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.014434, mae: 1.348861, mean_q: 1.643437, mean_eps: 0.552029\n",
      " 498791/500000: episode: 729, duration: 23.240s, episode steps: 834, steps per second:  36, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.013909, mae: 1.367100, mean_q: 1.666056, mean_eps: 0.551463\n",
      " 499514/500000: episode: 730, duration: 20.660s, episode steps: 723, steps per second:  35, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.014180, mae: 1.376167, mean_q: 1.676213, mean_eps: 0.550763\n",
      "done, took 12451.340 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2477ff19d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Entrenamiento del modelo\n",
    "dqn.fit(env, nb_steps=500000, visualize=False, verbose=2, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5328f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Guardar pesos finales\n",
    "final_weights = 'dqn_{}_final_weights.h5f'.format(ENV_NAME)\n",
    "dqn.save_weights(final_weights, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea6785e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 30 episodes ...\n",
      "Episode 1: reward: 16.000, steps: 810\n",
      "Episode 2: reward: 9.000, steps: 690\n",
      "Episode 3: reward: 7.000, steps: 785\n",
      "Episode 4: reward: 12.000, steps: 614\n",
      "Episode 5: reward: 11.000, steps: 1022\n",
      "Episode 6: reward: 11.000, steps: 678\n",
      "Episode 7: reward: 12.000, steps: 705\n",
      "Episode 8: reward: 7.000, steps: 639\n",
      "Episode 9: reward: 15.000, steps: 770\n",
      "Episode 10: reward: 8.000, steps: 549\n",
      "Episode 11: reward: 7.000, steps: 757\n",
      "Episode 12: reward: 22.000, steps: 960\n",
      "Episode 13: reward: 18.000, steps: 998\n",
      "Episode 14: reward: 14.000, steps: 828\n",
      "Episode 15: reward: 14.000, steps: 823\n",
      "Episode 16: reward: 12.000, steps: 763\n",
      "Episode 17: reward: 10.000, steps: 672\n",
      "Episode 18: reward: 19.000, steps: 1209\n",
      "Episode 19: reward: 13.000, steps: 821\n",
      "Episode 20: reward: 13.000, steps: 790\n",
      "Episode 21: reward: 18.000, steps: 1154\n",
      "Episode 22: reward: 16.000, steps: 974\n",
      "Episode 23: reward: 15.000, steps: 847\n",
      "Episode 24: reward: 12.000, steps: 856\n",
      "Episode 25: reward: 19.000, steps: 1076\n",
      "Episode 26: reward: 12.000, steps: 775\n",
      "Episode 27: reward: 12.000, steps: 768\n",
      "Episode 28: reward: 15.000, steps: 903\n",
      "Episode 29: reward: 11.000, steps: 717\n",
      "Episode 30: reward: 16.000, steps: 935\n",
      "\n",
      "🎯 Recompensas por episodio: [16.0, 9.0, 7.0, 12.0, 11.0, 11.0, 12.0, 7.0, 15.0, 8.0, 7.0, 22.0, 18.0, 14.0, 14.0, 12.0, 10.0, 19.0, 13.0, 13.0, 18.0, 16.0, 15.0, 12.0, 19.0, 12.0, 12.0, 15.0, 11.0, 16.0]\n",
      "📊 Media de recompensa sobre 30 episodios: 13.20\n",
      "❌ Objetivo no alcanzado: media de recompensa <= 20\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# EVALUACIÓN DEL AGENTE ENTRENADO\n",
    "# ================================\n",
    "\n",
    "# Cargar pesos finales entrenados\n",
    "final_weights = 'dqn_SpaceInvaders-v0_final_weights.h5f'\n",
    "dqn.load_weights(final_weights)\n",
    "\n",
    "# Evaluar el agente\n",
    "num_episodios = 30\n",
    "historial = dqn.test(env, nb_episodes=num_episodios, visualize=False)\n",
    "\n",
    "# Obtener las recompensas de cada episodio\n",
    "recompensas = historial.history['episode_reward']\n",
    "media_recompensas = np.mean(recompensas)\n",
    "\n",
    "# ================================\n",
    "# MOSTRAR RESULTADOS\n",
    "# ================================\n",
    "print(f\"\\n🎯 Recompensas por episodio: {recompensas}\")\n",
    "print(f\"📊 Media de recompensa sobre {num_episodios} episodios: {media_recompensas:.2f}\")\n",
    "if media_recompensas > 20:\n",
    "    print(\"✅ Objetivo cumplido: media de recompensa > 20\")\n",
    "else:\n",
    "    print(\"❌ Objetivo no alcanzado: media de recompensa <= 20\")\n",
    "\n",
    "# ================================\n",
    "# GRAFICAR RESULTADOS\n",
    "# ================================\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(recompensas, marker='o', linestyle='-', color='dodgerblue', label='Recompensa por episodio')\n",
    "plt.axhline(y=20, color='red', linestyle='--', label='Objetivo mínimo (20 puntos)')\n",
    "plt.axhline(y=media_recompensas, color='green', linestyle='-.', label=f'Media ({media_recompensas:.2f})')\n",
    "plt.title('Recompensa obtenida por episodio en modo test')\n",
    "plt.xlabel('Episodio')\n",
    "plt.ylabel('Recompensa (con clipping)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cerrar entorno\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c5c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('dqn_SpaceInvaders-v0_final_weights.h5f')\n",
    "dqn.policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
    "                                  attr='eps',\n",
    "                                  value_max=1.0,\n",
    "                                  value_min=0.05,   # puedes probar con 0.01 si ya aprendió bastante\n",
    "                                  value_test=0.01,\n",
    "                                  nb_steps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9df01680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "   781/100000: episode: 1, duration: 3.711s, episode steps: 781, steps per second: 210, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  1416/100000: episode: 2, duration: 3.000s, episode steps: 635, steps per second: 212, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  1786/100000: episode: 3, duration: 1.816s, episode steps: 370, steps per second: 204, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  2502/100000: episode: 4, duration: 3.445s, episode steps: 716, steps per second: 208, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  3469/100000: episode: 5, duration: 4.888s, episode steps: 967, steps per second: 198, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  4174/100000: episode: 6, duration: 3.211s, episode steps: 705, steps per second: 220, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  4810/100000: episode: 7, duration: 3.096s, episode steps: 636, steps per second: 205, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  5792/100000: episode: 8, duration: 6.608s, episode steps: 982, steps per second: 149, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  6319/100000: episode: 9, duration: 4.695s, episode steps: 527, steps per second: 112, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  6985/100000: episode: 10, duration: 3.120s, episode steps: 666, steps per second: 213, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  8067/100000: episode: 11, duration: 5.059s, episode steps: 1082, steps per second: 214, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  8576/100000: episode: 12, duration: 2.738s, episode steps: 509, steps per second: 186, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  9685/100000: episode: 13, duration: 8.950s, episode steps: 1109, steps per second: 124, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 10374/100000: episode: 14, duration: 6.614s, episode steps: 689, steps per second: 104, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 11062/100000: episode: 15, duration: 6.914s, episode steps: 688, steps per second: 100, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 11656/100000: episode: 16, duration: 4.524s, episode steps: 594, steps per second: 131, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 12854/100000: episode: 17, duration: 5.940s, episode steps: 1198, steps per second: 202, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 13674/100000: episode: 18, duration: 4.161s, episode steps: 820, steps per second: 197, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 14424/100000: episode: 19, duration: 3.561s, episode steps: 750, steps per second: 211, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 15725/100000: episode: 20, duration: 6.534s, episode steps: 1301, steps per second: 199, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 16301/100000: episode: 21, duration: 3.439s, episode steps: 576, steps per second: 167, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 16977/100000: episode: 22, duration: 6.490s, episode steps: 676, steps per second: 104, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 17481/100000: episode: 23, duration: 4.347s, episode steps: 504, steps per second: 116, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 17869/100000: episode: 24, duration: 3.735s, episode steps: 388, steps per second: 104, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 18652/100000: episode: 25, duration: 5.589s, episode steps: 783, steps per second: 140, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 19588/100000: episode: 26, duration: 4.462s, episode steps: 936, steps per second: 210, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 21002/100000: episode: 27, duration: 6.692s, episode steps: 1414, steps per second: 211, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 21533/100000: episode: 28, duration: 2.574s, episode steps: 531, steps per second: 206, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 22252/100000: episode: 29, duration: 3.852s, episode steps: 719, steps per second: 187, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 23054/100000: episode: 30, duration: 6.593s, episode steps: 802, steps per second: 122, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 23550/100000: episode: 31, duration: 4.584s, episode steps: 496, steps per second: 108, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 24296/100000: episode: 32, duration: 3.502s, episode steps: 746, steps per second: 213, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 25494/100000: episode: 33, duration: 5.495s, episode steps: 1198, steps per second: 218, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 25895/100000: episode: 34, duration: 1.779s, episode steps: 401, steps per second: 225, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 26582/100000: episode: 35, duration: 3.088s, episode steps: 687, steps per second: 222, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 27655/100000: episode: 36, duration: 5.102s, episode steps: 1073, steps per second: 210, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 28146/100000: episode: 37, duration: 2.411s, episode steps: 491, steps per second: 204, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 29021/100000: episode: 38, duration: 4.192s, episode steps: 875, steps per second: 209, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 29850/100000: episode: 39, duration: 3.914s, episode steps: 829, steps per second: 212, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 30510/100000: episode: 40, duration: 3.144s, episode steps: 660, steps per second: 210, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 31319/100000: episode: 41, duration: 3.684s, episode steps: 809, steps per second: 220, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 32179/100000: episode: 42, duration: 3.898s, episode steps: 860, steps per second: 221, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 33077/100000: episode: 43, duration: 4.067s, episode steps: 898, steps per second: 221, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 33679/100000: episode: 44, duration: 2.638s, episode steps: 602, steps per second: 228, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 34078/100000: episode: 45, duration: 1.851s, episode steps: 399, steps per second: 216, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 34728/100000: episode: 46, duration: 3.022s, episode steps: 650, steps per second: 215, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 35319/100000: episode: 47, duration: 2.691s, episode steps: 591, steps per second: 220, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 35994/100000: episode: 48, duration: 2.966s, episode steps: 675, steps per second: 228, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 36511/100000: episode: 49, duration: 2.312s, episode steps: 517, steps per second: 224, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 37024/100000: episode: 50, duration: 2.323s, episode steps: 513, steps per second: 221, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 37753/100000: episode: 51, duration: 3.271s, episode steps: 729, steps per second: 223, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 38470/100000: episode: 52, duration: 3.192s, episode steps: 717, steps per second: 225, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 39299/100000: episode: 53, duration: 3.740s, episode steps: 829, steps per second: 222, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 39775/100000: episode: 54, duration: 2.187s, episode steps: 476, steps per second: 218, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 40729/100000: episode: 55, duration: 4.354s, episode steps: 954, steps per second: 219, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 41346/100000: episode: 56, duration: 2.913s, episode steps: 617, steps per second: 212, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 41936/100000: episode: 57, duration: 2.720s, episode steps: 590, steps per second: 217, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 42888/100000: episode: 58, duration: 4.388s, episode steps: 952, steps per second: 217, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 43404/100000: episode: 59, duration: 2.226s, episode steps: 516, steps per second: 232, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 43972/100000: episode: 60, duration: 2.462s, episode steps: 568, steps per second: 231, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 44680/100000: episode: 61, duration: 3.067s, episode steps: 708, steps per second: 231, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 45390/100000: episode: 62, duration: 3.035s, episode steps: 710, steps per second: 234, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 46032/100000: episode: 63, duration: 2.870s, episode steps: 642, steps per second: 224, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 46662/100000: episode: 64, duration: 2.941s, episode steps: 630, steps per second: 214, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 47595/100000: episode: 65, duration: 4.248s, episode steps: 933, steps per second: 220, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 48478/100000: episode: 66, duration: 4.131s, episode steps: 883, steps per second: 214, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 49083/100000: episode: 67, duration: 2.652s, episode steps: 605, steps per second: 228, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 49895/100000: episode: 68, duration: 3.787s, episode steps: 812, steps per second: 214, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      " 50404/100000: episode: 69, duration: 12.158s, episode steps: 509, steps per second:  42, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.012843, mae: 1.435420, mean_q: 1.752342, mean_eps: 0.952308\n",
      " 51060/100000: episode: 70, duration: 19.183s, episode steps: 656, steps per second:  34, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.014770, mae: 1.442741, mean_q: 1.758268, mean_eps: 0.951807\n",
      " 51781/100000: episode: 71, duration: 47.132s, episode steps: 721, steps per second:  15, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.013621, mae: 1.441758, mean_q: 1.756764, mean_eps: 0.951151\n",
      " 52558/100000: episode: 72, duration: 52.518s, episode steps: 777, steps per second:  15, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.014389, mae: 1.443906, mean_q: 1.758463, mean_eps: 0.950438\n",
      " 53566/100000: episode: 73, duration: 64.308s, episode steps: 1008, steps per second:  16, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.015165, mae: 1.430440, mean_q: 1.740505, mean_eps: 0.949591\n",
      " 54067/100000: episode: 74, duration: 29.790s, episode steps: 501, steps per second:  17, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.012847, mae: 1.435670, mean_q: 1.750640, mean_eps: 0.948875\n",
      " 54692/100000: episode: 75, duration: 42.963s, episode steps: 625, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.014963, mae: 1.454942, mean_q: 1.769657, mean_eps: 0.948341\n",
      " 55683/100000: episode: 76, duration: 69.041s, episode steps: 991, steps per second:  14, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.014919, mae: 1.440397, mean_q: 1.751333, mean_eps: 0.947573\n",
      " 56629/100000: episode: 77, duration: 62.147s, episode steps: 946, steps per second:  15, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.015108, mae: 1.441278, mean_q: 1.754388, mean_eps: 0.946652\n",
      " 57143/100000: episode: 78, duration: 21.024s, episode steps: 514, steps per second:  24, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.017536, mae: 1.478605, mean_q: 1.796796, mean_eps: 0.945958\n",
      " 57751/100000: episode: 79, duration: 17.059s, episode steps: 608, steps per second:  36, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.014158, mae: 1.440286, mean_q: 1.751526, mean_eps: 0.945426\n",
      " 58357/100000: episode: 80, duration: 17.363s, episode steps: 606, steps per second:  35, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.012503, mae: 1.450753, mean_q: 1.767240, mean_eps: 0.944849\n",
      " 59610/100000: episode: 81, duration: 34.661s, episode steps: 1253, steps per second:  36, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.014139, mae: 1.442964, mean_q: 1.756140, mean_eps: 0.943965\n",
      " 60481/100000: episode: 82, duration: 27.250s, episode steps: 871, steps per second:  32, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.013078, mae: 1.460360, mean_q: 1.776177, mean_eps: 0.942956\n",
      " 61186/100000: episode: 83, duration: 24.480s, episode steps: 705, steps per second:  29, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.018804, mae: 1.471948, mean_q: 1.791089, mean_eps: 0.942208\n",
      " 61857/100000: episode: 84, duration: 19.427s, episode steps: 671, steps per second:  35, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.015305, mae: 1.463288, mean_q: 1.779504, mean_eps: 0.941554\n",
      " 62505/100000: episode: 85, duration: 17.998s, episode steps: 648, steps per second:  36, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.015372, mae: 1.486727, mean_q: 1.808791, mean_eps: 0.940927\n",
      " 63045/100000: episode: 86, duration: 14.913s, episode steps: 540, steps per second:  36, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.014304, mae: 1.450076, mean_q: 1.765819, mean_eps: 0.940363\n",
      " 63458/100000: episode: 87, duration: 11.333s, episode steps: 413, steps per second:  36, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.014684, mae: 1.481028, mean_q: 1.801162, mean_eps: 0.939911\n",
      " 64454/100000: episode: 88, duration: 27.586s, episode steps: 996, steps per second:  36, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.014679, mae: 1.467986, mean_q: 1.786442, mean_eps: 0.939242\n",
      " 64932/100000: episode: 89, duration: 13.348s, episode steps: 478, steps per second:  36, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.013947, mae: 1.480754, mean_q: 1.799572, mean_eps: 0.938543\n",
      " 65431/100000: episode: 90, duration: 14.244s, episode steps: 499, steps per second:  35, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.015715, mae: 1.461231, mean_q: 1.775888, mean_eps: 0.938079\n",
      " 66068/100000: episode: 91, duration: 17.846s, episode steps: 637, steps per second:  36, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.015226, mae: 1.469728, mean_q: 1.790184, mean_eps: 0.937539\n",
      " 67345/100000: episode: 92, duration: 36.467s, episode steps: 1277, steps per second:  35, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.014796, mae: 1.473163, mean_q: 1.791716, mean_eps: 0.936629\n",
      " 67725/100000: episode: 93, duration: 14.132s, episode steps: 380, steps per second:  27, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.016058, mae: 1.476300, mean_q: 1.799679, mean_eps: 0.935841\n",
      " 68293/100000: episode: 94, duration: 21.279s, episode steps: 568, steps per second:  27, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.017130, mae: 1.482489, mean_q: 1.803372, mean_eps: 0.935390\n",
      " 68699/100000: episode: 95, duration: 11.273s, episode steps: 406, steps per second:  36, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.016654, mae: 1.480495, mean_q: 1.801821, mean_eps: 0.934929\n",
      " 69334/100000: episode: 96, duration: 17.642s, episode steps: 635, steps per second:  36, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.014143, mae: 1.451765, mean_q: 1.766270, mean_eps: 0.934435\n",
      " 69934/100000: episode: 97, duration: 16.624s, episode steps: 600, steps per second:  36, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.013620, mae: 1.451532, mean_q: 1.763567, mean_eps: 0.933848\n",
      " 70921/100000: episode: 98, duration: 27.535s, episode steps: 987, steps per second:  36, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.015337, mae: 1.497361, mean_q: 1.821669, mean_eps: 0.933093\n",
      " 71365/100000: episode: 99, duration: 12.325s, episode steps: 444, steps per second:  36, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.012618, mae: 1.509031, mean_q: 1.833293, mean_eps: 0.932413\n",
      " 71887/100000: episode: 100, duration: 14.452s, episode steps: 522, steps per second:  36, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.014362, mae: 1.506071, mean_q: 1.828364, mean_eps: 0.931955\n",
      " 72323/100000: episode: 101, duration: 12.573s, episode steps: 436, steps per second:  35, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.015481, mae: 1.496797, mean_q: 1.816383, mean_eps: 0.931501\n",
      " 72808/100000: episode: 102, duration: 13.955s, episode steps: 485, steps per second:  35, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.014704, mae: 1.495567, mean_q: 1.817936, mean_eps: 0.931064\n",
      " 73458/100000: episode: 103, duration: 20.057s, episode steps: 650, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.014587, mae: 1.521503, mean_q: 1.849226, mean_eps: 0.930525\n",
      " 74599/100000: episode: 104, duration: 33.133s, episode steps: 1141, steps per second:  34, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.014708, mae: 1.488090, mean_q: 1.806489, mean_eps: 0.929673\n",
      " 75308/100000: episode: 105, duration: 20.073s, episode steps: 709, steps per second:  35, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.015290, mae: 1.512823, mean_q: 1.841900, mean_eps: 0.928796\n",
      " 76206/100000: episode: 106, duration: 35.961s, episode steps: 898, steps per second:  25, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.015211, mae: 1.498068, mean_q: 1.820218, mean_eps: 0.928032\n",
      " 76861/100000: episode: 107, duration: 18.543s, episode steps: 655, steps per second:  35, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.014675, mae: 1.494758, mean_q: 1.817925, mean_eps: 0.927293\n",
      " 77263/100000: episode: 108, duration: 12.249s, episode steps: 402, steps per second:  33, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.016431, mae: 1.480621, mean_q: 1.799275, mean_eps: 0.926791\n",
      " 77971/100000: episode: 109, duration: 41.776s, episode steps: 708, steps per second:  17, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.015364, mae: 1.497655, mean_q: 1.817848, mean_eps: 0.926265\n",
      " 78334/100000: episode: 110, duration: 19.210s, episode steps: 363, steps per second:  19, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.013386, mae: 1.464310, mean_q: 1.779867, mean_eps: 0.925756\n",
      " 78880/100000: episode: 111, duration: 34.357s, episode steps: 546, steps per second:  16, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.014086, mae: 1.495723, mean_q: 1.817541, mean_eps: 0.925324\n",
      " 79596/100000: episode: 112, duration: 22.841s, episode steps: 716, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.014620, mae: 1.490272, mean_q: 1.810988, mean_eps: 0.924726\n",
      " 79988/100000: episode: 113, duration: 11.396s, episode steps: 392, steps per second:  34, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.015320, mae: 1.508036, mean_q: 1.831830, mean_eps: 0.924199\n",
      " 80365/100000: episode: 114, duration: 11.524s, episode steps: 377, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.015373, mae: 1.532493, mean_q: 1.862240, mean_eps: 0.923833\n",
      " 80973/100000: episode: 115, duration: 18.018s, episode steps: 608, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.014892, mae: 1.525608, mean_q: 1.853595, mean_eps: 0.923364\n",
      " 81604/100000: episode: 116, duration: 17.879s, episode steps: 631, steps per second:  35, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.014591, mae: 1.536463, mean_q: 1.866749, mean_eps: 0.922776\n",
      " 82768/100000: episode: 117, duration: 32.880s, episode steps: 1164, steps per second:  35, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.014264, mae: 1.547699, mean_q: 1.880060, mean_eps: 0.921925\n",
      " 83229/100000: episode: 118, duration: 13.216s, episode steps: 461, steps per second:  35, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.014137, mae: 1.554080, mean_q: 1.888603, mean_eps: 0.921152\n",
      " 83619/100000: episode: 119, duration: 11.206s, episode steps: 390, steps per second:  35, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.015822, mae: 1.544424, mean_q: 1.875811, mean_eps: 0.920747\n",
      " 84242/100000: episode: 120, duration: 17.991s, episode steps: 623, steps per second:  35, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.012887, mae: 1.556213, mean_q: 1.893942, mean_eps: 0.920267\n",
      " 85140/100000: episode: 121, duration: 26.030s, episode steps: 898, steps per second:  34, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.014267, mae: 1.534372, mean_q: 1.863813, mean_eps: 0.919544\n",
      " 85829/100000: episode: 122, duration: 19.734s, episode steps: 689, steps per second:  35, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.015518, mae: 1.537140, mean_q: 1.870405, mean_eps: 0.918790\n",
      " 86403/100000: episode: 123, duration: 16.152s, episode steps: 574, steps per second:  36, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.013521, mae: 1.546647, mean_q: 1.879950, mean_eps: 0.918190\n",
      " 86975/100000: episode: 124, duration: 16.170s, episode steps: 572, steps per second:  35, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.016041, mae: 1.527370, mean_q: 1.854584, mean_eps: 0.917646\n",
      " 87491/100000: episode: 125, duration: 14.430s, episode steps: 516, steps per second:  36, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.013789, mae: 1.542590, mean_q: 1.875999, mean_eps: 0.917130\n",
      " 88165/100000: episode: 126, duration: 18.957s, episode steps: 674, steps per second:  36, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.013193, mae: 1.541351, mean_q: 1.874303, mean_eps: 0.916563\n",
      " 88867/100000: episode: 127, duration: 19.958s, episode steps: 702, steps per second:  35, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.014643, mae: 1.537169, mean_q: 1.869587, mean_eps: 0.915910\n",
      " 89581/100000: episode: 128, duration: 21.359s, episode steps: 714, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.013768, mae: 1.533097, mean_q: 1.863698, mean_eps: 0.915237\n",
      " 90083/100000: episode: 129, duration: 14.502s, episode steps: 502, steps per second:  35, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.014484, mae: 1.539408, mean_q: 1.871954, mean_eps: 0.914660\n",
      " 90562/100000: episode: 130, duration: 13.746s, episode steps: 479, steps per second:  35, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.012818, mae: 1.566658, mean_q: 1.909321, mean_eps: 0.914194\n",
      " 91427/100000: episode: 131, duration: 25.058s, episode steps: 865, steps per second:  35, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.014239, mae: 1.565339, mean_q: 1.906535, mean_eps: 0.913556\n",
      " 91996/100000: episode: 132, duration: 16.589s, episode steps: 569, steps per second:  34, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.015806, mae: 1.558763, mean_q: 1.894790, mean_eps: 0.912875\n",
      " 92634/100000: episode: 133, duration: 18.706s, episode steps: 638, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.014289, mae: 1.565426, mean_q: 1.902546, mean_eps: 0.912302\n",
      " 93168/100000: episode: 134, duration: 16.051s, episode steps: 534, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.014218, mae: 1.573095, mean_q: 1.912592, mean_eps: 0.911745\n",
      " 93789/100000: episode: 135, duration: 17.983s, episode steps: 621, steps per second:  35, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.013083, mae: 1.555885, mean_q: 1.890787, mean_eps: 0.911196\n",
      " 94559/100000: episode: 136, duration: 21.792s, episode steps: 770, steps per second:  35, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.015836, mae: 1.578577, mean_q: 1.918342, mean_eps: 0.910535\n",
      " 95178/100000: episode: 137, duration: 17.337s, episode steps: 619, steps per second:  36, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.014358, mae: 1.565150, mean_q: 1.902100, mean_eps: 0.909875\n",
      " 95828/100000: episode: 138, duration: 18.100s, episode steps: 650, steps per second:  36, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.016018, mae: 1.571091, mean_q: 1.909190, mean_eps: 0.909273\n",
      " 96480/100000: episode: 139, duration: 18.663s, episode steps: 652, steps per second:  35, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.014416, mae: 1.572752, mean_q: 1.909041, mean_eps: 0.908656\n",
      " 97281/100000: episode: 140, duration: 22.660s, episode steps: 801, steps per second:  35, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.016329, mae: 1.575148, mean_q: 1.913986, mean_eps: 0.907964\n",
      " 98090/100000: episode: 141, duration: 22.781s, episode steps: 809, steps per second:  36, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.014679, mae: 1.546899, mean_q: 1.880041, mean_eps: 0.907198\n",
      " 98610/100000: episode: 142, duration: 15.259s, episode steps: 520, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.014977, mae: 1.566129, mean_q: 1.901934, mean_eps: 0.906568\n",
      " 99156/100000: episode: 143, duration: 15.385s, episode steps: 546, steps per second:  35, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.013550, mae: 1.566917, mean_q: 1.904539, mean_eps: 0.906062\n",
      " 99702/100000: episode: 144, duration: 15.896s, episode steps: 546, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.014577, mae: 1.586625, mean_q: 1.927344, mean_eps: 0.905543\n",
      "done, took 1985.966 seconds\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# ENTRENAMIENTO ADICIONAL (100K)\n",
    "# ================================\n",
    "dqn.fit(env, nb_steps=100000, visualize=False, verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "# Guardar pesos nuevos finales\n",
    "dqn.save_weights('dqn_SpaceInvaders-v0_final_weights_600k.h5f', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "487ba418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 30 episodes ...\n",
      "Episode 1: reward: 13.000, steps: 652\n",
      "Episode 2: reward: 18.000, steps: 1299\n",
      "Episode 3: reward: 14.000, steps: 723\n",
      "Episode 4: reward: 18.000, steps: 1055\n",
      "Episode 5: reward: 10.000, steps: 560\n",
      "Episode 6: reward: 20.000, steps: 1159\n",
      "Episode 7: reward: 19.000, steps: 1043\n",
      "Episode 8: reward: 22.000, steps: 939\n",
      "Episode 9: reward: 12.000, steps: 655\n",
      "Episode 10: reward: 8.000, steps: 525\n",
      "Episode 11: reward: 8.000, steps: 609\n",
      "Episode 12: reward: 21.000, steps: 891\n",
      "Episode 13: reward: 12.000, steps: 646\n",
      "Episode 14: reward: 14.000, steps: 805\n",
      "Episode 15: reward: 14.000, steps: 854\n",
      "Episode 16: reward: 7.000, steps: 491\n",
      "Episode 17: reward: 11.000, steps: 615\n",
      "Episode 18: reward: 19.000, steps: 913\n",
      "Episode 19: reward: 10.000, steps: 553\n",
      "Episode 20: reward: 10.000, steps: 506\n",
      "Episode 21: reward: 20.000, steps: 724\n",
      "Episode 22: reward: 12.000, steps: 809\n",
      "Episode 23: reward: 16.000, steps: 703\n",
      "Episode 24: reward: 13.000, steps: 666\n",
      "Episode 25: reward: 9.000, steps: 682\n",
      "Episode 26: reward: 25.000, steps: 1168\n",
      "Episode 27: reward: 12.000, steps: 612\n",
      "Episode 28: reward: 19.000, steps: 824\n",
      "Episode 29: reward: 19.000, steps: 1016\n",
      "Episode 30: reward: 13.000, steps: 686\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Cargar nuevos pesos \n",
    "dqn.load_weights('dqn_SpaceInvaders-v0_final_weights_600k.h5f')\n",
    "\n",
    "# Evaluación con nuevos pesos\n",
    "num_episodios = 30\n",
    "nuevo_historial = dqn.test(env, nb_episodes=num_episodios, visualize=False)\n",
    "nuevas_recompensas = nuevo_historial.history['episode_reward']\n",
    "media_nueva = np.mean(nuevas_recompensas)\n",
    "\n",
    "# Aquí pega tus recompensas anteriores manualmente:\n",
    "recompensas_anteriores = [16.0, 9.0, 7.0, 12.0, 11.0, 11.0, 12.0, 7.0, 15.0, 8.0, 7.0, 22.0, 18.0, 14.0, 14.0, 12.0, 10.0, 19.0, 13.0, 13.0, 18.0, 16.0, 15.0, 12.0, 19.0, 12.0, 12.0, 15.0, 11.0, 16.0]\n",
    "media_anterior = np.mean(recompensas_anteriores)\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(recompensas_anteriores, label='Antes (500k)', marker='o', linestyle='--')\n",
    "plt.plot(nuevas_recompensas, label='Después (600k)', marker='s', linestyle='-')\n",
    "plt.axhline(20, color='red', linestyle=':', label='Objetivo mínimo')\n",
    "plt.axhline(media_anterior, color='blue', linestyle='--', label=f'Media 500k: {media_anterior:.2f}')\n",
    "plt.axhline(media_nueva, color='green', linestyle='--', label=f'Media 600k: {media_nueva:.2f}')\n",
    "plt.title(\"Comparación de recompensas por episodio (500k vs 600k pasos)\")\n",
    "plt.xlabel(\"Episodio\")\n",
    "plt.ylabel(\"Recompensa\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "352bd1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Recompensas por episodio: [16.0, 9.0, 7.0, 12.0, 11.0, 11.0, 12.0, 7.0, 15.0, 8.0, 7.0, 22.0, 18.0, 14.0, 14.0, 12.0, 10.0, 19.0, 13.0, 13.0, 18.0, 16.0, 15.0, 12.0, 19.0, 12.0, 12.0, 15.0, 11.0, 16.0]\n",
      "📊 Media de recompensa sobre 30 episodios: 14.60\n",
      "❌ Objetivo no alcanzado: media de recompensa <= 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🎯 Recompensas por episodio: {recompensas}\")\n",
    "print(f\"📊 Media de recompensa sobre {num_episodios} episodios: {media_nueva:.2f}\")\n",
    "if media_nueva > 20:\n",
    "    print(\"✅ Objetivo cumplido: media de recompensa > 20\")\n",
    "else:\n",
    "    print(\"❌ Objetivo no alcanzado: media de recompensa <= 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56371d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo desde paso 500k hasta 2M...\n",
      "Training for 1500000 steps ...\n",
      "     576/1500000: episode: 1, duration: 2.733s, episode steps: 576, steps per second: 211, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "     941/1500000: episode: 2, duration: 1.798s, episode steps: 365, steps per second: 203, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    2423/1500000: episode: 3, duration: 7.397s, episode steps: 1482, steps per second: 200, episode reward: 12.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    3177/1500000: episode: 4, duration: 3.527s, episode steps: 754, steps per second: 214, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    3652/1500000: episode: 5, duration: 2.253s, episode steps: 475, steps per second: 211, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    4435/1500000: episode: 6, duration: 3.753s, episode steps: 783, steps per second: 209, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    5708/1500000: episode: 7, duration: 6.104s, episode steps: 1273, steps per second: 209, episode reward: 24.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    6381/1500000: episode: 8, duration: 3.249s, episode steps: 673, steps per second: 207, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    7230/1500000: episode: 9, duration: 3.932s, episode steps: 849, steps per second: 216, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    7992/1500000: episode: 10, duration: 3.621s, episode steps: 762, steps per second: 210, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "    9118/1500000: episode: 11, duration: 4.991s, episode steps: 1126, steps per second: 226, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   10060/1500000: episode: 12, duration: 4.580s, episode steps: 942, steps per second: 206, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   11095/1500000: episode: 13, duration: 4.611s, episode steps: 1035, steps per second: 224, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   12097/1500000: episode: 14, duration: 4.701s, episode steps: 1002, steps per second: 213, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   12783/1500000: episode: 15, duration: 3.177s, episode steps: 686, steps per second: 216, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   13431/1500000: episode: 16, duration: 3.239s, episode steps: 648, steps per second: 200, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   14241/1500000: episode: 17, duration: 3.875s, episode steps: 810, steps per second: 209, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   14834/1500000: episode: 18, duration: 2.609s, episode steps: 593, steps per second: 227, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   15405/1500000: episode: 19, duration: 2.534s, episode steps: 571, steps per second: 225, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   16349/1500000: episode: 20, duration: 4.151s, episode steps: 944, steps per second: 227, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   17673/1500000: episode: 21, duration: 6.018s, episode steps: 1324, steps per second: 220, episode reward: 24.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   18279/1500000: episode: 22, duration: 2.845s, episode steps: 606, steps per second: 213, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   19148/1500000: episode: 23, duration: 3.927s, episode steps: 869, steps per second: 221, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   19611/1500000: episode: 24, duration: 2.071s, episode steps: 463, steps per second: 224, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   20212/1500000: episode: 25, duration: 2.841s, episode steps: 601, steps per second: 212, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   20840/1500000: episode: 26, duration: 2.982s, episode steps: 628, steps per second: 211, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   21491/1500000: episode: 27, duration: 2.968s, episode steps: 651, steps per second: 219, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   22778/1500000: episode: 28, duration: 5.655s, episode steps: 1287, steps per second: 228, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   23456/1500000: episode: 29, duration: 3.059s, episode steps: 678, steps per second: 222, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   24052/1500000: episode: 30, duration: 2.766s, episode steps: 596, steps per second: 215, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   24650/1500000: episode: 31, duration: 2.725s, episode steps: 598, steps per second: 219, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   25141/1500000: episode: 32, duration: 2.315s, episode steps: 491, steps per second: 212, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   25982/1500000: episode: 33, duration: 7.470s, episode steps: 841, steps per second: 113, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   26509/1500000: episode: 34, duration: 4.060s, episode steps: 527, steps per second: 130, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   27150/1500000: episode: 35, duration: 4.767s, episode steps: 641, steps per second: 134, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   27926/1500000: episode: 36, duration: 5.557s, episode steps: 776, steps per second: 140, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   28867/1500000: episode: 37, duration: 7.512s, episode steps: 941, steps per second: 125, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   29476/1500000: episode: 38, duration: 4.703s, episode steps: 609, steps per second: 129, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   30082/1500000: episode: 39, duration: 4.895s, episode steps: 606, steps per second: 124, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   30953/1500000: episode: 40, duration: 4.341s, episode steps: 871, steps per second: 201, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   31517/1500000: episode: 41, duration: 2.743s, episode steps: 564, steps per second: 206, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   32230/1500000: episode: 42, duration: 3.421s, episode steps: 713, steps per second: 208, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   33120/1500000: episode: 43, duration: 4.075s, episode steps: 890, steps per second: 218, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   33511/1500000: episode: 44, duration: 1.825s, episode steps: 391, steps per second: 214, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   34331/1500000: episode: 45, duration: 3.818s, episode steps: 820, steps per second: 215, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   34835/1500000: episode: 46, duration: 2.275s, episode steps: 504, steps per second: 222, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   35645/1500000: episode: 47, duration: 3.685s, episode steps: 810, steps per second: 220, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   36048/1500000: episode: 48, duration: 1.912s, episode steps: 403, steps per second: 211, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   36646/1500000: episode: 49, duration: 3.122s, episode steps: 598, steps per second: 192, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   37466/1500000: episode: 50, duration: 3.845s, episode steps: 820, steps per second: 213, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   37962/1500000: episode: 51, duration: 2.321s, episode steps: 496, steps per second: 214, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   38428/1500000: episode: 52, duration: 2.168s, episode steps: 466, steps per second: 215, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   39147/1500000: episode: 53, duration: 3.283s, episode steps: 719, steps per second: 219, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   40293/1500000: episode: 54, duration: 5.451s, episode steps: 1146, steps per second: 210, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   41120/1500000: episode: 55, duration: 4.060s, episode steps: 827, steps per second: 204, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   41800/1500000: episode: 56, duration: 3.347s, episode steps: 680, steps per second: 203, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   42197/1500000: episode: 57, duration: 1.971s, episode steps: 397, steps per second: 201, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   43514/1500000: episode: 58, duration: 6.504s, episode steps: 1317, steps per second: 202, episode reward: 28.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   44034/1500000: episode: 59, duration: 2.570s, episode steps: 520, steps per second: 202, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   44782/1500000: episode: 60, duration: 3.399s, episode steps: 748, steps per second: 220, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   45176/1500000: episode: 61, duration: 1.758s, episode steps: 394, steps per second: 224, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   45687/1500000: episode: 62, duration: 2.307s, episode steps: 511, steps per second: 222, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   46025/1500000: episode: 63, duration: 1.524s, episode steps: 338, steps per second: 222, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   46656/1500000: episode: 64, duration: 2.908s, episode steps: 631, steps per second: 217, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   47051/1500000: episode: 65, duration: 1.810s, episode steps: 395, steps per second: 218, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   47696/1500000: episode: 66, duration: 3.061s, episode steps: 645, steps per second: 211, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   48565/1500000: episode: 67, duration: 3.891s, episode steps: 869, steps per second: 223, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   49145/1500000: episode: 68, duration: 2.732s, episode steps: 580, steps per second: 212, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   49705/1500000: episode: 69, duration: 2.619s, episode steps: 560, steps per second: 214, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   50382/1500000: episode: 70, duration: 12.397s, episode steps: 677, steps per second:  55, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.013032, mae: 1.572034, mean_q: 1.912451, mean_eps: 0.952318\n",
      "   50774/1500000: episode: 71, duration: 11.358s, episode steps: 392, steps per second:  35, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.015017, mae: 1.622055, mean_q: 1.973557, mean_eps: 0.951951\n",
      "   51507/1500000: episode: 72, duration: 21.546s, episode steps: 733, steps per second:  34, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.014545, mae: 1.611789, mean_q: 1.958760, mean_eps: 0.951417\n",
      "   52196/1500000: episode: 73, duration: 29.446s, episode steps: 689, steps per second:  23, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.013673, mae: 1.602115, mean_q: 1.946288, mean_eps: 0.950742\n",
      "   52837/1500000: episode: 74, duration: 36.090s, episode steps: 641, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.014740, mae: 1.622881, mean_q: 1.968222, mean_eps: 0.950110\n",
      "   54054/1500000: episode: 75, duration: 71.936s, episode steps: 1217, steps per second:  17, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.015385, mae: 1.613564, mean_q: 1.959268, mean_eps: 0.949226\n",
      "   54846/1500000: episode: 76, duration: 25.454s, episode steps: 792, steps per second:  31, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.016405, mae: 1.613702, mean_q: 1.957621, mean_eps: 0.948273\n",
      "   55458/1500000: episode: 77, duration: 19.704s, episode steps: 612, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.014864, mae: 1.641436, mean_q: 1.991918, mean_eps: 0.947606\n",
      "   56677/1500000: episode: 78, duration: 72.688s, episode steps: 1219, steps per second:  17, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.014370, mae: 1.634531, mean_q: 1.983354, mean_eps: 0.946735\n",
      "   57215/1500000: episode: 79, duration: 21.259s, episode steps: 538, steps per second:  25, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.013793, mae: 1.653493, mean_q: 2.005975, mean_eps: 0.945901\n",
      "   57837/1500000: episode: 80, duration: 23.330s, episode steps: 622, steps per second:  27, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.013374, mae: 1.644739, mean_q: 1.993756, mean_eps: 0.945350\n",
      "   58534/1500000: episode: 81, duration: 20.388s, episode steps: 697, steps per second:  34, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.016275, mae: 1.620520, mean_q: 1.965119, mean_eps: 0.944723\n",
      "   59382/1500000: episode: 82, duration: 24.431s, episode steps: 848, steps per second:  35, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.016883, mae: 1.638418, mean_q: 1.988306, mean_eps: 0.943990\n",
      "   59936/1500000: episode: 83, duration: 25.122s, episode steps: 554, steps per second:  22, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.013875, mae: 1.660774, mean_q: 2.015733, mean_eps: 0.943325\n",
      "   60709/1500000: episode: 84, duration: 39.959s, episode steps: 773, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.013292, mae: 1.659294, mean_q: 2.014546, mean_eps: 0.942694\n",
      "   61619/1500000: episode: 85, duration: 27.755s, episode steps: 910, steps per second:  33, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.014704, mae: 1.687115, mean_q: 2.048314, mean_eps: 0.941894\n",
      "   62463/1500000: episode: 86, duration: 24.264s, episode steps: 844, steps per second:  35, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.015690, mae: 1.667874, mean_q: 2.025195, mean_eps: 0.941062\n",
      "   63125/1500000: episode: 87, duration: 22.088s, episode steps: 662, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.014243, mae: 1.673241, mean_q: 2.031301, mean_eps: 0.940346\n",
      "   63824/1500000: episode: 88, duration: 20.904s, episode steps: 699, steps per second:  33, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.015337, mae: 1.686134, mean_q: 2.046171, mean_eps: 0.939700\n",
      "   64687/1500000: episode: 89, duration: 26.409s, episode steps: 863, steps per second:  33, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.014366, mae: 1.657657, mean_q: 2.009858, mean_eps: 0.938959\n",
      "   65064/1500000: episode: 90, duration: 11.690s, episode steps: 377, steps per second:  32, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.014663, mae: 1.668989, mean_q: 2.025011, mean_eps: 0.938370\n",
      "   65574/1500000: episode: 91, duration: 15.918s, episode steps: 510, steps per second:  32, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.014909, mae: 1.726873, mean_q: 2.097674, mean_eps: 0.937948\n",
      "   66329/1500000: episode: 92, duration: 23.214s, episode steps: 755, steps per second:  33, episode reward:  3.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.014833, mae: 1.701354, mean_q: 2.067066, mean_eps: 0.937346\n",
      "   67425/1500000: episode: 93, duration: 34.646s, episode steps: 1096, steps per second:  32, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.015512, mae: 1.724215, mean_q: 2.094051, mean_eps: 0.936466\n",
      "   67934/1500000: episode: 94, duration: 15.074s, episode steps: 509, steps per second:  34, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.014513, mae: 1.684982, mean_q: 2.047115, mean_eps: 0.935704\n",
      "   68532/1500000: episode: 95, duration: 17.850s, episode steps: 598, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.014439, mae: 1.687578, mean_q: 2.045848, mean_eps: 0.935180\n",
      "   68927/1500000: episode: 96, duration: 11.758s, episode steps: 395, steps per second:  34, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.015060, mae: 1.699423, mean_q: 2.065288, mean_eps: 0.934708\n",
      "   69638/1500000: episode: 97, duration: 22.175s, episode steps: 711, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.014175, mae: 1.713697, mean_q: 2.081090, mean_eps: 0.934182\n",
      "   70308/1500000: episode: 98, duration: 20.677s, episode steps: 670, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.014722, mae: 1.702226, mean_q: 2.067927, mean_eps: 0.933527\n",
      "   71033/1500000: episode: 99, duration: 22.145s, episode steps: 725, steps per second:  33, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.013427, mae: 1.745939, mean_q: 2.118002, mean_eps: 0.932864\n",
      "   71531/1500000: episode: 100, duration: 15.378s, episode steps: 498, steps per second:  32, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.014017, mae: 1.757019, mean_q: 2.130942, mean_eps: 0.932282\n",
      "   72379/1500000: episode: 101, duration: 26.364s, episode steps: 848, steps per second:  32, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.013818, mae: 1.719176, mean_q: 2.085559, mean_eps: 0.931644\n",
      "   73034/1500000: episode: 102, duration: 19.910s, episode steps: 655, steps per second:  33, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.015201, mae: 1.747312, mean_q: 2.118136, mean_eps: 0.930929\n",
      "   73918/1500000: episode: 103, duration: 26.354s, episode steps: 884, steps per second:  34, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.014128, mae: 1.720160, mean_q: 2.084862, mean_eps: 0.930198\n",
      "   74796/1500000: episode: 104, duration: 26.081s, episode steps: 878, steps per second:  34, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.016160, mae: 1.733366, mean_q: 2.102149, mean_eps: 0.929362\n",
      "   75658/1500000: episode: 105, duration: 25.657s, episode steps: 862, steps per second:  34, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.013816, mae: 1.763682, mean_q: 2.141089, mean_eps: 0.928535\n",
      "   76058/1500000: episode: 106, duration: 11.987s, episode steps: 400, steps per second:  33, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.014858, mae: 1.775880, mean_q: 2.154721, mean_eps: 0.927935\n",
      "   76954/1500000: episode: 107, duration: 27.106s, episode steps: 896, steps per second:  33, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.016039, mae: 1.765000, mean_q: 2.141737, mean_eps: 0.927319\n",
      "   77588/1500000: episode: 108, duration: 19.016s, episode steps: 634, steps per second:  33, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.014976, mae: 1.768909, mean_q: 2.144915, mean_eps: 0.926593\n",
      "   78471/1500000: episode: 109, duration: 26.124s, episode steps: 883, steps per second:  34, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.016979, mae: 1.769275, mean_q: 2.145394, mean_eps: 0.925873\n",
      "   79206/1500000: episode: 110, duration: 22.001s, episode steps: 735, steps per second:  33, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.016639, mae: 1.766762, mean_q: 2.142097, mean_eps: 0.925104\n",
      "   79851/1500000: episode: 111, duration: 19.155s, episode steps: 645, steps per second:  34, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.015479, mae: 1.781345, mean_q: 2.160092, mean_eps: 0.924448\n",
      "   80547/1500000: episode: 112, duration: 20.323s, episode steps: 696, steps per second:  34, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.014323, mae: 1.788899, mean_q: 2.171757, mean_eps: 0.923812\n",
      "   81082/1500000: episode: 113, duration: 16.911s, episode steps: 535, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.014865, mae: 1.801239, mean_q: 2.184686, mean_eps: 0.923227\n",
      "   81956/1500000: episode: 114, duration: 27.869s, episode steps: 874, steps per second:  31, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.015838, mae: 1.812428, mean_q: 2.196257, mean_eps: 0.922558\n",
      "   82346/1500000: episode: 115, duration: 12.330s, episode steps: 390, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.017210, mae: 1.763440, mean_q: 2.137433, mean_eps: 0.921958\n",
      "   83088/1500000: episode: 116, duration: 24.128s, episode steps: 742, steps per second:  31, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.015356, mae: 1.780685, mean_q: 2.158919, mean_eps: 0.921420\n",
      "   83780/1500000: episode: 117, duration: 20.799s, episode steps: 692, steps per second:  33, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.015852, mae: 1.777314, mean_q: 2.154436, mean_eps: 0.920740\n",
      "   84381/1500000: episode: 118, duration: 17.777s, episode steps: 601, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.015188, mae: 1.788225, mean_q: 2.166203, mean_eps: 0.920124\n",
      "   85047/1500000: episode: 119, duration: 19.536s, episode steps: 666, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.015564, mae: 1.788129, mean_q: 2.165855, mean_eps: 0.919522\n",
      "   85433/1500000: episode: 120, duration: 17.684s, episode steps: 386, steps per second:  22, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.013955, mae: 1.773852, mean_q: 2.148608, mean_eps: 0.919022\n",
      "   85889/1500000: episode: 121, duration: 33.958s, episode steps: 456, steps per second:  13, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.015803, mae: 1.797283, mean_q: 2.179763, mean_eps: 0.918621\n",
      "   86844/1500000: episode: 122, duration: 50.561s, episode steps: 955, steps per second:  19, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.015130, mae: 1.792436, mean_q: 2.173881, mean_eps: 0.917952\n",
      "   87487/1500000: episode: 123, duration: 23.055s, episode steps: 643, steps per second:  28, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.016428, mae: 1.787717, mean_q: 2.167493, mean_eps: 0.917194\n",
      "   88072/1500000: episode: 124, duration: 18.248s, episode steps: 585, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.014105, mae: 1.814069, mean_q: 2.199579, mean_eps: 0.916611\n",
      "   88660/1500000: episode: 125, duration: 18.248s, episode steps: 588, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.014750, mae: 1.795282, mean_q: 2.177238, mean_eps: 0.916054\n",
      "   89064/1500000: episode: 126, duration: 14.533s, episode steps: 404, steps per second:  28, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.017108, mae: 1.789671, mean_q: 2.169573, mean_eps: 0.915583\n",
      "   89793/1500000: episode: 127, duration: 26.388s, episode steps: 729, steps per second:  28, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.015176, mae: 1.806265, mean_q: 2.190174, mean_eps: 0.915043\n",
      "   90243/1500000: episode: 128, duration: 14.538s, episode steps: 450, steps per second:  31, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.014609, mae: 1.781702, mean_q: 2.159586, mean_eps: 0.914483\n",
      "   91092/1500000: episode: 129, duration: 27.628s, episode steps: 849, steps per second:  31, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.016592, mae: 1.809476, mean_q: 2.196359, mean_eps: 0.913867\n",
      "   92049/1500000: episode: 130, duration: 27.992s, episode steps: 957, steps per second:  34, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.016751, mae: 1.795644, mean_q: 2.178308, mean_eps: 0.913008\n",
      "   92482/1500000: episode: 131, duration: 12.679s, episode steps: 433, steps per second:  34, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.014842, mae: 1.816344, mean_q: 2.204025, mean_eps: 0.912347\n",
      "   93453/1500000: episode: 132, duration: 28.265s, episode steps: 971, steps per second:  34, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.016606, mae: 1.819119, mean_q: 2.206391, mean_eps: 0.911680\n",
      "   94000/1500000: episode: 133, duration: 16.089s, episode steps: 547, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.016094, mae: 1.806939, mean_q: 2.188299, mean_eps: 0.910960\n",
      "   94450/1500000: episode: 134, duration: 13.196s, episode steps: 450, steps per second:  34, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.015656, mae: 1.787696, mean_q: 2.167987, mean_eps: 0.910487\n",
      "   94962/1500000: episode: 135, duration: 14.870s, episode steps: 512, steps per second:  34, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.014808, mae: 1.777706, mean_q: 2.155170, mean_eps: 0.910029\n",
      "   95910/1500000: episode: 136, duration: 27.494s, episode steps: 948, steps per second:  34, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.014463, mae: 1.798188, mean_q: 2.181835, mean_eps: 0.909336\n",
      "   96307/1500000: episode: 137, duration: 11.527s, episode steps: 397, steps per second:  34, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.016861, mae: 1.802843, mean_q: 2.185213, mean_eps: 0.908697\n",
      "   96811/1500000: episode: 138, duration: 14.590s, episode steps: 504, steps per second:  35, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.014402, mae: 1.816569, mean_q: 2.203618, mean_eps: 0.908270\n",
      "   97458/1500000: episode: 139, duration: 18.748s, episode steps: 647, steps per second:  35, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.014683, mae: 1.793155, mean_q: 2.174814, mean_eps: 0.907723\n",
      "   98574/1500000: episode: 140, duration: 32.878s, episode steps: 1116, steps per second:  34, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.016469, mae: 1.815795, mean_q: 2.200336, mean_eps: 0.906885\n",
      "   99200/1500000: episode: 141, duration: 18.568s, episode steps: 626, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.013912, mae: 1.803559, mean_q: 2.185200, mean_eps: 0.906058\n",
      "   99672/1500000: episode: 142, duration: 14.751s, episode steps: 472, steps per second:  32, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.016008, mae: 1.810996, mean_q: 2.197121, mean_eps: 0.905538\n",
      "Step 100000: saving model to dqn_SpaceInvaders-v0_step_100000.h5f\n",
      "  100803/1500000: episode: 143, duration: 35.711s, episode steps: 1131, steps per second:  32, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.013980, mae: 1.818756, mean_q: 2.207401, mean_eps: 0.904776\n",
      "  101320/1500000: episode: 144, duration: 16.481s, episode steps: 517, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.014560, mae: 1.840498, mean_q: 2.232779, mean_eps: 0.903993\n",
      "  101813/1500000: episode: 145, duration: 14.974s, episode steps: 493, steps per second:  33, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.015538, mae: 1.810143, mean_q: 2.194306, mean_eps: 0.903512\n",
      "  102510/1500000: episode: 146, duration: 20.950s, episode steps: 697, steps per second:  33, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.015740, mae: 1.834557, mean_q: 2.222549, mean_eps: 0.902946\n",
      "  103562/1500000: episode: 147, duration: 31.645s, episode steps: 1052, steps per second:  33, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.016603, mae: 1.807449, mean_q: 2.192161, mean_eps: 0.902116\n",
      "  104422/1500000: episode: 148, duration: 26.189s, episode steps: 860, steps per second:  33, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.017083, mae: 1.852355, mean_q: 2.247592, mean_eps: 0.901208\n",
      "  105098/1500000: episode: 149, duration: 19.975s, episode steps: 676, steps per second:  34, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.014450, mae: 1.829075, mean_q: 2.220505, mean_eps: 0.900478\n",
      "  105705/1500000: episode: 150, duration: 18.090s, episode steps: 607, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.014356, mae: 1.870091, mean_q: 2.269491, mean_eps: 0.899868\n",
      "  106099/1500000: episode: 151, duration: 11.536s, episode steps: 394, steps per second:  34, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.018339, mae: 1.840471, mean_q: 2.230011, mean_eps: 0.899393\n",
      "  106538/1500000: episode: 152, duration: 13.228s, episode steps: 439, steps per second:  33, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.014902, mae: 1.844288, mean_q: 2.240294, mean_eps: 0.898998\n",
      "  107039/1500000: episode: 153, duration: 14.749s, episode steps: 501, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.018136, mae: 1.862951, mean_q: 2.260005, mean_eps: 0.898551\n",
      "  107818/1500000: episode: 154, duration: 24.069s, episode steps: 779, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.015648, mae: 1.880861, mean_q: 2.282855, mean_eps: 0.897943\n",
      "  108314/1500000: episode: 155, duration: 15.591s, episode steps: 496, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.015744, mae: 1.877591, mean_q: 2.280263, mean_eps: 0.897337\n",
      "  108818/1500000: episode: 156, duration: 15.428s, episode steps: 504, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.015471, mae: 1.856689, mean_q: 2.251201, mean_eps: 0.896862\n",
      "  109474/1500000: episode: 157, duration: 20.429s, episode steps: 656, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.014815, mae: 1.866355, mean_q: 2.266384, mean_eps: 0.896311\n",
      "  110003/1500000: episode: 158, duration: 16.729s, episode steps: 529, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.015688, mae: 1.847704, mean_q: 2.240434, mean_eps: 0.895749\n",
      "  110805/1500000: episode: 159, duration: 25.517s, episode steps: 802, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.015345, mae: 1.858083, mean_q: 2.253163, mean_eps: 0.895116\n",
      "  111505/1500000: episode: 160, duration: 21.610s, episode steps: 700, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.014829, mae: 1.866922, mean_q: 2.263679, mean_eps: 0.894402\n",
      "  112228/1500000: episode: 161, duration: 21.822s, episode steps: 723, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.015826, mae: 1.868771, mean_q: 2.264640, mean_eps: 0.893727\n",
      "  112612/1500000: episode: 162, duration: 11.697s, episode steps: 384, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.015955, mae: 1.862213, mean_q: 2.256202, mean_eps: 0.893203\n",
      "  113370/1500000: episode: 163, duration: 23.287s, episode steps: 758, steps per second:  33, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.015784, mae: 1.869220, mean_q: 2.268467, mean_eps: 0.892659\n",
      "  114351/1500000: episode: 164, duration: 29.988s, episode steps: 981, steps per second:  33, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.015575, mae: 1.863666, mean_q: 2.258749, mean_eps: 0.891833\n",
      "  114867/1500000: episode: 165, duration: 15.814s, episode steps: 516, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.015147, mae: 1.848133, mean_q: 2.238472, mean_eps: 0.891122\n",
      "  115379/1500000: episode: 166, duration: 16.571s, episode steps: 512, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.013789, mae: 1.907706, mean_q: 2.311237, mean_eps: 0.890634\n",
      "  115940/1500000: episode: 167, duration: 18.332s, episode steps: 561, steps per second:  31, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.015491, mae: 1.909971, mean_q: 2.318110, mean_eps: 0.890125\n",
      "  116762/1500000: episode: 168, duration: 26.687s, episode steps: 822, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.014939, mae: 1.904728, mean_q: 2.309343, mean_eps: 0.889467\n",
      "  117296/1500000: episode: 169, duration: 17.973s, episode steps: 534, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.015244, mae: 1.905079, mean_q: 2.310163, mean_eps: 0.888823\n",
      "  118252/1500000: episode: 170, duration: 29.998s, episode steps: 956, steps per second:  32, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.014239, mae: 1.881383, mean_q: 2.282041, mean_eps: 0.888117\n",
      "  118712/1500000: episode: 171, duration: 14.410s, episode steps: 460, steps per second:  32, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.015071, mae: 1.887703, mean_q: 2.293180, mean_eps: 0.887444\n",
      "  119397/1500000: episode: 172, duration: 21.282s, episode steps: 685, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.016659, mae: 1.883051, mean_q: 2.282791, mean_eps: 0.886899\n",
      "  119890/1500000: episode: 173, duration: 15.337s, episode steps: 493, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.015021, mae: 1.864430, mean_q: 2.260925, mean_eps: 0.886338\n",
      "  120396/1500000: episode: 174, duration: 15.648s, episode steps: 506, steps per second:  32, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.015350, mae: 1.889123, mean_q: 2.294273, mean_eps: 0.885865\n",
      "  121167/1500000: episode: 175, duration: 23.830s, episode steps: 771, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.015417, mae: 1.874829, mean_q: 2.271652, mean_eps: 0.885259\n",
      "  121819/1500000: episode: 176, duration: 20.331s, episode steps: 652, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.014918, mae: 1.907819, mean_q: 2.311556, mean_eps: 0.884583\n",
      "  122288/1500000: episode: 177, duration: 14.566s, episode steps: 469, steps per second:  32, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.014060, mae: 1.887886, mean_q: 2.286990, mean_eps: 0.884051\n",
      "  122859/1500000: episode: 178, duration: 17.747s, episode steps: 571, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.014181, mae: 1.894572, mean_q: 2.295331, mean_eps: 0.883557\n",
      "  123578/1500000: episode: 179, duration: 21.849s, episode steps: 719, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.014253, mae: 1.890605, mean_q: 2.291121, mean_eps: 0.882943\n",
      "  124591/1500000: episode: 180, duration: 29.709s, episode steps: 1013, steps per second:  34, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.016626, mae: 1.872276, mean_q: 2.268031, mean_eps: 0.882120\n",
      "  125197/1500000: episode: 181, duration: 17.842s, episode steps: 606, steps per second:  34, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.018662, mae: 1.923163, mean_q: 2.330216, mean_eps: 0.881351\n",
      "  125862/1500000: episode: 182, duration: 19.662s, episode steps: 665, steps per second:  34, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.015196, mae: 1.968263, mean_q: 2.387828, mean_eps: 0.880747\n",
      "  126606/1500000: episode: 183, duration: 23.132s, episode steps: 744, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.016042, mae: 1.918910, mean_q: 2.327187, mean_eps: 0.880078\n",
      "  127297/1500000: episode: 184, duration: 21.425s, episode steps: 691, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.014460, mae: 1.943278, mean_q: 2.355932, mean_eps: 0.879396\n",
      "  127949/1500000: episode: 185, duration: 20.430s, episode steps: 652, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.015626, mae: 1.938422, mean_q: 2.348756, mean_eps: 0.878757\n",
      "  128321/1500000: episode: 186, duration: 11.691s, episode steps: 372, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.014924, mae: 1.898701, mean_q: 2.301775, mean_eps: 0.878271\n",
      "  129094/1500000: episode: 187, duration: 24.149s, episode steps: 773, steps per second:  32, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.015486, mae: 1.931855, mean_q: 2.341322, mean_eps: 0.877727\n",
      "  129490/1500000: episode: 188, duration: 12.369s, episode steps: 396, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.015871, mae: 1.928089, mean_q: 2.337103, mean_eps: 0.877173\n",
      "  129830/1500000: episode: 189, duration: 10.620s, episode steps: 340, steps per second:  32, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.018491, mae: 1.954479, mean_q: 2.367819, mean_eps: 0.876823\n",
      "  130819/1500000: episode: 190, duration: 31.001s, episode steps: 989, steps per second:  32, episode reward: 27.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.015153, mae: 1.953275, mean_q: 2.366814, mean_eps: 0.876192\n",
      "  131355/1500000: episode: 191, duration: 16.316s, episode steps: 536, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.018391, mae: 1.960967, mean_q: 2.376086, mean_eps: 0.875468\n",
      "  131984/1500000: episode: 192, duration: 19.391s, episode steps: 629, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.017410, mae: 1.972911, mean_q: 2.393300, mean_eps: 0.874915\n",
      "  132680/1500000: episode: 193, duration: 21.502s, episode steps: 696, steps per second:  32, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.016221, mae: 1.949030, mean_q: 2.363416, mean_eps: 0.874287\n",
      "  133599/1500000: episode: 194, duration: 28.575s, episode steps: 919, steps per second:  32, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.015289, mae: 1.946079, mean_q: 2.358435, mean_eps: 0.873519\n",
      "  134394/1500000: episode: 195, duration: 24.933s, episode steps: 795, steps per second:  32, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.016900, mae: 1.976857, mean_q: 2.394676, mean_eps: 0.872704\n",
      "  135125/1500000: episode: 196, duration: 22.595s, episode steps: 731, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.016575, mae: 1.971094, mean_q: 2.389379, mean_eps: 0.871978\n",
      "  135734/1500000: episode: 197, duration: 19.187s, episode steps: 609, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.015883, mae: 1.943960, mean_q: 2.358056, mean_eps: 0.871341\n",
      "  136370/1500000: episode: 198, duration: 19.879s, episode steps: 636, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.017381, mae: 1.949068, mean_q: 2.362308, mean_eps: 0.870751\n",
      "  136889/1500000: episode: 199, duration: 16.010s, episode steps: 519, steps per second:  32, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.018533, mae: 1.958468, mean_q: 2.374201, mean_eps: 0.870201\n",
      "  137531/1500000: episode: 200, duration: 19.871s, episode steps: 642, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.016807, mae: 1.959588, mean_q: 2.375534, mean_eps: 0.869650\n",
      "  138184/1500000: episode: 201, duration: 20.623s, episode steps: 653, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.017100, mae: 1.960363, mean_q: 2.375252, mean_eps: 0.869037\n",
      "  138920/1500000: episode: 202, duration: 22.984s, episode steps: 736, steps per second:  32, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.015792, mae: 1.927516, mean_q: 2.339217, mean_eps: 0.868378\n",
      "  139822/1500000: episode: 203, duration: 28.380s, episode steps: 902, steps per second:  32, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.017118, mae: 1.963434, mean_q: 2.379861, mean_eps: 0.867599\n",
      "  141099/1500000: episode: 204, duration: 38.275s, episode steps: 1277, steps per second:  33, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.015169, mae: 1.972851, mean_q: 2.391573, mean_eps: 0.866563\n",
      "  141993/1500000: episode: 205, duration: 26.665s, episode steps: 894, steps per second:  34, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.017595, mae: 1.966707, mean_q: 2.383810, mean_eps: 0.865531\n",
      "  142504/1500000: episode: 206, duration: 15.792s, episode steps: 511, steps per second:  32, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.015565, mae: 1.968355, mean_q: 2.389241, mean_eps: 0.864864\n",
      "  143356/1500000: episode: 207, duration: 27.656s, episode steps: 852, steps per second:  31, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.017320, mae: 1.981590, mean_q: 2.401752, mean_eps: 0.864218\n",
      "  143979/1500000: episode: 208, duration: 19.798s, episode steps: 623, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.016244, mae: 1.987998, mean_q: 2.411801, mean_eps: 0.863517\n",
      "  144776/1500000: episode: 209, duration: 25.280s, episode steps: 797, steps per second:  32, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.017255, mae: 1.966531, mean_q: 2.383430, mean_eps: 0.862843\n",
      "  145369/1500000: episode: 210, duration: 18.943s, episode steps: 593, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.018066, mae: 2.021253, mean_q: 2.451916, mean_eps: 0.862182\n",
      "  146018/1500000: episode: 211, duration: 20.747s, episode steps: 649, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.017841, mae: 2.034523, mean_q: 2.467868, mean_eps: 0.861591\n",
      "  147186/1500000: episode: 212, duration: 36.565s, episode steps: 1168, steps per second:  32, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.017535, mae: 2.040827, mean_q: 2.473964, mean_eps: 0.860728\n",
      "  147838/1500000: episode: 213, duration: 20.636s, episode steps: 652, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.016518, mae: 2.035917, mean_q: 2.467423, mean_eps: 0.859864\n",
      "  148470/1500000: episode: 214, duration: 18.743s, episode steps: 632, steps per second:  34, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.019289, mae: 2.042328, mean_q: 2.472220, mean_eps: 0.859254\n",
      "  149159/1500000: episode: 215, duration: 21.282s, episode steps: 689, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.015661, mae: 2.017740, mean_q: 2.445986, mean_eps: 0.858627\n",
      "  149754/1500000: episode: 216, duration: 19.007s, episode steps: 595, steps per second:  31, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.015327, mae: 2.032088, mean_q: 2.461012, mean_eps: 0.858017\n",
      "  150533/1500000: episode: 217, duration: 24.063s, episode steps: 779, steps per second:  32, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.018655, mae: 2.029647, mean_q: 2.460384, mean_eps: 0.857363\n",
      "  151260/1500000: episode: 218, duration: 22.668s, episode steps: 727, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.018117, mae: 2.014938, mean_q: 2.442454, mean_eps: 0.856649\n",
      "  151903/1500000: episode: 219, duration: 19.712s, episode steps: 643, steps per second:  33, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.016313, mae: 2.033460, mean_q: 2.460797, mean_eps: 0.855999\n",
      "  153297/1500000: episode: 220, duration: 43.143s, episode steps: 1394, steps per second:  32, episode reward: 17.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.017965, mae: 2.036670, mean_q: 2.465260, mean_eps: 0.855030\n",
      "  153677/1500000: episode: 221, duration: 12.426s, episode steps: 380, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.018209, mae: 2.047906, mean_q: 2.480609, mean_eps: 0.854186\n",
      "  154404/1500000: episode: 222, duration: 22.710s, episode steps: 727, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.017497, mae: 2.034342, mean_q: 2.464356, mean_eps: 0.853662\n",
      "  154986/1500000: episode: 223, duration: 18.533s, episode steps: 582, steps per second:  31, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.015272, mae: 2.048154, mean_q: 2.478877, mean_eps: 0.853041\n",
      "  155656/1500000: episode: 224, duration: 21.334s, episode steps: 670, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.019562, mae: 2.080394, mean_q: 2.519801, mean_eps: 0.852446\n",
      "  156251/1500000: episode: 225, duration: 18.698s, episode steps: 595, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.015496, mae: 2.094828, mean_q: 2.534536, mean_eps: 0.851846\n",
      "  156798/1500000: episode: 226, duration: 17.611s, episode steps: 547, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.015524, mae: 2.074509, mean_q: 2.511161, mean_eps: 0.851302\n",
      "  157196/1500000: episode: 227, duration: 12.660s, episode steps: 398, steps per second:  31, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.016608, mae: 2.103568, mean_q: 2.545908, mean_eps: 0.850854\n",
      "  157705/1500000: episode: 228, duration: 16.586s, episode steps: 509, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.017502, mae: 2.084616, mean_q: 2.524178, mean_eps: 0.850422\n",
      "  158552/1500000: episode: 229, duration: 27.120s, episode steps: 847, steps per second:  31, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.016949, mae: 2.053998, mean_q: 2.485179, mean_eps: 0.849778\n",
      "  159612/1500000: episode: 230, duration: 34.286s, episode steps: 1060, steps per second:  31, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.017399, mae: 2.075386, mean_q: 2.511847, mean_eps: 0.848874\n",
      "  159989/1500000: episode: 231, duration: 11.755s, episode steps: 377, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.706 [0.000, 5.000],  loss: 0.017370, mae: 2.081090, mean_q: 2.515242, mean_eps: 0.848190\n",
      "  160521/1500000: episode: 232, duration: 16.732s, episode steps: 532, steps per second:  32, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.015333, mae: 2.087710, mean_q: 2.528905, mean_eps: 0.847757\n",
      "  161110/1500000: episode: 233, duration: 18.199s, episode steps: 589, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.017243, mae: 2.127907, mean_q: 2.575322, mean_eps: 0.847225\n",
      "  161633/1500000: episode: 234, duration: 16.107s, episode steps: 523, steps per second:  32, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.018698, mae: 2.096457, mean_q: 2.535601, mean_eps: 0.846697\n",
      "  162257/1500000: episode: 235, duration: 19.748s, episode steps: 624, steps per second:  32, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.016146, mae: 2.125941, mean_q: 2.573195, mean_eps: 0.846151\n",
      "  162743/1500000: episode: 236, duration: 15.490s, episode steps: 486, steps per second:  31, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.017384, mae: 2.130384, mean_q: 2.576238, mean_eps: 0.845625\n",
      "  163671/1500000: episode: 237, duration: 29.233s, episode steps: 928, steps per second:  32, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.018502, mae: 2.100520, mean_q: 2.543504, mean_eps: 0.844954\n",
      "  164156/1500000: episode: 238, duration: 15.422s, episode steps: 485, steps per second:  31, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.017207, mae: 2.114382, mean_q: 2.555562, mean_eps: 0.844284\n",
      "  164787/1500000: episode: 239, duration: 19.978s, episode steps: 631, steps per second:  32, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.018547, mae: 2.117813, mean_q: 2.563915, mean_eps: 0.843753\n",
      "  165557/1500000: episode: 240, duration: 24.690s, episode steps: 770, steps per second:  31, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.017871, mae: 2.103109, mean_q: 2.544401, mean_eps: 0.843087\n",
      "  166082/1500000: episode: 241, duration: 17.116s, episode steps: 525, steps per second:  31, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.018196, mae: 2.111266, mean_q: 2.553347, mean_eps: 0.842471\n",
      "  166695/1500000: episode: 242, duration: 19.540s, episode steps: 613, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.020762, mae: 2.112490, mean_q: 2.555381, mean_eps: 0.841931\n",
      "  167504/1500000: episode: 243, duration: 26.086s, episode steps: 809, steps per second:  31, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.018923, mae: 2.130323, mean_q: 2.577514, mean_eps: 0.841257\n",
      "  167878/1500000: episode: 244, duration: 12.169s, episode steps: 374, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.018395, mae: 2.144813, mean_q: 2.596892, mean_eps: 0.840695\n",
      "  168742/1500000: episode: 245, duration: 26.433s, episode steps: 864, steps per second:  33, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.017680, mae: 2.148092, mean_q: 2.599186, mean_eps: 0.840106\n",
      "  169493/1500000: episode: 246, duration: 22.734s, episode steps: 751, steps per second:  33, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.018054, mae: 2.126290, mean_q: 2.572599, mean_eps: 0.839338\n",
      "  170003/1500000: episode: 247, duration: 15.522s, episode steps: 510, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.018972, mae: 2.130944, mean_q: 2.577604, mean_eps: 0.838739\n",
      "  170677/1500000: episode: 248, duration: 20.384s, episode steps: 674, steps per second:  33, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.019017, mae: 2.197478, mean_q: 2.659343, mean_eps: 0.838177\n",
      "  171406/1500000: episode: 249, duration: 24.131s, episode steps: 729, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.017911, mae: 2.198411, mean_q: 2.661177, mean_eps: 0.837510\n",
      "  171994/1500000: episode: 250, duration: 19.058s, episode steps: 588, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.019328, mae: 2.187910, mean_q: 2.648360, mean_eps: 0.836885\n",
      "  172503/1500000: episode: 251, duration: 16.444s, episode steps: 509, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.018292, mae: 2.183248, mean_q: 2.642373, mean_eps: 0.836364\n",
      "  173200/1500000: episode: 252, duration: 22.549s, episode steps: 697, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.020191, mae: 2.151349, mean_q: 2.603115, mean_eps: 0.835792\n",
      "  173765/1500000: episode: 253, duration: 17.742s, episode steps: 565, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.018605, mae: 2.185391, mean_q: 2.644132, mean_eps: 0.835192\n",
      "  174721/1500000: episode: 254, duration: 29.796s, episode steps: 956, steps per second:  32, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.018584, mae: 2.178000, mean_q: 2.633908, mean_eps: 0.834468\n",
      "  175483/1500000: episode: 255, duration: 23.622s, episode steps: 762, steps per second:  32, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.017244, mae: 2.206073, mean_q: 2.669042, mean_eps: 0.833653\n",
      "  176371/1500000: episode: 256, duration: 28.717s, episode steps: 888, steps per second:  31, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.017229, mae: 2.221266, mean_q: 2.688439, mean_eps: 0.832870\n",
      "  176948/1500000: episode: 257, duration: 18.559s, episode steps: 577, steps per second:  31, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.018345, mae: 2.234799, mean_q: 2.705532, mean_eps: 0.832175\n",
      "  178302/1500000: episode: 258, duration: 43.749s, episode steps: 1354, steps per second:  31, episode reward: 28.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.016928, mae: 2.213322, mean_q: 2.676237, mean_eps: 0.831257\n",
      "  178924/1500000: episode: 259, duration: 20.187s, episode steps: 622, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.019671, mae: 2.229781, mean_q: 2.698893, mean_eps: 0.830319\n",
      "  179731/1500000: episode: 260, duration: 26.474s, episode steps: 807, steps per second:  30, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.019454, mae: 2.219898, mean_q: 2.683566, mean_eps: 0.829640\n",
      "  180349/1500000: episode: 261, duration: 20.156s, episode steps: 618, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.019798, mae: 2.215166, mean_q: 2.683950, mean_eps: 0.828962\n",
      "  180846/1500000: episode: 262, duration: 15.608s, episode steps: 497, steps per second:  32, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.243 [0.000, 5.000],  loss: 0.017325, mae: 2.240030, mean_q: 2.709335, mean_eps: 0.828432\n",
      "  181593/1500000: episode: 263, duration: 24.054s, episode steps: 747, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.020594, mae: 2.250601, mean_q: 2.721730, mean_eps: 0.827841\n",
      "  182289/1500000: episode: 264, duration: 22.624s, episode steps: 696, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.018415, mae: 2.221599, mean_q: 2.685528, mean_eps: 0.827155\n",
      "  183174/1500000: episode: 265, duration: 28.716s, episode steps: 885, steps per second:  31, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.017064, mae: 2.224826, mean_q: 2.690758, mean_eps: 0.826405\n",
      "  183942/1500000: episode: 266, duration: 24.725s, episode steps: 768, steps per second:  31, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.018518, mae: 2.240888, mean_q: 2.709326, mean_eps: 0.825620\n",
      "  184991/1500000: episode: 267, duration: 33.810s, episode steps: 1049, steps per second:  31, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.019260, mae: 2.238058, mean_q: 2.704916, mean_eps: 0.824757\n",
      "  185340/1500000: episode: 268, duration: 11.409s, episode steps: 349, steps per second:  31, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.020272, mae: 2.261589, mean_q: 2.741006, mean_eps: 0.824094\n",
      "  186016/1500000: episode: 269, duration: 21.916s, episode steps: 676, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.019632, mae: 2.273723, mean_q: 2.746259, mean_eps: 0.823608\n",
      "  186524/1500000: episode: 270, duration: 16.619s, episode steps: 508, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.016034, mae: 2.301841, mean_q: 2.783750, mean_eps: 0.823045\n",
      "  187475/1500000: episode: 271, duration: 30.812s, episode steps: 951, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.019569, mae: 2.269074, mean_q: 2.740702, mean_eps: 0.822352\n",
      "  188306/1500000: episode: 272, duration: 26.337s, episode steps: 831, steps per second:  32, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.020056, mae: 2.281265, mean_q: 2.755651, mean_eps: 0.821505\n",
      "  188885/1500000: episode: 273, duration: 18.055s, episode steps: 579, steps per second:  32, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.019752, mae: 2.267361, mean_q: 2.737231, mean_eps: 0.820834\n",
      "  189428/1500000: episode: 274, duration: 17.134s, episode steps: 543, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.018965, mae: 2.251750, mean_q: 2.723799, mean_eps: 0.820302\n",
      "  190060/1500000: episode: 275, duration: 20.224s, episode steps: 632, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.019059, mae: 2.250352, mean_q: 2.718245, mean_eps: 0.819745\n",
      "  190679/1500000: episode: 276, duration: 19.476s, episode steps: 619, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.018139, mae: 2.247112, mean_q: 2.715581, mean_eps: 0.819150\n",
      "  191064/1500000: episode: 277, duration: 12.229s, episode steps: 385, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.016678, mae: 2.283177, mean_q: 2.758975, mean_eps: 0.818674\n",
      "  191592/1500000: episode: 278, duration: 17.286s, episode steps: 528, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.021145, mae: 2.266783, mean_q: 2.742545, mean_eps: 0.818240\n",
      "  192010/1500000: episode: 279, duration: 13.321s, episode steps: 418, steps per second:  31, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.017047, mae: 2.270530, mean_q: 2.742885, mean_eps: 0.817790\n",
      "  192592/1500000: episode: 280, duration: 19.322s, episode steps: 582, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.020666, mae: 2.276595, mean_q: 2.748602, mean_eps: 0.817315\n",
      "  193251/1500000: episode: 281, duration: 22.580s, episode steps: 659, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.022141, mae: 2.269052, mean_q: 2.740305, mean_eps: 0.816726\n",
      "  193774/1500000: episode: 282, duration: 17.956s, episode steps: 523, steps per second:  29, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.018124, mae: 2.296642, mean_q: 2.774238, mean_eps: 0.816164\n",
      "  194560/1500000: episode: 283, duration: 26.092s, episode steps: 786, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.018513, mae: 2.304029, mean_q: 2.784453, mean_eps: 0.815542\n",
      "  195857/1500000: episode: 284, duration: 41.606s, episode steps: 1297, steps per second:  31, episode reward: 20.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.016637, mae: 2.306358, mean_q: 2.786095, mean_eps: 0.814552\n",
      "  196619/1500000: episode: 285, duration: 24.361s, episode steps: 762, steps per second:  31, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.018006, mae: 2.294027, mean_q: 2.770755, mean_eps: 0.813574\n",
      "  197380/1500000: episode: 286, duration: 24.958s, episode steps: 761, steps per second:  30, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.017775, mae: 2.303380, mean_q: 2.784771, mean_eps: 0.812852\n",
      "  197843/1500000: episode: 287, duration: 15.358s, episode steps: 463, steps per second:  30, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.016941, mae: 2.293745, mean_q: 2.770420, mean_eps: 0.812271\n",
      "  198820/1500000: episode: 288, duration: 31.481s, episode steps: 977, steps per second:  31, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.019899, mae: 2.325236, mean_q: 2.808464, mean_eps: 0.811586\n",
      "  199416/1500000: episode: 289, duration: 19.262s, episode steps: 596, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.018347, mae: 2.314999, mean_q: 2.796028, mean_eps: 0.810840\n",
      "  199806/1500000: episode: 290, duration: 13.109s, episode steps: 390, steps per second:  30, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.019531, mae: 2.304350, mean_q: 2.781724, mean_eps: 0.810371\n",
      "Step 200000: saving model to dqn_SpaceInvaders-v0_step_200000.h5f\n",
      "  200198/1500000: episode: 291, duration: 12.646s, episode steps: 392, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.014405, mae: 2.309003, mean_q: 2.791546, mean_eps: 0.809998\n",
      "  201164/1500000: episode: 292, duration: 31.160s, episode steps: 966, steps per second:  31, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.018282, mae: 2.349446, mean_q: 2.841465, mean_eps: 0.809354\n",
      "  201548/1500000: episode: 293, duration: 12.585s, episode steps: 384, steps per second:  31, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.022105, mae: 2.372617, mean_q: 2.866006, mean_eps: 0.808714\n",
      "  201945/1500000: episode: 294, duration: 12.632s, episode steps: 397, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.017407, mae: 2.345520, mean_q: 2.832299, mean_eps: 0.808341\n",
      "  202624/1500000: episode: 295, duration: 21.622s, episode steps: 679, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.021644, mae: 2.342200, mean_q: 2.831045, mean_eps: 0.807830\n",
      "  203722/1500000: episode: 296, duration: 35.283s, episode steps: 1098, steps per second:  31, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.020552, mae: 2.371103, mean_q: 2.866277, mean_eps: 0.806987\n",
      "  204486/1500000: episode: 297, duration: 24.508s, episode steps: 764, steps per second:  31, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.022001, mae: 2.330305, mean_q: 2.814364, mean_eps: 0.806101\n",
      "  205594/1500000: episode: 298, duration: 35.388s, episode steps: 1108, steps per second:  31, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.018498, mae: 2.335355, mean_q: 2.823886, mean_eps: 0.805212\n",
      "  206041/1500000: episode: 299, duration: 14.411s, episode steps: 447, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.017146, mae: 2.333475, mean_q: 2.818259, mean_eps: 0.804473\n",
      "  206881/1500000: episode: 300, duration: 26.259s, episode steps: 840, steps per second:  32, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.020154, mae: 2.356326, mean_q: 2.847301, mean_eps: 0.803861\n",
      "  207512/1500000: episode: 301, duration: 19.969s, episode steps: 631, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.016765, mae: 2.327879, mean_q: 2.811373, mean_eps: 0.803164\n",
      "  208016/1500000: episode: 302, duration: 15.925s, episode steps: 504, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.017470, mae: 2.333417, mean_q: 2.816174, mean_eps: 0.802626\n",
      "  208773/1500000: episode: 303, duration: 23.662s, episode steps: 757, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.016706, mae: 2.326921, mean_q: 2.813235, mean_eps: 0.802026\n",
      "  209329/1500000: episode: 304, duration: 16.951s, episode steps: 556, steps per second:  33, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.018233, mae: 2.338462, mean_q: 2.827591, mean_eps: 0.801401\n",
      "  209869/1500000: episode: 305, duration: 15.986s, episode steps: 540, steps per second:  34, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.019683, mae: 2.314552, mean_q: 2.795833, mean_eps: 0.800880\n",
      "  210257/1500000: episode: 306, duration: 11.573s, episode steps: 388, steps per second:  34, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.018956, mae: 2.354599, mean_q: 2.843659, mean_eps: 0.800439\n",
      "  211136/1500000: episode: 307, duration: 26.178s, episode steps: 879, steps per second:  34, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.018446, mae: 2.355770, mean_q: 2.846536, mean_eps: 0.799839\n",
      "  212200/1500000: episode: 308, duration: 31.852s, episode steps: 1064, steps per second:  33, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.018095, mae: 2.354780, mean_q: 2.847550, mean_eps: 0.798917\n",
      "  213038/1500000: episode: 309, duration: 26.276s, episode steps: 838, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.018490, mae: 2.369809, mean_q: 2.864739, mean_eps: 0.798013\n",
      "  213421/1500000: episode: 310, duration: 11.612s, episode steps: 383, steps per second:  33, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.016746, mae: 2.356906, mean_q: 2.848912, mean_eps: 0.797432\n",
      "  214149/1500000: episode: 311, duration: 22.450s, episode steps: 728, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.019394, mae: 2.358624, mean_q: 2.850018, mean_eps: 0.796903\n",
      "  214736/1500000: episode: 312, duration: 18.117s, episode steps: 587, steps per second:  32, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.017929, mae: 2.362691, mean_q: 2.856499, mean_eps: 0.796280\n",
      "  215180/1500000: episode: 313, duration: 14.141s, episode steps: 444, steps per second:  31, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.734 [0.000, 5.000],  loss: 0.017857, mae: 2.377252, mean_q: 2.874890, mean_eps: 0.795792\n",
      "  216088/1500000: episode: 314, duration: 28.548s, episode steps: 908, steps per second:  32, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.018514, mae: 2.394364, mean_q: 2.892985, mean_eps: 0.795150\n",
      "  216473/1500000: episode: 315, duration: 12.223s, episode steps: 385, steps per second:  31, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.019211, mae: 2.399227, mean_q: 2.900840, mean_eps: 0.794534\n",
      "  217105/1500000: episode: 316, duration: 19.579s, episode steps: 632, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.018981, mae: 2.387771, mean_q: 2.885231, mean_eps: 0.794049\n",
      "  217969/1500000: episode: 317, duration: 26.189s, episode steps: 864, steps per second:  33, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.019216, mae: 2.384146, mean_q: 2.882732, mean_eps: 0.793339\n",
      "  218631/1500000: episode: 318, duration: 19.606s, episode steps: 662, steps per second:  34, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.021097, mae: 2.388658, mean_q: 2.884176, mean_eps: 0.792615\n",
      "  219297/1500000: episode: 319, duration: 20.378s, episode steps: 666, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.018761, mae: 2.408738, mean_q: 2.913220, mean_eps: 0.791984\n",
      "  220292/1500000: episode: 320, duration: 31.641s, episode steps: 995, steps per second:  31, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.018836, mae: 2.379612, mean_q: 2.872912, mean_eps: 0.791196\n",
      "  220824/1500000: episode: 321, duration: 16.800s, episode steps: 532, steps per second:  32, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.018638, mae: 2.456964, mean_q: 2.971405, mean_eps: 0.790472\n",
      "  221356/1500000: episode: 322, duration: 16.451s, episode steps: 532, steps per second:  32, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.018772, mae: 2.396107, mean_q: 2.894648, mean_eps: 0.789966\n",
      "  222136/1500000: episode: 323, duration: 24.013s, episode steps: 780, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.019823, mae: 2.430210, mean_q: 2.938115, mean_eps: 0.789343\n",
      "  223219/1500000: episode: 324, duration: 32.855s, episode steps: 1083, steps per second:  33, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.022918, mae: 2.444922, mean_q: 2.953829, mean_eps: 0.788458\n",
      "  224116/1500000: episode: 325, duration: 27.356s, episode steps: 897, steps per second:  33, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.019911, mae: 2.421757, mean_q: 2.926837, mean_eps: 0.787517\n",
      "  225136/1500000: episode: 326, duration: 32.235s, episode steps: 1020, steps per second:  32, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.019127, mae: 2.448615, mean_q: 2.959152, mean_eps: 0.786607\n",
      "  226172/1500000: episode: 327, duration: 32.702s, episode steps: 1036, steps per second:  32, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.019940, mae: 2.438551, mean_q: 2.947851, mean_eps: 0.785631\n",
      "  226561/1500000: episode: 328, duration: 12.386s, episode steps: 389, steps per second:  31, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.018477, mae: 2.411041, mean_q: 2.913575, mean_eps: 0.784952\n",
      "  227263/1500000: episode: 329, duration: 21.724s, episode steps: 702, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.018839, mae: 2.417252, mean_q: 2.922019, mean_eps: 0.784434\n",
      "  227737/1500000: episode: 330, duration: 15.059s, episode steps: 474, steps per second:  31, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.021726, mae: 2.456666, mean_q: 2.969931, mean_eps: 0.783875\n",
      "  228079/1500000: episode: 331, duration: 10.936s, episode steps: 342, steps per second:  31, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.020232, mae: 2.447853, mean_q: 2.959709, mean_eps: 0.783487\n",
      "  228602/1500000: episode: 332, duration: 16.778s, episode steps: 523, steps per second:  31, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.019966, mae: 2.455873, mean_q: 2.967174, mean_eps: 0.783077\n",
      "  229332/1500000: episode: 333, duration: 22.526s, episode steps: 730, steps per second:  32, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.018236, mae: 2.438825, mean_q: 2.949130, mean_eps: 0.782482\n",
      "  229714/1500000: episode: 334, duration: 11.894s, episode steps: 382, steps per second:  32, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.019551, mae: 2.445809, mean_q: 2.951932, mean_eps: 0.781954\n",
      "  230368/1500000: episode: 335, duration: 20.352s, episode steps: 654, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.019982, mae: 2.459784, mean_q: 2.972868, mean_eps: 0.781462\n",
      "  230889/1500000: episode: 336, duration: 16.296s, episode steps: 521, steps per second:  32, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.017902, mae: 2.446827, mean_q: 2.956729, mean_eps: 0.780903\n",
      "  231656/1500000: episode: 337, duration: 23.766s, episode steps: 767, steps per second:  32, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.018583, mae: 2.423827, mean_q: 2.930855, mean_eps: 0.780292\n",
      "  232728/1500000: episode: 338, duration: 33.788s, episode steps: 1072, steps per second:  32, episode reward: 27.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.019195, mae: 2.464813, mean_q: 2.981476, mean_eps: 0.779420\n",
      "  233207/1500000: episode: 339, duration: 15.144s, episode steps: 479, steps per second:  32, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.018429, mae: 2.416691, mean_q: 2.921425, mean_eps: 0.778682\n",
      "  233655/1500000: episode: 340, duration: 14.044s, episode steps: 448, steps per second:  32, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.020088, mae: 2.447460, mean_q: 2.956629, mean_eps: 0.778242\n",
      "  234345/1500000: episode: 341, duration: 21.466s, episode steps: 690, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.019680, mae: 2.404288, mean_q: 2.909842, mean_eps: 0.777700\n",
      "  235130/1500000: episode: 342, duration: 24.560s, episode steps: 785, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.020699, mae: 2.442532, mean_q: 2.955416, mean_eps: 0.776999\n",
      "  236226/1500000: episode: 343, duration: 35.220s, episode steps: 1096, steps per second:  31, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.018657, mae: 2.474612, mean_q: 2.992991, mean_eps: 0.776106\n",
      "  236605/1500000: episode: 344, duration: 12.120s, episode steps: 379, steps per second:  31, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.017084, mae: 2.410268, mean_q: 2.914299, mean_eps: 0.775405\n",
      "  237192/1500000: episode: 345, duration: 18.879s, episode steps: 587, steps per second:  31, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.020930, mae: 2.446696, mean_q: 2.957402, mean_eps: 0.774947\n",
      "  237589/1500000: episode: 346, duration: 12.697s, episode steps: 397, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.017777, mae: 2.461605, mean_q: 2.975711, mean_eps: 0.774479\n",
      "  238356/1500000: episode: 347, duration: 24.285s, episode steps: 767, steps per second:  32, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.020024, mae: 2.482784, mean_q: 3.004085, mean_eps: 0.773927\n",
      "  239157/1500000: episode: 348, duration: 24.940s, episode steps: 801, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.017965, mae: 2.476108, mean_q: 2.991496, mean_eps: 0.773182\n",
      "  239908/1500000: episode: 349, duration: 22.690s, episode steps: 751, steps per second:  33, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.019716, mae: 2.432246, mean_q: 2.937805, mean_eps: 0.772445\n",
      "  240315/1500000: episode: 350, duration: 12.227s, episode steps: 407, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.018360, mae: 2.481061, mean_q: 3.004072, mean_eps: 0.771896\n",
      "  240901/1500000: episode: 351, duration: 17.885s, episode steps: 586, steps per second:  33, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.017639, mae: 2.473956, mean_q: 2.988298, mean_eps: 0.771422\n",
      "  241413/1500000: episode: 352, duration: 15.408s, episode steps: 512, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.017221, mae: 2.459262, mean_q: 2.973740, mean_eps: 0.770900\n",
      "  242103/1500000: episode: 353, duration: 21.372s, episode steps: 690, steps per second:  32, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.020450, mae: 2.481906, mean_q: 3.000878, mean_eps: 0.770330\n",
      "  242926/1500000: episode: 354, duration: 25.237s, episode steps: 823, steps per second:  33, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.019762, mae: 2.471668, mean_q: 2.986849, mean_eps: 0.769612\n",
      "  244077/1500000: episode: 355, duration: 35.245s, episode steps: 1151, steps per second:  33, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.019884, mae: 2.479224, mean_q: 2.997918, mean_eps: 0.768673\n",
      "  244462/1500000: episode: 356, duration: 12.087s, episode steps: 385, steps per second:  32, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.018786, mae: 2.469534, mean_q: 2.992675, mean_eps: 0.767944\n",
      "  245477/1500000: episode: 357, duration: 33.419s, episode steps: 1015, steps per second:  30, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.018762, mae: 2.485456, mean_q: 3.006292, mean_eps: 0.767279\n",
      "  245980/1500000: episode: 358, duration: 16.005s, episode steps: 503, steps per second:  31, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.019257, mae: 2.531305, mean_q: 3.062149, mean_eps: 0.766558\n",
      "  246808/1500000: episode: 359, duration: 25.885s, episode steps: 828, steps per second:  32, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.019974, mae: 2.512756, mean_q: 3.039342, mean_eps: 0.765928\n",
      "  247204/1500000: episode: 360, duration: 12.560s, episode steps: 396, steps per second:  32, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.019701, mae: 2.513884, mean_q: 3.039849, mean_eps: 0.765346\n",
      "  247774/1500000: episode: 361, duration: 18.880s, episode steps: 570, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.021609, mae: 2.518640, mean_q: 3.047212, mean_eps: 0.764886\n",
      "  248169/1500000: episode: 362, duration: 12.719s, episode steps: 395, steps per second:  31, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.022589, mae: 2.520339, mean_q: 3.046683, mean_eps: 0.764427\n",
      "  249269/1500000: episode: 363, duration: 34.849s, episode steps: 1100, steps per second:  32, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.019699, mae: 2.520500, mean_q: 3.047558, mean_eps: 0.763716\n",
      "  249985/1500000: episode: 364, duration: 22.730s, episode steps: 716, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.019746, mae: 2.530408, mean_q: 3.057806, mean_eps: 0.762853\n",
      "  250511/1500000: episode: 365, duration: 16.462s, episode steps: 526, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.020800, mae: 2.566874, mean_q: 3.106478, mean_eps: 0.762264\n",
      "  250921/1500000: episode: 366, duration: 12.839s, episode steps: 410, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.016833, mae: 2.530590, mean_q: 3.055642, mean_eps: 0.761820\n",
      "  251761/1500000: episode: 367, duration: 26.577s, episode steps: 840, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.021045, mae: 2.558262, mean_q: 3.092121, mean_eps: 0.761225\n",
      "  252158/1500000: episode: 368, duration: 12.491s, episode steps: 397, steps per second:  32, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.023478, mae: 2.541672, mean_q: 3.070314, mean_eps: 0.760638\n",
      "  252982/1500000: episode: 369, duration: 26.116s, episode steps: 824, steps per second:  32, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.018974, mae: 2.545936, mean_q: 3.076921, mean_eps: 0.760059\n",
      "  253487/1500000: episode: 370, duration: 16.124s, episode steps: 505, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.021559, mae: 2.590685, mean_q: 3.132347, mean_eps: 0.759428\n",
      "  253914/1500000: episode: 371, duration: 13.332s, episode steps: 427, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.789 [0.000, 5.000],  loss: 0.020435, mae: 2.540278, mean_q: 3.072747, mean_eps: 0.758985\n",
      "  254688/1500000: episode: 372, duration: 24.502s, episode steps: 774, steps per second:  32, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.020433, mae: 2.540363, mean_q: 3.071266, mean_eps: 0.758415\n",
      "  255833/1500000: episode: 373, duration: 36.157s, episode steps: 1145, steps per second:  32, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.020605, mae: 2.581270, mean_q: 3.120868, mean_eps: 0.757503\n",
      "  256747/1500000: episode: 374, duration: 28.685s, episode steps: 914, steps per second:  32, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.019080, mae: 2.595857, mean_q: 3.135095, mean_eps: 0.756525\n",
      "  257310/1500000: episode: 375, duration: 18.204s, episode steps: 563, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.019762, mae: 2.568596, mean_q: 3.105806, mean_eps: 0.755823\n",
      "  257877/1500000: episode: 376, duration: 17.584s, episode steps: 567, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.021650, mae: 2.601206, mean_q: 3.145925, mean_eps: 0.755286\n",
      "  258547/1500000: episode: 377, duration: 20.805s, episode steps: 670, steps per second:  32, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.021387, mae: 2.581252, mean_q: 3.120516, mean_eps: 0.754699\n",
      "  259303/1500000: episode: 378, duration: 23.522s, episode steps: 756, steps per second:  32, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.021256, mae: 2.601978, mean_q: 3.147922, mean_eps: 0.754022\n",
      "  260236/1500000: episode: 379, duration: 29.218s, episode steps: 933, steps per second:  32, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.021977, mae: 2.621141, mean_q: 3.169785, mean_eps: 0.753220\n",
      "  260869/1500000: episode: 380, duration: 19.876s, episode steps: 633, steps per second:  32, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.019677, mae: 2.647910, mean_q: 3.202515, mean_eps: 0.752476\n",
      "  261621/1500000: episode: 381, duration: 23.811s, episode steps: 752, steps per second:  32, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.019170, mae: 2.608304, mean_q: 3.150529, mean_eps: 0.751816\n",
      "  262403/1500000: episode: 382, duration: 25.281s, episode steps: 782, steps per second:  31, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.020543, mae: 2.624468, mean_q: 3.171690, mean_eps: 0.751089\n",
      "  263192/1500000: episode: 383, duration: 25.229s, episode steps: 789, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.021482, mae: 2.620664, mean_q: 3.167523, mean_eps: 0.750344\n",
      "  264344/1500000: episode: 384, duration: 36.519s, episode steps: 1152, steps per second:  32, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.019559, mae: 2.625414, mean_q: 3.175790, mean_eps: 0.749422\n",
      "  265299/1500000: episode: 385, duration: 30.155s, episode steps: 955, steps per second:  32, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.021861, mae: 2.620588, mean_q: 3.166129, mean_eps: 0.748421\n",
      "  265887/1500000: episode: 386, duration: 19.194s, episode steps: 588, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.021583, mae: 2.640176, mean_q: 3.196197, mean_eps: 0.747688\n",
      "  266432/1500000: episode: 387, duration: 18.280s, episode steps: 545, steps per second:  30, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.020699, mae: 2.610343, mean_q: 3.155701, mean_eps: 0.747150\n",
      "  266985/1500000: episode: 388, duration: 18.878s, episode steps: 553, steps per second:  29, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.020819, mae: 2.617780, mean_q: 3.167465, mean_eps: 0.746627\n",
      "  267502/1500000: episode: 389, duration: 17.586s, episode steps: 517, steps per second:  29, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.021109, mae: 2.641255, mean_q: 3.192169, mean_eps: 0.746118\n",
      "  268104/1500000: episode: 390, duration: 19.700s, episode steps: 602, steps per second:  31, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.022500, mae: 2.649193, mean_q: 3.204467, mean_eps: 0.745588\n",
      "  268763/1500000: episode: 391, duration: 21.535s, episode steps: 659, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.024593, mae: 2.628029, mean_q: 3.184493, mean_eps: 0.744990\n",
      "  269227/1500000: episode: 392, duration: 14.619s, episode steps: 464, steps per second:  32, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.019360, mae: 2.636404, mean_q: 3.189129, mean_eps: 0.744456\n",
      "  269876/1500000: episode: 393, duration: 20.820s, episode steps: 649, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.020601, mae: 2.606640, mean_q: 3.149313, mean_eps: 0.743927\n",
      "  270965/1500000: episode: 394, duration: 34.358s, episode steps: 1089, steps per second:  32, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.020126, mae: 2.635127, mean_q: 3.189570, mean_eps: 0.743101\n",
      "  271703/1500000: episode: 395, duration: 23.589s, episode steps: 738, steps per second:  31, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.021911, mae: 2.651878, mean_q: 3.208777, mean_eps: 0.742233\n",
      "  272689/1500000: episode: 396, duration: 31.542s, episode steps: 986, steps per second:  31, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.021166, mae: 2.654355, mean_q: 3.207284, mean_eps: 0.741414\n",
      "  273140/1500000: episode: 397, duration: 14.634s, episode steps: 451, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.882 [0.000, 5.000],  loss: 0.024915, mae: 2.639200, mean_q: 3.190891, mean_eps: 0.740732\n",
      "  274078/1500000: episode: 398, duration: 30.412s, episode steps: 938, steps per second:  31, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.020864, mae: 2.636626, mean_q: 3.184791, mean_eps: 0.740072\n",
      "  274600/1500000: episode: 399, duration: 16.321s, episode steps: 522, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.025574, mae: 2.645757, mean_q: 3.199617, mean_eps: 0.739379\n",
      "  275317/1500000: episode: 400, duration: 21.969s, episode steps: 717, steps per second:  33, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.018124, mae: 2.664394, mean_q: 3.221793, mean_eps: 0.738790\n",
      "  276214/1500000: episode: 401, duration: 27.617s, episode steps: 897, steps per second:  32, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.020459, mae: 2.678438, mean_q: 3.236524, mean_eps: 0.738022\n",
      "  276944/1500000: episode: 402, duration: 22.541s, episode steps: 730, steps per second:  32, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.021619, mae: 2.682968, mean_q: 3.243827, mean_eps: 0.737251\n",
      "  277777/1500000: episode: 403, duration: 26.568s, episode steps: 833, steps per second:  31, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.022740, mae: 2.705129, mean_q: 3.271572, mean_eps: 0.736508\n",
      "  278582/1500000: episode: 404, duration: 26.075s, episode steps: 805, steps per second:  31, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.022087, mae: 2.719126, mean_q: 3.285276, mean_eps: 0.735729\n",
      "  279185/1500000: episode: 405, duration: 19.236s, episode steps: 603, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.025571, mae: 2.684467, mean_q: 3.245896, mean_eps: 0.735060\n",
      "  279674/1500000: episode: 406, duration: 15.728s, episode steps: 489, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.022587, mae: 2.707995, mean_q: 3.279297, mean_eps: 0.734541\n",
      "  281053/1500000: episode: 407, duration: 44.150s, episode steps: 1379, steps per second:  31, episode reward: 25.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.019943, mae: 2.705525, mean_q: 3.273482, mean_eps: 0.733654\n",
      "  281713/1500000: episode: 408, duration: 21.158s, episode steps: 660, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.024368, mae: 2.722482, mean_q: 3.292108, mean_eps: 0.732685\n",
      "  282682/1500000: episode: 409, duration: 30.951s, episode steps: 969, steps per second:  31, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.022366, mae: 2.723599, mean_q: 3.291501, mean_eps: 0.731912\n",
      "  283538/1500000: episode: 410, duration: 27.164s, episode steps: 856, steps per second:  32, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.020976, mae: 2.745810, mean_q: 3.321097, mean_eps: 0.731045\n",
      "  284198/1500000: episode: 411, duration: 20.893s, episode steps: 660, steps per second:  32, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.020021, mae: 2.720268, mean_q: 3.289519, mean_eps: 0.730325\n",
      "  285139/1500000: episode: 412, duration: 30.454s, episode steps: 941, steps per second:  31, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.022045, mae: 2.735991, mean_q: 3.308607, mean_eps: 0.729565\n",
      "  285849/1500000: episode: 413, duration: 22.566s, episode steps: 710, steps per second:  31, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.022204, mae: 2.806875, mean_q: 3.396048, mean_eps: 0.728781\n",
      "  286373/1500000: episode: 414, duration: 16.564s, episode steps: 524, steps per second:  32, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.020873, mae: 2.782065, mean_q: 3.364386, mean_eps: 0.728194\n",
      "  286979/1500000: episode: 415, duration: 18.905s, episode steps: 606, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.025052, mae: 2.804037, mean_q: 3.388953, mean_eps: 0.727658\n",
      "  287757/1500000: episode: 416, duration: 24.412s, episode steps: 778, steps per second:  32, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.023201, mae: 2.784941, mean_q: 3.364201, mean_eps: 0.727000\n",
      "  288426/1500000: episode: 417, duration: 20.973s, episode steps: 669, steps per second:  32, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.023899, mae: 2.763951, mean_q: 3.343198, mean_eps: 0.726313\n",
      "  289370/1500000: episode: 418, duration: 30.842s, episode steps: 944, steps per second:  31, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.023283, mae: 2.783236, mean_q: 3.364843, mean_eps: 0.725547\n",
      "  290229/1500000: episode: 419, duration: 27.663s, episode steps: 859, steps per second:  31, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.021896, mae: 2.784780, mean_q: 3.363277, mean_eps: 0.724690\n",
      "  290825/1500000: episode: 420, duration: 18.752s, episode steps: 596, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.019706, mae: 2.802419, mean_q: 3.386374, mean_eps: 0.723998\n",
      "  291651/1500000: episode: 421, duration: 26.471s, episode steps: 826, steps per second:  31, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.023646, mae: 2.817670, mean_q: 3.406304, mean_eps: 0.723324\n",
      "  292309/1500000: episode: 422, duration: 21.687s, episode steps: 658, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.024556, mae: 2.824815, mean_q: 3.413772, mean_eps: 0.722619\n",
      "  292952/1500000: episode: 423, duration: 20.967s, episode steps: 643, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.021884, mae: 2.812965, mean_q: 3.396771, mean_eps: 0.722002\n",
      "  293346/1500000: episode: 424, duration: 12.547s, episode steps: 394, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.024958, mae: 2.796641, mean_q: 3.373847, mean_eps: 0.721509\n",
      "  293870/1500000: episode: 425, duration: 17.162s, episode steps: 524, steps per second:  31, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.700 [0.000, 5.000],  loss: 0.022265, mae: 2.781192, mean_q: 3.362477, mean_eps: 0.721072\n",
      "  294293/1500000: episode: 426, duration: 13.325s, episode steps: 423, steps per second:  32, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.023452, mae: 2.816925, mean_q: 3.401983, mean_eps: 0.720622\n",
      "  295047/1500000: episode: 427, duration: 24.813s, episode steps: 754, steps per second:  30, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.022769, mae: 2.799983, mean_q: 3.379798, mean_eps: 0.720063\n",
      "  295953/1500000: episode: 428, duration: 30.307s, episode steps: 906, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.025666, mae: 2.848107, mean_q: 3.440324, mean_eps: 0.719275\n",
      "  296567/1500000: episode: 429, duration: 19.733s, episode steps: 614, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.025239, mae: 2.858266, mean_q: 3.451178, mean_eps: 0.718553\n",
      "  297227/1500000: episode: 430, duration: 21.362s, episode steps: 660, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.024226, mae: 2.823908, mean_q: 3.409421, mean_eps: 0.717949\n",
      "  298146/1500000: episode: 431, duration: 29.294s, episode steps: 919, steps per second:  31, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.024239, mae: 2.839967, mean_q: 3.429385, mean_eps: 0.717198\n",
      "  298941/1500000: episode: 432, duration: 25.226s, episode steps: 795, steps per second:  32, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.026932, mae: 2.835940, mean_q: 3.423212, mean_eps: 0.716383\n",
      "  299624/1500000: episode: 433, duration: 22.188s, episode steps: 683, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.022537, mae: 2.808087, mean_q: 3.392680, mean_eps: 0.715682\n",
      "Step 300000: saving model to dqn_SpaceInvaders-v0_step_300000.h5f\n",
      "  300357/1500000: episode: 434, duration: 23.434s, episode steps: 733, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.023174, mae: 2.828080, mean_q: 3.416447, mean_eps: 0.715009\n",
      "  301127/1500000: episode: 435, duration: 24.656s, episode steps: 770, steps per second:  31, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.022058, mae: 2.834961, mean_q: 3.420814, mean_eps: 0.714295\n",
      "  302027/1500000: episode: 436, duration: 29.818s, episode steps: 900, steps per second:  30, episode reward: 24.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.021038, mae: 2.843696, mean_q: 3.433448, mean_eps: 0.713503\n",
      "  303023/1500000: episode: 437, duration: 32.171s, episode steps: 996, steps per second:  31, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.025854, mae: 2.862129, mean_q: 3.455345, mean_eps: 0.712602\n",
      "  303664/1500000: episode: 438, duration: 20.699s, episode steps: 641, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.021716, mae: 2.843635, mean_q: 3.432517, mean_eps: 0.711825\n",
      "  304559/1500000: episode: 439, duration: 28.661s, episode steps: 895, steps per second:  31, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.023362, mae: 2.832382, mean_q: 3.420963, mean_eps: 0.711095\n",
      "  305192/1500000: episode: 440, duration: 20.704s, episode steps: 633, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.021754, mae: 2.824224, mean_q: 3.410216, mean_eps: 0.710370\n",
      "  305647/1500000: episode: 441, duration: 14.476s, episode steps: 455, steps per second:  31, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.022888, mae: 2.895754, mean_q: 3.493075, mean_eps: 0.709853\n",
      "  306366/1500000: episode: 442, duration: 23.299s, episode steps: 719, steps per second:  31, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.022568, mae: 2.904710, mean_q: 3.507700, mean_eps: 0.709294\n",
      "  307385/1500000: episode: 443, duration: 33.027s, episode steps: 1019, steps per second:  31, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.022662, mae: 2.886036, mean_q: 3.486493, mean_eps: 0.708468\n",
      "  307979/1500000: episode: 444, duration: 19.173s, episode steps: 594, steps per second:  31, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.020730, mae: 2.894580, mean_q: 3.496145, mean_eps: 0.707702\n",
      "  308534/1500000: episode: 445, duration: 17.753s, episode steps: 555, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.025564, mae: 2.908330, mean_q: 3.510459, mean_eps: 0.707157\n",
      "  309379/1500000: episode: 446, duration: 26.309s, episode steps: 845, steps per second:  32, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.022106, mae: 2.850699, mean_q: 3.444688, mean_eps: 0.706492\n",
      "  309994/1500000: episode: 447, duration: 19.344s, episode steps: 615, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.026059, mae: 2.885403, mean_q: 3.482581, mean_eps: 0.705798\n",
      "  310464/1500000: episode: 448, duration: 14.791s, episode steps: 470, steps per second:  32, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.253 [0.000, 5.000],  loss: 0.020947, mae: 2.906486, mean_q: 3.511617, mean_eps: 0.705283\n",
      "  310954/1500000: episode: 449, duration: 15.614s, episode steps: 490, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.021916, mae: 2.874185, mean_q: 3.472807, mean_eps: 0.704827\n",
      "  311496/1500000: episode: 450, duration: 17.747s, episode steps: 542, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.022502, mae: 2.887169, mean_q: 3.487139, mean_eps: 0.704337\n",
      "  311991/1500000: episode: 451, duration: 16.157s, episode steps: 495, steps per second:  31, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.023461, mae: 2.914237, mean_q: 3.520895, mean_eps: 0.703845\n",
      "  312363/1500000: episode: 452, duration: 12.241s, episode steps: 372, steps per second:  30, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.026741, mae: 2.880669, mean_q: 3.475977, mean_eps: 0.703433\n",
      "  313049/1500000: episode: 453, duration: 21.935s, episode steps: 686, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.027775, mae: 2.932597, mean_q: 3.542674, mean_eps: 0.702929\n",
      "  313804/1500000: episode: 454, duration: 24.621s, episode steps: 755, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.021808, mae: 2.886041, mean_q: 3.485702, mean_eps: 0.702245\n",
      "  314179/1500000: episode: 455, duration: 12.163s, episode steps: 375, steps per second:  31, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.026435, mae: 2.889020, mean_q: 3.486361, mean_eps: 0.701709\n",
      "  314731/1500000: episode: 456, duration: 17.857s, episode steps: 552, steps per second:  31, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.021069, mae: 2.882748, mean_q: 3.479493, mean_eps: 0.701269\n",
      "  315589/1500000: episode: 457, duration: 27.809s, episode steps: 858, steps per second:  31, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.022788, mae: 2.911397, mean_q: 3.516455, mean_eps: 0.700598\n",
      "  316285/1500000: episode: 458, duration: 22.823s, episode steps: 696, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.022286, mae: 2.920865, mean_q: 3.527568, mean_eps: 0.699859\n",
      "  316703/1500000: episode: 459, duration: 13.335s, episode steps: 418, steps per second:  31, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.023856, mae: 2.954349, mean_q: 3.566979, mean_eps: 0.699331\n",
      "  317744/1500000: episode: 460, duration: 33.671s, episode steps: 1041, steps per second:  31, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.024620, mae: 2.896139, mean_q: 3.496776, mean_eps: 0.698639\n",
      "  318419/1500000: episode: 461, duration: 21.808s, episode steps: 675, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.022924, mae: 2.921253, mean_q: 3.527758, mean_eps: 0.697824\n",
      "  319337/1500000: episode: 462, duration: 29.738s, episode steps: 918, steps per second:  31, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.023262, mae: 2.899197, mean_q: 3.499624, mean_eps: 0.697066\n",
      "  319940/1500000: episode: 463, duration: 19.690s, episode steps: 603, steps per second:  31, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.024789, mae: 2.904849, mean_q: 3.505532, mean_eps: 0.696344\n",
      "  320486/1500000: episode: 464, duration: 17.521s, episode steps: 546, steps per second:  31, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.020755, mae: 2.921325, mean_q: 3.530263, mean_eps: 0.695799\n",
      "  321494/1500000: episode: 465, duration: 32.536s, episode steps: 1008, steps per second:  31, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.024063, mae: 2.939570, mean_q: 3.549098, mean_eps: 0.695060\n",
      "  321901/1500000: episode: 466, duration: 13.341s, episode steps: 407, steps per second:  31, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.019373, mae: 2.967532, mean_q: 3.586204, mean_eps: 0.694387\n",
      "  322536/1500000: episode: 467, duration: 20.647s, episode steps: 635, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.020272, mae: 2.956230, mean_q: 3.570686, mean_eps: 0.693893\n",
      "  323733/1500000: episode: 468, duration: 38.903s, episode steps: 1197, steps per second:  31, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.023436, mae: 2.928105, mean_q: 3.534263, mean_eps: 0.693023\n",
      "  324887/1500000: episode: 469, duration: 37.268s, episode steps: 1154, steps per second:  31, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.025387, mae: 2.979041, mean_q: 3.598260, mean_eps: 0.691905\n",
      "  325287/1500000: episode: 470, duration: 12.601s, episode steps: 400, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.180 [0.000, 5.000],  loss: 0.023595, mae: 2.952505, mean_q: 3.563963, mean_eps: 0.691168\n",
      "  325740/1500000: episode: 471, duration: 14.471s, episode steps: 453, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.021356, mae: 2.931602, mean_q: 3.538505, mean_eps: 0.690764\n",
      "  326454/1500000: episode: 472, duration: 22.659s, episode steps: 714, steps per second:  32, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.870 [0.000, 5.000],  loss: 0.023216, mae: 2.940453, mean_q: 3.550857, mean_eps: 0.690209\n",
      "  327156/1500000: episode: 473, duration: 22.348s, episode steps: 702, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.053 [0.000, 5.000],  loss: 0.024008, mae: 2.962538, mean_q: 3.574263, mean_eps: 0.689536\n",
      "  328244/1500000: episode: 474, duration: 35.403s, episode steps: 1088, steps per second:  31, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.023008, mae: 2.951230, mean_q: 3.566973, mean_eps: 0.688687\n",
      "  328868/1500000: episode: 475, duration: 20.337s, episode steps: 624, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.023570, mae: 2.979619, mean_q: 3.595714, mean_eps: 0.687874\n",
      "  329367/1500000: episode: 476, duration: 16.313s, episode steps: 499, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.025137, mae: 2.930328, mean_q: 3.539318, mean_eps: 0.687340\n",
      "  330019/1500000: episode: 477, duration: 22.202s, episode steps: 652, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.024339, mae: 2.934428, mean_q: 3.544277, mean_eps: 0.686793\n",
      "  330617/1500000: episode: 478, duration: 19.530s, episode steps: 598, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.024414, mae: 3.004411, mean_q: 3.629017, mean_eps: 0.686198\n",
      "  331600/1500000: episode: 479, duration: 31.086s, episode steps: 983, steps per second:  32, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.022998, mae: 2.978504, mean_q: 3.594689, mean_eps: 0.685447\n",
      "  332167/1500000: episode: 480, duration: 18.031s, episode steps: 567, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.028389, mae: 2.979071, mean_q: 3.600953, mean_eps: 0.684712\n",
      "  332756/1500000: episode: 481, duration: 18.350s, episode steps: 589, steps per second:  32, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.740 [0.000, 5.000],  loss: 0.030463, mae: 3.001455, mean_q: 3.621770, mean_eps: 0.684163\n",
      "  333569/1500000: episode: 482, duration: 25.853s, episode steps: 813, steps per second:  31, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.026891, mae: 2.992454, mean_q: 3.611820, mean_eps: 0.683496\n",
      "  334474/1500000: episode: 483, duration: 29.488s, episode steps: 905, steps per second:  31, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.027663, mae: 2.972401, mean_q: 3.586117, mean_eps: 0.682679\n",
      "  335356/1500000: episode: 484, duration: 28.061s, episode steps: 882, steps per second:  31, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.025394, mae: 2.986981, mean_q: 3.607630, mean_eps: 0.681832\n",
      "  335717/1500000: episode: 485, duration: 11.571s, episode steps: 361, steps per second:  31, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.021941, mae: 3.024332, mean_q: 3.653824, mean_eps: 0.681241\n",
      "  336934/1500000: episode: 486, duration: 39.470s, episode steps: 1217, steps per second:  31, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.023250, mae: 3.036627, mean_q: 3.665428, mean_eps: 0.680490\n",
      "  337953/1500000: episode: 487, duration: 32.540s, episode steps: 1019, steps per second:  31, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.024505, mae: 3.043267, mean_q: 3.675268, mean_eps: 0.679428\n",
      "  338457/1500000: episode: 488, duration: 16.114s, episode steps: 504, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.023905, mae: 3.030737, mean_q: 3.659756, mean_eps: 0.678704\n",
      "  338983/1500000: episode: 489, duration: 16.791s, episode steps: 526, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.027827, mae: 3.023514, mean_q: 3.645632, mean_eps: 0.678216\n",
      "  339530/1500000: episode: 490, duration: 17.789s, episode steps: 547, steps per second:  31, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.025770, mae: 3.075926, mean_q: 3.710387, mean_eps: 0.677707\n",
      "  340299/1500000: episode: 491, duration: 24.425s, episode steps: 769, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.025838, mae: 3.046206, mean_q: 3.679204, mean_eps: 0.677082\n",
      "  340665/1500000: episode: 492, duration: 12.236s, episode steps: 366, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.023846, mae: 3.081301, mean_q: 3.722434, mean_eps: 0.676542\n",
      "  341372/1500000: episode: 493, duration: 23.273s, episode steps: 707, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.023601, mae: 3.041024, mean_q: 3.673758, mean_eps: 0.676033\n",
      "  342178/1500000: episode: 494, duration: 27.095s, episode steps: 806, steps per second:  30, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.029075, mae: 3.072472, mean_q: 3.707015, mean_eps: 0.675315\n",
      "  343282/1500000: episode: 495, duration: 37.323s, episode steps: 1104, steps per second:  30, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.024097, mae: 3.021439, mean_q: 3.646805, mean_eps: 0.674406\n",
      "  343778/1500000: episode: 496, duration: 16.798s, episode steps: 496, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.021382, mae: 3.033681, mean_q: 3.666115, mean_eps: 0.673646\n",
      "  344360/1500000: episode: 497, duration: 19.960s, episode steps: 582, steps per second:  29, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.025924, mae: 3.057867, mean_q: 3.689542, mean_eps: 0.673135\n",
      "  345552/1500000: episode: 498, duration: 38.689s, episode steps: 1192, steps per second:  31, episode reward: 29.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.027215, mae: 3.052241, mean_q: 3.685046, mean_eps: 0.672294\n",
      "  346263/1500000: episode: 499, duration: 22.975s, episode steps: 711, steps per second:  31, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.024111, mae: 3.053785, mean_q: 3.692959, mean_eps: 0.671389\n",
      "  346777/1500000: episode: 500, duration: 16.725s, episode steps: 514, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.243 [0.000, 5.000],  loss: 0.024384, mae: 3.096571, mean_q: 3.738317, mean_eps: 0.670806\n",
      "  347643/1500000: episode: 501, duration: 27.722s, episode steps: 866, steps per second:  31, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.024935, mae: 3.058837, mean_q: 3.691709, mean_eps: 0.670150\n",
      "  348276/1500000: episode: 502, duration: 20.644s, episode steps: 633, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.025181, mae: 3.053352, mean_q: 3.688408, mean_eps: 0.669440\n",
      "  349142/1500000: episode: 503, duration: 28.065s, episode steps: 866, steps per second:  31, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.023062, mae: 3.063974, mean_q: 3.698987, mean_eps: 0.668727\n",
      "  349827/1500000: episode: 504, duration: 22.144s, episode steps: 685, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.025075, mae: 3.088365, mean_q: 3.728582, mean_eps: 0.667990\n",
      "  350886/1500000: episode: 505, duration: 34.098s, episode steps: 1059, steps per second:  31, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.020017, mae: 3.059126, mean_q: 3.693037, mean_eps: 0.667162\n",
      "  351875/1500000: episode: 506, duration: 31.205s, episode steps: 989, steps per second:  32, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.023928, mae: 3.069260, mean_q: 3.700041, mean_eps: 0.666189\n",
      "  352743/1500000: episode: 507, duration: 27.701s, episode steps: 868, steps per second:  31, episode reward: 24.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.024669, mae: 3.056616, mean_q: 3.687773, mean_eps: 0.665307\n",
      "  353653/1500000: episode: 508, duration: 29.872s, episode steps: 910, steps per second:  30, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.023756, mae: 3.083790, mean_q: 3.720490, mean_eps: 0.664462\n",
      "  354431/1500000: episode: 509, duration: 25.015s, episode steps: 778, steps per second:  31, episode reward: 25.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.025179, mae: 3.062186, mean_q: 3.697599, mean_eps: 0.663660\n",
      "  355064/1500000: episode: 510, duration: 20.746s, episode steps: 633, steps per second:  31, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.024263, mae: 3.054309, mean_q: 3.690252, mean_eps: 0.662991\n",
      "  355961/1500000: episode: 511, duration: 29.531s, episode steps: 897, steps per second:  30, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.023836, mae: 3.083017, mean_q: 3.724267, mean_eps: 0.662264\n",
      "  356911/1500000: episode: 512, duration: 30.498s, episode steps: 950, steps per second:  31, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.024803, mae: 3.057176, mean_q: 3.688357, mean_eps: 0.661386\n",
      "  357564/1500000: episode: 513, duration: 21.148s, episode steps: 653, steps per second:  31, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.024902, mae: 3.065775, mean_q: 3.706077, mean_eps: 0.660626\n",
      "  358637/1500000: episode: 514, duration: 37.906s, episode steps: 1073, steps per second:  28, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.025529, mae: 3.110205, mean_q: 3.754075, mean_eps: 0.659805\n",
      "  359455/1500000: episode: 515, duration: 27.099s, episode steps: 818, steps per second:  30, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.025860, mae: 3.081846, mean_q: 3.718581, mean_eps: 0.658906\n",
      "  360325/1500000: episode: 516, duration: 28.898s, episode steps: 870, steps per second:  30, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.027197, mae: 3.065881, mean_q: 3.700135, mean_eps: 0.658105\n",
      "  361102/1500000: episode: 517, duration: 25.923s, episode steps: 777, steps per second:  30, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.024306, mae: 3.095260, mean_q: 3.736127, mean_eps: 0.657322\n",
      "  361628/1500000: episode: 518, duration: 18.735s, episode steps: 526, steps per second:  28, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.024963, mae: 3.068678, mean_q: 3.703253, mean_eps: 0.656704\n",
      "  362305/1500000: episode: 519, duration: 23.530s, episode steps: 677, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.025028, mae: 3.067543, mean_q: 3.701884, mean_eps: 0.656132\n",
      "  363339/1500000: episode: 520, duration: 33.827s, episode steps: 1034, steps per second:  31, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.024226, mae: 3.092424, mean_q: 3.729604, mean_eps: 0.655319\n",
      "  364034/1500000: episode: 521, duration: 22.327s, episode steps: 695, steps per second:  31, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.026165, mae: 3.092463, mean_q: 3.732853, mean_eps: 0.654498\n",
      "  364911/1500000: episode: 522, duration: 28.093s, episode steps: 877, steps per second:  31, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.026395, mae: 3.098802, mean_q: 3.737242, mean_eps: 0.653752\n",
      "  365420/1500000: episode: 523, duration: 16.848s, episode steps: 509, steps per second:  30, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.024610, mae: 3.059851, mean_q: 3.692606, mean_eps: 0.653094\n",
      "  366321/1500000: episode: 524, duration: 29.274s, episode steps: 901, steps per second:  31, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.020926, mae: 3.081321, mean_q: 3.720939, mean_eps: 0.652424\n",
      "  367158/1500000: episode: 525, duration: 28.059s, episode steps: 837, steps per second:  30, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.023437, mae: 3.077949, mean_q: 3.711706, mean_eps: 0.651597\n",
      "  367969/1500000: episode: 526, duration: 25.981s, episode steps: 811, steps per second:  31, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.025561, mae: 3.073781, mean_q: 3.707707, mean_eps: 0.650814\n",
      "  369282/1500000: episode: 527, duration: 42.365s, episode steps: 1313, steps per second:  31, episode reward: 39.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.025475, mae: 3.077034, mean_q: 3.711230, mean_eps: 0.649805\n",
      "  369970/1500000: episode: 528, duration: 22.214s, episode steps: 688, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.026284, mae: 3.097791, mean_q: 3.740931, mean_eps: 0.648855\n",
      "  370618/1500000: episode: 529, duration: 21.681s, episode steps: 648, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.023194, mae: 3.053213, mean_q: 3.683512, mean_eps: 0.648221\n",
      "  371552/1500000: episode: 530, duration: 30.624s, episode steps: 934, steps per second:  30, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.029048, mae: 3.072753, mean_q: 3.705895, mean_eps: 0.647470\n",
      "  372196/1500000: episode: 531, duration: 20.567s, episode steps: 644, steps per second:  31, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.024165, mae: 3.067294, mean_q: 3.700947, mean_eps: 0.646722\n",
      "  373069/1500000: episode: 532, duration: 28.142s, episode steps: 873, steps per second:  31, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.025858, mae: 3.057590, mean_q: 3.688291, mean_eps: 0.646000\n",
      "  374671/1500000: episode: 533, duration: 51.527s, episode steps: 1602, steps per second:  31, episode reward: 32.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.024009, mae: 3.052916, mean_q: 3.680310, mean_eps: 0.644824\n",
      "  375612/1500000: episode: 534, duration: 31.520s, episode steps: 941, steps per second:  30, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.023744, mae: 3.064053, mean_q: 3.695224, mean_eps: 0.643617\n",
      "  376370/1500000: episode: 535, duration: 25.998s, episode steps: 758, steps per second:  29, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.024185, mae: 3.023552, mean_q: 3.647432, mean_eps: 0.642810\n",
      "  377412/1500000: episode: 536, duration: 36.352s, episode steps: 1042, steps per second:  29, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.025215, mae: 3.095603, mean_q: 3.732622, mean_eps: 0.641954\n",
      "  377833/1500000: episode: 537, duration: 15.126s, episode steps: 421, steps per second:  28, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.026106, mae: 3.084335, mean_q: 3.722797, mean_eps: 0.641259\n",
      "  378633/1500000: episode: 538, duration: 26.974s, episode steps: 800, steps per second:  30, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.025815, mae: 3.088660, mean_q: 3.727324, mean_eps: 0.640678\n",
      "  379650/1500000: episode: 539, duration: 33.340s, episode steps: 1017, steps per second:  31, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.027645, mae: 3.086200, mean_q: 3.724247, mean_eps: 0.639815\n",
      "  380793/1500000: episode: 540, duration: 38.106s, episode steps: 1143, steps per second:  30, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.026741, mae: 3.052589, mean_q: 3.681299, mean_eps: 0.638789\n",
      "  382010/1500000: episode: 541, duration: 39.767s, episode steps: 1217, steps per second:  31, episode reward: 28.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.024839, mae: 3.079386, mean_q: 3.713300, mean_eps: 0.637668\n",
      "  382873/1500000: episode: 542, duration: 28.758s, episode steps: 863, steps per second:  30, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.026705, mae: 3.069375, mean_q: 3.702572, mean_eps: 0.636680\n",
      "  383450/1500000: episode: 543, duration: 18.417s, episode steps: 577, steps per second:  31, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.735 [0.000, 5.000],  loss: 0.024423, mae: 3.097406, mean_q: 3.736350, mean_eps: 0.635996\n",
      "  384402/1500000: episode: 544, duration: 31.083s, episode steps: 952, steps per second:  31, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.028097, mae: 3.082552, mean_q: 3.720011, mean_eps: 0.635270\n",
      "  385176/1500000: episode: 545, duration: 26.454s, episode steps: 774, steps per second:  29, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.025634, mae: 3.091222, mean_q: 3.726095, mean_eps: 0.634451\n",
      "  385888/1500000: episode: 546, duration: 24.225s, episode steps: 712, steps per second:  29, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.022172, mae: 3.081598, mean_q: 3.715018, mean_eps: 0.633746\n",
      "  386552/1500000: episode: 547, duration: 21.747s, episode steps: 664, steps per second:  31, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.022027, mae: 3.073478, mean_q: 3.707955, mean_eps: 0.633093\n",
      "  387163/1500000: episode: 548, duration: 20.136s, episode steps: 611, steps per second:  30, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.024633, mae: 3.090130, mean_q: 3.725347, mean_eps: 0.632487\n",
      "  387622/1500000: episode: 549, duration: 14.969s, episode steps: 459, steps per second:  31, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.023146, mae: 3.096629, mean_q: 3.737294, mean_eps: 0.631978\n",
      "  388134/1500000: episode: 550, duration: 17.009s, episode steps: 512, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.025897, mae: 3.042718, mean_q: 3.666318, mean_eps: 0.631516\n",
      "  388868/1500000: episode: 551, duration: 24.468s, episode steps: 734, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.023310, mae: 3.096331, mean_q: 3.737277, mean_eps: 0.630925\n",
      "  389872/1500000: episode: 552, duration: 32.811s, episode steps: 1004, steps per second:  31, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.025301, mae: 3.058024, mean_q: 3.686187, mean_eps: 0.630100\n",
      "  390744/1500000: episode: 553, duration: 28.813s, episode steps: 872, steps per second:  30, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.026906, mae: 3.067520, mean_q: 3.698693, mean_eps: 0.629209\n",
      "  391342/1500000: episode: 554, duration: 19.858s, episode steps: 598, steps per second:  30, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.027000, mae: 3.066188, mean_q: 3.697897, mean_eps: 0.628510\n",
      "  391949/1500000: episode: 555, duration: 20.032s, episode steps: 607, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.023786, mae: 3.042617, mean_q: 3.668033, mean_eps: 0.627936\n",
      "  392393/1500000: episode: 556, duration: 14.925s, episode steps: 444, steps per second:  30, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.025603, mae: 3.056807, mean_q: 3.686899, mean_eps: 0.627437\n",
      "  393082/1500000: episode: 557, duration: 23.608s, episode steps: 689, steps per second:  29, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.026012, mae: 3.066710, mean_q: 3.699264, mean_eps: 0.626899\n",
      "  393728/1500000: episode: 558, duration: 22.056s, episode steps: 646, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.027767, mae: 3.049810, mean_q: 3.680123, mean_eps: 0.626266\n",
      "  394607/1500000: episode: 559, duration: 30.490s, episode steps: 879, steps per second:  29, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.023605, mae: 3.038390, mean_q: 3.660580, mean_eps: 0.625542\n",
      "  395280/1500000: episode: 560, duration: 24.597s, episode steps: 673, steps per second:  27, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.022191, mae: 3.064745, mean_q: 3.694005, mean_eps: 0.624805\n",
      "  395967/1500000: episode: 561, duration: 23.034s, episode steps: 687, steps per second:  30, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.020804, mae: 3.077014, mean_q: 3.711434, mean_eps: 0.624159\n",
      "  396727/1500000: episode: 562, duration: 25.454s, episode steps: 760, steps per second:  30, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.024763, mae: 3.082348, mean_q: 3.717553, mean_eps: 0.623471\n",
      "  397926/1500000: episode: 563, duration: 39.627s, episode steps: 1199, steps per second:  30, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.025219, mae: 3.106559, mean_q: 3.742486, mean_eps: 0.622540\n",
      "  399223/1500000: episode: 564, duration: 42.964s, episode steps: 1297, steps per second:  30, episode reward: 25.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.026623, mae: 3.062399, mean_q: 3.690767, mean_eps: 0.621355\n",
      "Step 400000: saving model to dqn_SpaceInvaders-v0_step_400000.h5f\n",
      "  400402/1500000: episode: 565, duration: 39.361s, episode steps: 1179, steps per second:  30, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.024799, mae: 3.080696, mean_q: 3.713843, mean_eps: 0.620179\n",
      "  401469/1500000: episode: 566, duration: 35.359s, episode steps: 1067, steps per second:  30, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.025758, mae: 3.096989, mean_q: 3.733215, mean_eps: 0.619111\n",
      "  401958/1500000: episode: 567, duration: 16.456s, episode steps: 489, steps per second:  30, episode reward: 12.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.025016, mae: 3.093345, mean_q: 3.734180, mean_eps: 0.618372\n",
      "  402473/1500000: episode: 568, duration: 17.225s, episode steps: 515, steps per second:  30, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.025571, mae: 3.070835, mean_q: 3.703550, mean_eps: 0.617895\n",
      "  403098/1500000: episode: 569, duration: 21.071s, episode steps: 625, steps per second:  30, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.024782, mae: 3.074828, mean_q: 3.710194, mean_eps: 0.617353\n",
      "  403751/1500000: episode: 570, duration: 21.666s, episode steps: 653, steps per second:  30, episode reward: 18.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.026369, mae: 3.107748, mean_q: 3.743533, mean_eps: 0.616747\n",
      "  404985/1500000: episode: 571, duration: 40.811s, episode steps: 1234, steps per second:  30, episode reward: 24.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.025989, mae: 3.081846, mean_q: 3.714235, mean_eps: 0.615850\n",
      "  405516/1500000: episode: 572, duration: 17.654s, episode steps: 531, steps per second:  30, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.774 [0.000, 5.000],  loss: 0.025384, mae: 3.079539, mean_q: 3.714166, mean_eps: 0.615012\n",
      "  406027/1500000: episode: 573, duration: 16.826s, episode steps: 511, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.029412, mae: 3.102014, mean_q: 3.738674, mean_eps: 0.614518\n",
      "  407365/1500000: episode: 574, duration: 44.652s, episode steps: 1338, steps per second:  30, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.027180, mae: 3.047995, mean_q: 3.673393, mean_eps: 0.613639\n",
      "  408342/1500000: episode: 575, duration: 33.714s, episode steps: 977, steps per second:  29, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.025958, mae: 3.085537, mean_q: 3.719612, mean_eps: 0.612539\n",
      "  409009/1500000: episode: 576, duration: 23.303s, episode steps: 667, steps per second:  29, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.025112, mae: 3.068844, mean_q: 3.695414, mean_eps: 0.611758\n",
      "  409524/1500000: episode: 577, duration: 17.377s, episode steps: 515, steps per second:  30, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.024779, mae: 3.028630, mean_q: 3.651729, mean_eps: 0.611197\n",
      "  410025/1500000: episode: 578, duration: 17.057s, episode steps: 501, steps per second:  29, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.024273, mae: 3.070633, mean_q: 3.698658, mean_eps: 0.610715\n",
      "  410801/1500000: episode: 579, duration: 26.479s, episode steps: 776, steps per second:  29, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.025824, mae: 3.135342, mean_q: 3.779978, mean_eps: 0.610107\n",
      "  411366/1500000: episode: 580, duration: 19.045s, episode steps: 565, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.027799, mae: 3.062214, mean_q: 3.685878, mean_eps: 0.609470\n",
      "  412024/1500000: episode: 581, duration: 22.955s, episode steps: 658, steps per second:  29, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.031053, mae: 3.083612, mean_q: 3.714764, mean_eps: 0.608891\n",
      "  412616/1500000: episode: 582, duration: 20.592s, episode steps: 592, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.023281, mae: 3.071921, mean_q: 3.700202, mean_eps: 0.608298\n",
      "  413216/1500000: episode: 583, duration: 20.629s, episode steps: 600, steps per second:  29, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.025724, mae: 3.095558, mean_q: 3.730894, mean_eps: 0.607732\n",
      "  413911/1500000: episode: 584, duration: 23.183s, episode steps: 695, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.028327, mae: 3.088091, mean_q: 3.721371, mean_eps: 0.607116\n",
      "  414746/1500000: episode: 585, duration: 27.962s, episode steps: 835, steps per second:  30, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.025108, mae: 3.122299, mean_q: 3.766304, mean_eps: 0.606388\n",
      "  415464/1500000: episode: 586, duration: 24.246s, episode steps: 718, steps per second:  30, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.226 [0.000, 5.000],  loss: 0.023517, mae: 3.094755, mean_q: 3.732316, mean_eps: 0.605651\n",
      "  416365/1500000: episode: 587, duration: 32.570s, episode steps: 901, steps per second:  28, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.026645, mae: 3.101400, mean_q: 3.737278, mean_eps: 0.604882\n",
      "  417276/1500000: episode: 588, duration: 32.629s, episode steps: 911, steps per second:  28, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.026449, mae: 3.119678, mean_q: 3.760230, mean_eps: 0.604021\n",
      "  417963/1500000: episode: 589, duration: 24.362s, episode steps: 687, steps per second:  28, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.027830, mae: 3.134512, mean_q: 3.777996, mean_eps: 0.603263\n",
      "  418548/1500000: episode: 590, duration: 19.207s, episode steps: 585, steps per second:  30, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.028014, mae: 3.109400, mean_q: 3.745350, mean_eps: 0.602659\n",
      "  419453/1500000: episode: 591, duration: 29.735s, episode steps: 905, steps per second:  30, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.025308, mae: 3.121203, mean_q: 3.759735, mean_eps: 0.601950\n",
      "  420485/1500000: episode: 592, duration: 34.039s, episode steps: 1032, steps per second:  30, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.023901, mae: 3.144056, mean_q: 3.791100, mean_eps: 0.601029\n",
      "  421321/1500000: episode: 593, duration: 27.877s, episode steps: 836, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.022784, mae: 3.173505, mean_q: 3.824804, mean_eps: 0.600141\n",
      "  422112/1500000: episode: 594, duration: 26.042s, episode steps: 791, steps per second:  30, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.024612, mae: 3.166477, mean_q: 3.815447, mean_eps: 0.599370\n",
      "  422820/1500000: episode: 595, duration: 22.925s, episode steps: 708, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.026280, mae: 3.153079, mean_q: 3.798310, mean_eps: 0.598659\n",
      "  423570/1500000: episode: 596, duration: 24.412s, episode steps: 750, steps per second:  31, episode reward: 21.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.026078, mae: 3.184357, mean_q: 3.837891, mean_eps: 0.597966\n",
      "  423948/1500000: episode: 597, duration: 12.181s, episode steps: 378, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.019918, mae: 3.176794, mean_q: 3.831728, mean_eps: 0.597430\n",
      "  424430/1500000: episode: 598, duration: 15.752s, episode steps: 482, steps per second:  31, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.025402, mae: 3.181072, mean_q: 3.832564, mean_eps: 0.597021\n",
      "  425125/1500000: episode: 599, duration: 23.826s, episode steps: 695, steps per second:  29, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.023227, mae: 3.169288, mean_q: 3.817566, mean_eps: 0.596461\n",
      "  427024/1500000: episode: 600, duration: 65.183s, episode steps: 1899, steps per second:  29, episode reward: 37.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.024011, mae: 3.161665, mean_q: 3.812430, mean_eps: 0.595230\n",
      "  427676/1500000: episode: 601, duration: 21.435s, episode steps: 652, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.025099, mae: 3.151717, mean_q: 3.798013, mean_eps: 0.594019\n",
      "  428229/1500000: episode: 602, duration: 18.751s, episode steps: 553, steps per second:  29, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.026040, mae: 3.182941, mean_q: 3.835056, mean_eps: 0.593446\n",
      "  429231/1500000: episode: 603, duration: 34.030s, episode steps: 1002, steps per second:  29, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.027281, mae: 3.179070, mean_q: 3.832029, mean_eps: 0.592707\n",
      "  429765/1500000: episode: 604, duration: 18.024s, episode steps: 534, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.023153, mae: 3.198116, mean_q: 3.854568, mean_eps: 0.591977\n",
      "  430362/1500000: episode: 605, duration: 19.926s, episode steps: 597, steps per second:  30, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.023637, mae: 3.214643, mean_q: 3.877588, mean_eps: 0.591439\n",
      "  431309/1500000: episode: 606, duration: 32.338s, episode steps: 947, steps per second:  29, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.026068, mae: 3.239828, mean_q: 3.906932, mean_eps: 0.590706\n",
      "  432088/1500000: episode: 607, duration: 26.562s, episode steps: 779, steps per second:  29, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.025085, mae: 3.221147, mean_q: 3.882286, mean_eps: 0.589887\n",
      "  432972/1500000: episode: 608, duration: 29.478s, episode steps: 884, steps per second:  30, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.025492, mae: 3.241936, mean_q: 3.907569, mean_eps: 0.589098\n",
      "  434008/1500000: episode: 609, duration: 34.724s, episode steps: 1036, steps per second:  30, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.024934, mae: 3.215541, mean_q: 3.875038, mean_eps: 0.588186\n",
      "  434997/1500000: episode: 610, duration: 34.388s, episode steps: 989, steps per second:  29, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.028196, mae: 3.227719, mean_q: 3.890132, mean_eps: 0.587223\n",
      "  435527/1500000: episode: 611, duration: 17.764s, episode steps: 530, steps per second:  30, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.024023, mae: 3.221181, mean_q: 3.883021, mean_eps: 0.586501\n",
      "  436339/1500000: episode: 612, duration: 27.454s, episode steps: 812, steps per second:  30, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.023993, mae: 3.237851, mean_q: 3.903050, mean_eps: 0.585865\n",
      "  437629/1500000: episode: 613, duration: 43.081s, episode steps: 1290, steps per second:  30, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.027718, mae: 3.212033, mean_q: 3.869545, mean_eps: 0.584865\n",
      "  438156/1500000: episode: 614, duration: 17.954s, episode steps: 527, steps per second:  29, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.022077, mae: 3.203726, mean_q: 3.865118, mean_eps: 0.584003\n",
      "  439078/1500000: episode: 615, duration: 30.330s, episode steps: 922, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.025771, mae: 3.206592, mean_q: 3.864070, mean_eps: 0.583315\n",
      "  439470/1500000: episode: 616, duration: 13.617s, episode steps: 392, steps per second:  29, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 3.056 [0.000, 5.000],  loss: 0.021344, mae: 3.183744, mean_q: 3.838799, mean_eps: 0.582690\n",
      "  440380/1500000: episode: 617, duration: 30.258s, episode steps: 910, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.024735, mae: 3.229266, mean_q: 3.891993, mean_eps: 0.582072\n",
      "  441124/1500000: episode: 618, duration: 24.241s, episode steps: 744, steps per second:  31, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.024439, mae: 3.244349, mean_q: 3.910453, mean_eps: 0.581288\n",
      "  442056/1500000: episode: 619, duration: 30.225s, episode steps: 932, steps per second:  31, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.025727, mae: 3.191228, mean_q: 3.845538, mean_eps: 0.580491\n",
      "  443006/1500000: episode: 620, duration: 31.042s, episode steps: 950, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.025411, mae: 3.214677, mean_q: 3.874962, mean_eps: 0.579597\n",
      "  443928/1500000: episode: 621, duration: 32.024s, episode steps: 922, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.024897, mae: 3.200969, mean_q: 3.859111, mean_eps: 0.578707\n",
      "  444956/1500000: episode: 622, duration: 35.136s, episode steps: 1028, steps per second:  29, episode reward: 27.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.021905, mae: 3.203562, mean_q: 3.862595, mean_eps: 0.577782\n",
      "  445909/1500000: episode: 623, duration: 32.287s, episode steps: 953, steps per second:  30, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.024433, mae: 3.247428, mean_q: 3.914188, mean_eps: 0.576840\n",
      "  446404/1500000: episode: 624, duration: 16.724s, episode steps: 495, steps per second:  30, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.023016, mae: 3.208708, mean_q: 3.870209, mean_eps: 0.576152\n",
      "  447292/1500000: episode: 625, duration: 30.344s, episode steps: 888, steps per second:  29, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.028236, mae: 3.258813, mean_q: 3.928934, mean_eps: 0.575496\n",
      "  448016/1500000: episode: 626, duration: 24.567s, episode steps: 724, steps per second:  29, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.024094, mae: 3.249974, mean_q: 3.918770, mean_eps: 0.574731\n",
      "  448913/1500000: episode: 627, duration: 30.725s, episode steps: 897, steps per second:  29, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.026299, mae: 3.234732, mean_q: 3.896385, mean_eps: 0.573959\n",
      "  449531/1500000: episode: 628, duration: 21.074s, episode steps: 618, steps per second:  29, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: 0.027784, mae: 3.225130, mean_q: 3.887269, mean_eps: 0.573239\n",
      "  450170/1500000: episode: 629, duration: 21.887s, episode steps: 639, steps per second:  29, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.023932, mae: 3.236729, mean_q: 3.905197, mean_eps: 0.572642\n",
      "  450728/1500000: episode: 630, duration: 18.794s, episode steps: 558, steps per second:  30, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.029398, mae: 3.280524, mean_q: 3.953958, mean_eps: 0.572074\n",
      "  451367/1500000: episode: 631, duration: 21.410s, episode steps: 639, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.024525, mae: 3.256869, mean_q: 3.925396, mean_eps: 0.571506\n",
      "  452141/1500000: episode: 632, duration: 25.969s, episode steps: 774, steps per second:  30, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.028463, mae: 3.281109, mean_q: 3.953589, mean_eps: 0.570834\n",
      "  453488/1500000: episode: 633, duration: 44.720s, episode steps: 1347, steps per second:  30, episode reward: 26.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.026679, mae: 3.270637, mean_q: 3.939798, mean_eps: 0.569827\n",
      "  454262/1500000: episode: 634, duration: 25.081s, episode steps: 774, steps per second:  31, episode reward: 23.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.028072, mae: 3.233937, mean_q: 3.895157, mean_eps: 0.568820\n",
      "  454977/1500000: episode: 635, duration: 23.446s, episode steps: 715, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.024314, mae: 3.234066, mean_q: 3.898022, mean_eps: 0.568111\n",
      "  455640/1500000: episode: 636, duration: 22.491s, episode steps: 663, steps per second:  29, episode reward: 17.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.021915, mae: 3.257515, mean_q: 3.927261, mean_eps: 0.567457\n",
      "  456721/1500000: episode: 637, duration: 35.990s, episode steps: 1081, steps per second:  30, episode reward: 27.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.025522, mae: 3.242642, mean_q: 3.908547, mean_eps: 0.566629\n",
      "  457457/1500000: episode: 638, duration: 24.505s, episode steps: 736, steps per second:  30, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.025572, mae: 3.240726, mean_q: 3.906036, mean_eps: 0.565765\n",
      "  457967/1500000: episode: 639, duration: 16.883s, episode steps: 510, steps per second:  30, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.024106, mae: 3.242817, mean_q: 3.912681, mean_eps: 0.565174\n",
      "  458901/1500000: episode: 640, duration: 31.403s, episode steps: 934, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.027067, mae: 3.253705, mean_q: 3.923612, mean_eps: 0.564488\n",
      "  459561/1500000: episode: 641, duration: 21.966s, episode steps: 660, steps per second:  30, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.025772, mae: 3.244572, mean_q: 3.912018, mean_eps: 0.563730\n",
      "  459996/1500000: episode: 642, duration: 14.267s, episode steps: 435, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.023224, mae: 3.234265, mean_q: 3.895292, mean_eps: 0.563211\n",
      "  461346/1500000: episode: 643, duration: 45.516s, episode steps: 1350, steps per second:  30, episode reward: 28.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.023678, mae: 3.263284, mean_q: 3.935557, mean_eps: 0.562364\n",
      "  462326/1500000: episode: 644, duration: 33.582s, episode steps: 980, steps per second:  29, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.025789, mae: 3.261584, mean_q: 3.935101, mean_eps: 0.561256\n",
      "  462767/1500000: episode: 645, duration: 15.000s, episode steps: 441, steps per second:  29, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.027243, mae: 3.286544, mean_q: 3.961661, mean_eps: 0.560581\n",
      "  463485/1500000: episode: 646, duration: 23.974s, episode steps: 718, steps per second:  30, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.028254, mae: 3.282197, mean_q: 3.955976, mean_eps: 0.560030\n",
      "  464121/1500000: episode: 647, duration: 20.948s, episode steps: 636, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.022518, mae: 3.255931, mean_q: 3.926526, mean_eps: 0.559386\n",
      "  464743/1500000: episode: 648, duration: 20.210s, episode steps: 622, steps per second:  31, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.026046, mae: 3.278565, mean_q: 3.949342, mean_eps: 0.558790\n",
      "  465778/1500000: episode: 649, duration: 33.417s, episode steps: 1035, steps per second:  31, episode reward: 27.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.025223, mae: 3.257743, mean_q: 3.924519, mean_eps: 0.558003\n",
      "  466842/1500000: episode: 650, duration: 36.106s, episode steps: 1064, steps per second:  29, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.025098, mae: 3.280245, mean_q: 3.953956, mean_eps: 0.557005\n",
      "  467397/1500000: episode: 651, duration: 18.312s, episode steps: 555, steps per second:  30, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.025882, mae: 3.266534, mean_q: 3.936763, mean_eps: 0.556236\n",
      "  468085/1500000: episode: 652, duration: 23.619s, episode steps: 688, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.025010, mae: 3.265648, mean_q: 3.933895, mean_eps: 0.555645\n",
      "  469258/1500000: episode: 653, duration: 40.527s, episode steps: 1173, steps per second:  29, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.026572, mae: 3.248388, mean_q: 3.914092, mean_eps: 0.554762\n",
      "  469796/1500000: episode: 654, duration: 18.020s, episode steps: 538, steps per second:  30, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.027495, mae: 3.248336, mean_q: 3.913740, mean_eps: 0.553950\n",
      "  470702/1500000: episode: 655, duration: 30.718s, episode steps: 906, steps per second:  29, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.025833, mae: 3.271817, mean_q: 3.941021, mean_eps: 0.553264\n",
      "  471608/1500000: episode: 656, duration: 30.596s, episode steps: 906, steps per second:  30, episode reward: 25.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.001 [0.000, 5.000],  loss: 0.021631, mae: 3.256850, mean_q: 3.926608, mean_eps: 0.552404\n",
      "  472536/1500000: episode: 657, duration: 31.987s, episode steps: 928, steps per second:  29, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.022404, mae: 3.284221, mean_q: 3.956436, mean_eps: 0.551534\n",
      "  473469/1500000: episode: 658, duration: 31.450s, episode steps: 933, steps per second:  30, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.025883, mae: 3.305703, mean_q: 3.983294, mean_eps: 0.550648\n",
      "  474300/1500000: episode: 659, duration: 28.422s, episode steps: 831, steps per second:  29, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.028746, mae: 3.280797, mean_q: 3.952886, mean_eps: 0.549810\n",
      "  475257/1500000: episode: 660, duration: 32.472s, episode steps: 957, steps per second:  29, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.024382, mae: 3.274823, mean_q: 3.949031, mean_eps: 0.548961\n",
      "  475806/1500000: episode: 661, duration: 18.287s, episode steps: 549, steps per second:  30, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.024236, mae: 3.289882, mean_q: 3.969580, mean_eps: 0.548245\n",
      "  476428/1500000: episode: 662, duration: 20.696s, episode steps: 622, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.146 [0.000, 5.000],  loss: 0.024385, mae: 3.280108, mean_q: 3.956008, mean_eps: 0.547690\n",
      "  477395/1500000: episode: 663, duration: 32.066s, episode steps: 967, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.062 [0.000, 5.000],  loss: 0.022023, mae: 3.274324, mean_q: 3.947757, mean_eps: 0.546935\n",
      "  478034/1500000: episode: 664, duration: 21.269s, episode steps: 639, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.239 [0.000, 5.000],  loss: 0.026369, mae: 3.277284, mean_q: 3.951847, mean_eps: 0.546172\n",
      "  478735/1500000: episode: 665, duration: 23.147s, episode steps: 701, steps per second:  30, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.021800, mae: 3.256411, mean_q: 3.925866, mean_eps: 0.545535\n",
      "  479688/1500000: episode: 666, duration: 31.827s, episode steps: 953, steps per second:  30, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.025523, mae: 3.311457, mean_q: 3.990140, mean_eps: 0.544751\n",
      "  480648/1500000: episode: 667, duration: 32.188s, episode steps: 960, steps per second:  30, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.025739, mae: 3.273956, mean_q: 3.946844, mean_eps: 0.543842\n",
      "  481109/1500000: episode: 668, duration: 15.452s, episode steps: 461, steps per second:  30, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.021009, mae: 3.273046, mean_q: 3.946405, mean_eps: 0.543166\n",
      "  481613/1500000: episode: 669, duration: 16.661s, episode steps: 504, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.026900, mae: 3.284665, mean_q: 3.958695, mean_eps: 0.542706\n",
      "  482306/1500000: episode: 670, duration: 23.060s, episode steps: 693, steps per second:  30, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.025116, mae: 3.292993, mean_q: 3.973217, mean_eps: 0.542138\n",
      "  483334/1500000: episode: 671, duration: 34.396s, episode steps: 1028, steps per second:  30, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.025977, mae: 3.276801, mean_q: 3.950495, mean_eps: 0.541321\n",
      "  484268/1500000: episode: 672, duration: 31.166s, episode steps: 934, steps per second:  30, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.026286, mae: 3.269533, mean_q: 3.939639, mean_eps: 0.540390\n",
      "  484817/1500000: episode: 673, duration: 18.269s, episode steps: 549, steps per second:  30, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.025034, mae: 3.310087, mean_q: 3.989721, mean_eps: 0.539685\n",
      "  485796/1500000: episode: 674, duration: 32.695s, episode steps: 979, steps per second:  30, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.025976, mae: 3.274589, mean_q: 3.949053, mean_eps: 0.538959\n",
      "  486460/1500000: episode: 675, duration: 22.704s, episode steps: 664, steps per second:  29, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.027323, mae: 3.265769, mean_q: 3.936214, mean_eps: 0.538180\n",
      "  487440/1500000: episode: 676, duration: 33.273s, episode steps: 980, steps per second:  29, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.023901, mae: 3.296091, mean_q: 3.975154, mean_eps: 0.537399\n",
      "  488342/1500000: episode: 677, duration: 30.266s, episode steps: 902, steps per second:  30, episode reward: 24.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.027101, mae: 3.291917, mean_q: 3.968860, mean_eps: 0.536505\n",
      "  489059/1500000: episode: 678, duration: 23.996s, episode steps: 717, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.025747, mae: 3.273192, mean_q: 3.943396, mean_eps: 0.535735\n",
      "  490403/1500000: episode: 679, duration: 43.839s, episode steps: 1344, steps per second:  31, episode reward: 31.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.025951, mae: 3.294176, mean_q: 3.969625, mean_eps: 0.534757\n",
      "  491344/1500000: episode: 680, duration: 30.622s, episode steps: 941, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.024664, mae: 3.305876, mean_q: 3.985977, mean_eps: 0.533672\n",
      "  492042/1500000: episode: 681, duration: 23.708s, episode steps: 698, steps per second:  29, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.022771, mae: 3.300366, mean_q: 3.982666, mean_eps: 0.532893\n",
      "  493154/1500000: episode: 682, duration: 36.667s, episode steps: 1112, steps per second:  30, episode reward: 25.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.024212, mae: 3.298992, mean_q: 3.979311, mean_eps: 0.532032\n",
      "  494197/1500000: episode: 683, duration: 34.685s, episode steps: 1043, steps per second:  30, episode reward: 29.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.026193, mae: 3.311061, mean_q: 3.993370, mean_eps: 0.531008\n",
      "  495091/1500000: episode: 684, duration: 30.340s, episode steps: 894, steps per second:  29, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.021625, mae: 3.295262, mean_q: 3.972239, mean_eps: 0.530088\n",
      "  496062/1500000: episode: 685, duration: 33.725s, episode steps: 971, steps per second:  29, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.025183, mae: 3.330898, mean_q: 4.012637, mean_eps: 0.529203\n",
      "  496710/1500000: episode: 686, duration: 21.648s, episode steps: 648, steps per second:  30, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.022453, mae: 3.342231, mean_q: 4.031429, mean_eps: 0.528433\n",
      "  497414/1500000: episode: 687, duration: 23.840s, episode steps: 704, steps per second:  30, episode reward: 19.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.025586, mae: 3.319023, mean_q: 4.001918, mean_eps: 0.527791\n",
      "  498380/1500000: episode: 688, duration: 32.834s, episode steps: 966, steps per second:  29, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.025909, mae: 3.338309, mean_q: 4.028109, mean_eps: 0.526999\n",
      "  499036/1500000: episode: 689, duration: 22.306s, episode steps: 656, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.027409, mae: 3.329574, mean_q: 4.016158, mean_eps: 0.526229\n",
      "  499642/1500000: episode: 690, duration: 20.598s, episode steps: 606, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.025782, mae: 3.302794, mean_q: 3.982541, mean_eps: 0.525629\n",
      "Step 500000: saving model to dqn_SpaceInvaders-v0_step_500000.h5f\n",
      "  500725/1500000: episode: 691, duration: 37.130s, episode steps: 1083, steps per second:  29, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.024774, mae: 3.341182, mean_q: 4.032616, mean_eps: 0.524825\n",
      "  501484/1500000: episode: 692, duration: 27.118s, episode steps: 759, steps per second:  28, episode reward: 19.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.025439, mae: 3.349354, mean_q: 4.037051, mean_eps: 0.523951\n",
      "  502191/1500000: episode: 693, duration: 24.672s, episode steps: 707, steps per second:  29, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.025451, mae: 3.324574, mean_q: 4.006440, mean_eps: 0.523256\n",
      "  502689/1500000: episode: 694, duration: 16.793s, episode steps: 498, steps per second:  30, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.027940, mae: 3.336535, mean_q: 4.024299, mean_eps: 0.522682\n",
      "  503405/1500000: episode: 695, duration: 24.643s, episode steps: 716, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.024279, mae: 3.328682, mean_q: 4.014306, mean_eps: 0.522104\n",
      "  504024/1500000: episode: 696, duration: 20.974s, episode steps: 619, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.025951, mae: 3.343145, mean_q: 4.032144, mean_eps: 0.521472\n",
      "  504646/1500000: episode: 697, duration: 20.252s, episode steps: 622, steps per second:  31, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.022947, mae: 3.343743, mean_q: 4.037600, mean_eps: 0.520883\n",
      "  505634/1500000: episode: 698, duration: 32.427s, episode steps: 988, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.026156, mae: 3.371752, mean_q: 4.067634, mean_eps: 0.520117\n",
      "  506366/1500000: episode: 699, duration: 24.648s, episode steps: 732, steps per second:  30, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.025054, mae: 3.369970, mean_q: 4.064640, mean_eps: 0.519300\n",
      "  506899/1500000: episode: 700, duration: 17.585s, episode steps: 533, steps per second:  30, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.021208, mae: 3.389979, mean_q: 4.093823, mean_eps: 0.518700\n",
      "  507536/1500000: episode: 701, duration: 20.954s, episode steps: 637, steps per second:  30, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.027672, mae: 3.377667, mean_q: 4.074582, mean_eps: 0.518145\n",
      "  508476/1500000: episode: 702, duration: 31.382s, episode steps: 940, steps per second:  30, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.024494, mae: 3.372093, mean_q: 4.066451, mean_eps: 0.517396\n",
      "  509306/1500000: episode: 703, duration: 27.475s, episode steps: 830, steps per second:  30, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.029015, mae: 3.401224, mean_q: 4.104773, mean_eps: 0.516554\n",
      "  510291/1500000: episode: 704, duration: 34.054s, episode steps: 985, steps per second:  29, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.027648, mae: 3.382240, mean_q: 4.079148, mean_eps: 0.515692\n",
      "  511470/1500000: episode: 705, duration: 39.772s, episode steps: 1179, steps per second:  30, episode reward: 29.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.027161, mae: 3.387290, mean_q: 4.084324, mean_eps: 0.514664\n",
      "  512068/1500000: episode: 706, duration: 20.592s, episode steps: 598, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.028978, mae: 3.378432, mean_q: 4.073180, mean_eps: 0.513820\n",
      "  512800/1500000: episode: 707, duration: 24.087s, episode steps: 732, steps per second:  30, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.030785, mae: 3.392762, mean_q: 4.091628, mean_eps: 0.513190\n",
      "  514157/1500000: episode: 708, duration: 45.501s, episode steps: 1357, steps per second:  30, episode reward: 31.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.028558, mae: 3.393127, mean_q: 4.089065, mean_eps: 0.512196\n",
      "  514981/1500000: episode: 709, duration: 27.471s, episode steps: 824, steps per second:  30, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.030151, mae: 3.386081, mean_q: 4.080571, mean_eps: 0.511158\n",
      "  515865/1500000: episode: 710, duration: 29.925s, episode steps: 884, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.146 [0.000, 5.000],  loss: 0.027511, mae: 3.430973, mean_q: 4.137205, mean_eps: 0.510347\n",
      "  516714/1500000: episode: 711, duration: 27.889s, episode steps: 849, steps per second:  30, episode reward: 27.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.028927, mae: 3.419079, mean_q: 4.123743, mean_eps: 0.509525\n",
      "  517476/1500000: episode: 712, duration: 25.106s, episode steps: 762, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.028664, mae: 3.401896, mean_q: 4.100854, mean_eps: 0.508761\n",
      "  518632/1500000: episode: 713, duration: 38.680s, episode steps: 1156, steps per second:  30, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.760 [0.000, 5.000],  loss: 0.026661, mae: 3.413420, mean_q: 4.114743, mean_eps: 0.507851\n",
      "  519575/1500000: episode: 714, duration: 31.589s, episode steps: 943, steps per second:  30, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.030233, mae: 3.413796, mean_q: 4.113548, mean_eps: 0.506853\n",
      "  520079/1500000: episode: 715, duration: 17.343s, episode steps: 504, steps per second:  29, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.782 [0.000, 5.000],  loss: 0.028781, mae: 3.400168, mean_q: 4.100547, mean_eps: 0.506165\n",
      "  520762/1500000: episode: 716, duration: 23.474s, episode steps: 683, steps per second:  29, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.023727, mae: 3.432636, mean_q: 4.141585, mean_eps: 0.505601\n",
      "  521471/1500000: episode: 717, duration: 23.536s, episode steps: 709, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.028918, mae: 3.444184, mean_q: 4.152333, mean_eps: 0.504940\n",
      "  522076/1500000: episode: 718, duration: 20.100s, episode steps: 605, steps per second:  30, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.132 [0.000, 5.000],  loss: 0.026678, mae: 3.431696, mean_q: 4.135463, mean_eps: 0.504317\n",
      "  522969/1500000: episode: 719, duration: 29.366s, episode steps: 893, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.028401, mae: 3.468121, mean_q: 4.181806, mean_eps: 0.503604\n",
      "  523660/1500000: episode: 720, duration: 23.275s, episode steps: 691, steps per second:  30, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.031122, mae: 3.458376, mean_q: 4.170282, mean_eps: 0.502852\n",
      "  524474/1500000: episode: 721, duration: 28.014s, episode steps: 814, steps per second:  29, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.031780, mae: 3.464082, mean_q: 4.179739, mean_eps: 0.502137\n",
      "  525092/1500000: episode: 722, duration: 20.429s, episode steps: 618, steps per second:  30, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.026357, mae: 3.468311, mean_q: 4.183260, mean_eps: 0.501457\n",
      "  525598/1500000: episode: 723, duration: 16.819s, episode steps: 506, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.025215, mae: 3.488335, mean_q: 4.209320, mean_eps: 0.500923\n",
      "  526114/1500000: episode: 724, duration: 17.221s, episode steps: 516, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.025563, mae: 3.508132, mean_q: 4.234674, mean_eps: 0.500437\n",
      "  526772/1500000: episode: 725, duration: 21.991s, episode steps: 658, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.025633, mae: 3.479016, mean_q: 4.198456, mean_eps: 0.499880\n",
      "  527594/1500000: episode: 726, duration: 27.157s, episode steps: 822, steps per second:  30, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.024953, mae: 3.501252, mean_q: 4.223735, mean_eps: 0.499177\n",
      "  528484/1500000: episode: 727, duration: 30.546s, episode steps: 890, steps per second:  29, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.025303, mae: 3.486186, mean_q: 4.208970, mean_eps: 0.498364\n",
      "  529187/1500000: episode: 728, duration: 23.322s, episode steps: 703, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.030411, mae: 3.508642, mean_q: 4.234180, mean_eps: 0.497608\n",
      "  530458/1500000: episode: 729, duration: 42.801s, episode steps: 1271, steps per second:  30, episode reward: 27.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.027113, mae: 3.494606, mean_q: 4.219188, mean_eps: 0.496669\n",
      "  531355/1500000: episode: 730, duration: 29.847s, episode steps: 897, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.826 [0.000, 5.000],  loss: 0.030101, mae: 3.490858, mean_q: 4.211734, mean_eps: 0.495639\n",
      "  531959/1500000: episode: 731, duration: 20.323s, episode steps: 604, steps per second:  30, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.032832, mae: 3.503029, mean_q: 4.223566, mean_eps: 0.494927\n",
      "  532874/1500000: episode: 732, duration: 30.281s, episode steps: 915, steps per second:  30, episode reward: 26.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: 0.029891, mae: 3.511460, mean_q: 4.234787, mean_eps: 0.494205\n",
      "  533882/1500000: episode: 733, duration: 33.674s, episode steps: 1008, steps per second:  30, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.031125, mae: 3.509408, mean_q: 4.229990, mean_eps: 0.493291\n",
      "  534764/1500000: episode: 734, duration: 28.534s, episode steps: 882, steps per second:  31, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.032865, mae: 3.509318, mean_q: 4.228701, mean_eps: 0.492394\n",
      "  535276/1500000: episode: 735, duration: 16.988s, episode steps: 512, steps per second:  30, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.027972, mae: 3.490273, mean_q: 4.208067, mean_eps: 0.491733\n",
      "  536106/1500000: episode: 736, duration: 27.007s, episode steps: 830, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.028012, mae: 3.535552, mean_q: 4.265604, mean_eps: 0.491095\n",
      "  536803/1500000: episode: 737, duration: 23.273s, episode steps: 697, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.075 [0.000, 5.000],  loss: 0.028111, mae: 3.517493, mean_q: 4.245479, mean_eps: 0.490369\n",
      "  537812/1500000: episode: 738, duration: 35.010s, episode steps: 1009, steps per second:  29, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.032693, mae: 3.513842, mean_q: 4.237365, mean_eps: 0.489559\n",
      "  538751/1500000: episode: 739, duration: 34.368s, episode steps: 939, steps per second:  27, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.029550, mae: 3.514748, mean_q: 4.237674, mean_eps: 0.488634\n",
      "  539314/1500000: episode: 740, duration: 19.846s, episode steps: 563, steps per second:  28, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.032346, mae: 3.523137, mean_q: 4.248708, mean_eps: 0.487920\n",
      "  540028/1500000: episode: 741, duration: 25.540s, episode steps: 714, steps per second:  28, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.029337, mae: 3.550119, mean_q: 4.285771, mean_eps: 0.487314\n",
      "  540690/1500000: episode: 742, duration: 24.106s, episode steps: 662, steps per second:  27, episode reward: 19.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.026272, mae: 3.524503, mean_q: 4.247108, mean_eps: 0.486660\n",
      "  541424/1500000: episode: 743, duration: 25.115s, episode steps: 734, steps per second:  29, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.030109, mae: 3.514217, mean_q: 4.237154, mean_eps: 0.485997\n",
      "  542322/1500000: episode: 744, duration: 30.574s, episode steps: 898, steps per second:  29, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.024144, mae: 3.506052, mean_q: 4.228108, mean_eps: 0.485222\n",
      "  542963/1500000: episode: 745, duration: 21.220s, episode steps: 641, steps per second:  30, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.033261, mae: 3.507202, mean_q: 4.227584, mean_eps: 0.484490\n",
      "  543831/1500000: episode: 746, duration: 29.917s, episode steps: 868, steps per second:  29, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.032540, mae: 3.515953, mean_q: 4.237369, mean_eps: 0.483774\n",
      "  544378/1500000: episode: 747, duration: 18.856s, episode steps: 547, steps per second:  29, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.029288, mae: 3.491942, mean_q: 4.214017, mean_eps: 0.483101\n",
      "  545249/1500000: episode: 748, duration: 29.838s, episode steps: 871, steps per second:  29, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.028261, mae: 3.537982, mean_q: 4.270895, mean_eps: 0.482427\n",
      "  545930/1500000: episode: 749, duration: 23.668s, episode steps: 681, steps per second:  29, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.029508, mae: 3.638680, mean_q: 4.393399, mean_eps: 0.481689\n",
      "  546625/1500000: episode: 750, duration: 23.607s, episode steps: 695, steps per second:  29, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.028140, mae: 3.603614, mean_q: 4.353492, mean_eps: 0.481036\n",
      "  547154/1500000: episode: 751, duration: 18.204s, episode steps: 529, steps per second:  29, episode reward: 13.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.033062, mae: 3.548265, mean_q: 4.282174, mean_eps: 0.480455\n",
      "  547685/1500000: episode: 752, duration: 17.997s, episode steps: 531, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.066 [0.000, 5.000],  loss: 0.035535, mae: 3.594058, mean_q: 4.337214, mean_eps: 0.479951\n",
      "  548553/1500000: episode: 753, duration: 28.336s, episode steps: 868, steps per second:  31, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.032713, mae: 3.597523, mean_q: 4.340214, mean_eps: 0.479286\n",
      "  549217/1500000: episode: 754, duration: 21.615s, episode steps: 664, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.033348, mae: 3.552142, mean_q: 4.283505, mean_eps: 0.478558\n",
      "  550118/1500000: episode: 755, duration: 29.546s, episode steps: 901, steps per second:  30, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.029307, mae: 3.602418, mean_q: 4.344196, mean_eps: 0.477815\n",
      "  551193/1500000: episode: 756, duration: 36.686s, episode steps: 1075, steps per second:  29, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.026783, mae: 3.625235, mean_q: 4.375479, mean_eps: 0.476877\n",
      "  552113/1500000: episode: 757, duration: 31.394s, episode steps: 920, steps per second:  29, episode reward: 28.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.026183, mae: 3.604439, mean_q: 4.351729, mean_eps: 0.475929\n",
      "  552731/1500000: episode: 758, duration: 20.723s, episode steps: 618, steps per second:  30, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.025724, mae: 3.618453, mean_q: 4.366590, mean_eps: 0.475199\n",
      "  553474/1500000: episode: 759, duration: 25.239s, episode steps: 743, steps per second:  29, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.030050, mae: 3.627884, mean_q: 4.374121, mean_eps: 0.474553\n",
      "  554184/1500000: episode: 760, duration: 24.042s, episode steps: 710, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.025320, mae: 3.632148, mean_q: 4.387131, mean_eps: 0.473863\n",
      "  554752/1500000: episode: 761, duration: 19.464s, episode steps: 568, steps per second:  29, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.030158, mae: 3.623857, mean_q: 4.372253, mean_eps: 0.473257\n",
      "  555269/1500000: episode: 762, duration: 17.834s, episode steps: 517, steps per second:  29, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.029953, mae: 3.617597, mean_q: 4.365210, mean_eps: 0.472741\n",
      "  555992/1500000: episode: 763, duration: 25.336s, episode steps: 723, steps per second:  29, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.028459, mae: 3.641946, mean_q: 4.398208, mean_eps: 0.472151\n",
      "  556669/1500000: episode: 764, duration: 23.934s, episode steps: 677, steps per second:  28, episode reward: 17.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.027743, mae: 3.663223, mean_q: 4.419344, mean_eps: 0.471487\n",
      "  557288/1500000: episode: 765, duration: 22.231s, episode steps: 619, steps per second:  28, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.026462, mae: 3.631499, mean_q: 4.382157, mean_eps: 0.470871\n",
      "  557767/1500000: episode: 766, duration: 16.886s, episode steps: 479, steps per second:  28, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.025421, mae: 3.646916, mean_q: 4.400885, mean_eps: 0.470350\n",
      "  559510/1500000: episode: 767, duration: 61.361s, episode steps: 1743, steps per second:  28, episode reward: 33.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.030602, mae: 3.644920, mean_q: 4.397674, mean_eps: 0.469294\n",
      "  560274/1500000: episode: 768, duration: 26.589s, episode steps: 764, steps per second:  29, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.025031, mae: 3.676001, mean_q: 4.434083, mean_eps: 0.468103\n",
      "  560659/1500000: episode: 769, duration: 13.389s, episode steps: 385, steps per second:  29, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.028471, mae: 3.639986, mean_q: 4.392123, mean_eps: 0.467557\n",
      "  561465/1500000: episode: 770, duration: 27.709s, episode steps: 806, steps per second:  29, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.024118, mae: 3.639195, mean_q: 4.393010, mean_eps: 0.466991\n",
      "  562161/1500000: episode: 771, duration: 24.114s, episode steps: 696, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.068 [0.000, 5.000],  loss: 0.028268, mae: 3.645551, mean_q: 4.402392, mean_eps: 0.466277\n",
      "  562954/1500000: episode: 772, duration: 27.665s, episode steps: 793, steps per second:  29, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.852 [0.000, 5.000],  loss: 0.030213, mae: 3.653871, mean_q: 4.407053, mean_eps: 0.465570\n",
      "  563666/1500000: episode: 773, duration: 24.242s, episode steps: 712, steps per second:  29, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.027646, mae: 3.654555, mean_q: 4.409960, mean_eps: 0.464855\n",
      "  564580/1500000: episode: 774, duration: 30.244s, episode steps: 914, steps per second:  30, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.028974, mae: 3.675079, mean_q: 4.432498, mean_eps: 0.464084\n",
      "  565626/1500000: episode: 775, duration: 35.265s, episode steps: 1046, steps per second:  30, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.026575, mae: 3.637422, mean_q: 4.389160, mean_eps: 0.463153\n",
      "  566286/1500000: episode: 776, duration: 22.446s, episode steps: 660, steps per second:  29, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.027747, mae: 3.634397, mean_q: 4.382261, mean_eps: 0.462342\n",
      "  567223/1500000: episode: 777, duration: 33.463s, episode steps: 937, steps per second:  28, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.026023, mae: 3.655219, mean_q: 4.412217, mean_eps: 0.461584\n",
      "  567891/1500000: episode: 778, duration: 23.167s, episode steps: 668, steps per second:  29, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.026467, mae: 3.656148, mean_q: 4.409039, mean_eps: 0.460822\n",
      "  568844/1500000: episode: 779, duration: 33.366s, episode steps: 953, steps per second:  29, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.027345, mae: 3.650647, mean_q: 4.405565, mean_eps: 0.460052\n",
      "  569365/1500000: episode: 780, duration: 18.163s, episode steps: 521, steps per second:  29, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.028306, mae: 3.684376, mean_q: 4.441948, mean_eps: 0.459351\n",
      "  570515/1500000: episode: 781, duration: 39.909s, episode steps: 1150, steps per second:  29, episode reward: 32.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.024824, mae: 3.663611, mean_q: 4.421063, mean_eps: 0.458557\n",
      "  571418/1500000: episode: 782, duration: 31.383s, episode steps: 903, steps per second:  29, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.025364, mae: 3.665967, mean_q: 4.424006, mean_eps: 0.457582\n",
      "  571936/1500000: episode: 783, duration: 17.551s, episode steps: 518, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.788 [0.000, 5.000],  loss: 0.029914, mae: 3.673668, mean_q: 4.426240, mean_eps: 0.456908\n",
      "  572832/1500000: episode: 784, duration: 29.524s, episode steps: 896, steps per second:  30, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.025464, mae: 3.674713, mean_q: 4.429871, mean_eps: 0.456237\n",
      "  573557/1500000: episode: 785, duration: 24.649s, episode steps: 725, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.029670, mae: 3.676033, mean_q: 4.429812, mean_eps: 0.455466\n",
      "  574265/1500000: episode: 786, duration: 23.704s, episode steps: 708, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.026980, mae: 3.664485, mean_q: 4.420217, mean_eps: 0.454784\n",
      "  575616/1500000: episode: 787, duration: 44.754s, episode steps: 1351, steps per second:  30, episode reward: 32.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.030264, mae: 3.669947, mean_q: 4.427617, mean_eps: 0.453807\n",
      "  576294/1500000: episode: 788, duration: 22.144s, episode steps: 678, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.025677, mae: 3.682479, mean_q: 4.443282, mean_eps: 0.452844\n",
      "  576988/1500000: episode: 789, duration: 23.169s, episode steps: 694, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.026210, mae: 3.652196, mean_q: 4.405496, mean_eps: 0.452192\n",
      "  578537/1500000: episode: 790, duration: 50.491s, episode steps: 1549, steps per second:  31, episode reward: 33.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.028133, mae: 3.696177, mean_q: 4.458126, mean_eps: 0.451126\n",
      "  579288/1500000: episode: 791, duration: 25.427s, episode steps: 751, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.029401, mae: 3.675214, mean_q: 4.435749, mean_eps: 0.450034\n",
      "  579975/1500000: episode: 792, duration: 23.534s, episode steps: 687, steps per second:  29, episode reward: 17.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.025221, mae: 3.690057, mean_q: 4.452192, mean_eps: 0.449351\n",
      "  580740/1500000: episode: 793, duration: 26.181s, episode steps: 765, steps per second:  29, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.996 [0.000, 5.000],  loss: 0.029095, mae: 3.694025, mean_q: 4.451740, mean_eps: 0.448662\n",
      "  581766/1500000: episode: 794, duration: 34.816s, episode steps: 1026, steps per second:  29, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.025941, mae: 3.716625, mean_q: 4.481583, mean_eps: 0.447811\n",
      "  582587/1500000: episode: 795, duration: 27.083s, episode steps: 821, steps per second:  30, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.027287, mae: 3.694705, mean_q: 4.458686, mean_eps: 0.446933\n",
      "  583220/1500000: episode: 796, duration: 21.400s, episode steps: 633, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.766 [0.000, 5.000],  loss: 0.030213, mae: 3.705787, mean_q: 4.473609, mean_eps: 0.446243\n",
      "  584009/1500000: episode: 797, duration: 26.817s, episode steps: 789, steps per second:  29, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.026068, mae: 3.717743, mean_q: 4.481944, mean_eps: 0.445567\n",
      "  584896/1500000: episode: 798, duration: 30.768s, episode steps: 887, steps per second:  29, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.028258, mae: 3.709812, mean_q: 4.473368, mean_eps: 0.444771\n",
      "  585543/1500000: episode: 799, duration: 21.746s, episode steps: 647, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.026560, mae: 3.787369, mean_q: 4.568901, mean_eps: 0.444043\n",
      "  586177/1500000: episode: 800, duration: 21.030s, episode steps: 634, steps per second:  30, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.028526, mae: 3.748194, mean_q: 4.522322, mean_eps: 0.443433\n",
      "  587126/1500000: episode: 801, duration: 31.841s, episode steps: 949, steps per second:  30, episode reward: 26.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.028971, mae: 3.748376, mean_q: 4.517159, mean_eps: 0.442681\n",
      "  587849/1500000: episode: 802, duration: 25.131s, episode steps: 723, steps per second:  29, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.025426, mae: 3.717274, mean_q: 4.482143, mean_eps: 0.441886\n",
      "  589003/1500000: episode: 803, duration: 41.325s, episode steps: 1154, steps per second:  28, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.030560, mae: 3.766914, mean_q: 4.544540, mean_eps: 0.440995\n",
      "  589624/1500000: episode: 804, duration: 21.519s, episode steps: 621, steps per second:  29, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.834 [0.000, 5.000],  loss: 0.030535, mae: 3.748534, mean_q: 4.522980, mean_eps: 0.440154\n",
      "  590375/1500000: episode: 805, duration: 26.411s, episode steps: 751, steps per second:  28, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.026057, mae: 3.758415, mean_q: 4.535382, mean_eps: 0.439502\n",
      "  590858/1500000: episode: 806, duration: 17.614s, episode steps: 483, steps per second:  27, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.026866, mae: 3.745842, mean_q: 4.511924, mean_eps: 0.438915\n",
      "  591456/1500000: episode: 807, duration: 20.475s, episode steps: 598, steps per second:  29, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.025186, mae: 3.729221, mean_q: 4.500013, mean_eps: 0.438402\n",
      "  592008/1500000: episode: 808, duration: 19.306s, episode steps: 552, steps per second:  29, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.026356, mae: 3.739232, mean_q: 4.513310, mean_eps: 0.437857\n",
      "  593077/1500000: episode: 809, duration: 36.068s, episode steps: 1069, steps per second:  30, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.024937, mae: 3.737433, mean_q: 4.510295, mean_eps: 0.437085\n",
      "  594055/1500000: episode: 810, duration: 33.076s, episode steps: 978, steps per second:  30, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.031735, mae: 3.760545, mean_q: 4.534008, mean_eps: 0.436112\n",
      "  594675/1500000: episode: 811, duration: 20.389s, episode steps: 620, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.026472, mae: 3.773530, mean_q: 4.556102, mean_eps: 0.435354\n",
      "  595373/1500000: episode: 812, duration: 23.086s, episode steps: 698, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.027468, mae: 3.748176, mean_q: 4.519745, mean_eps: 0.434727\n",
      "  596374/1500000: episode: 813, duration: 32.781s, episode steps: 1001, steps per second:  31, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.027754, mae: 3.760273, mean_q: 4.534886, mean_eps: 0.433920\n",
      "  597261/1500000: episode: 814, duration: 30.319s, episode steps: 887, steps per second:  29, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.027339, mae: 3.754899, mean_q: 4.529109, mean_eps: 0.433023\n",
      "  597996/1500000: episode: 815, duration: 25.072s, episode steps: 735, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.113 [0.000, 5.000],  loss: 0.029457, mae: 3.756028, mean_q: 4.534147, mean_eps: 0.432253\n",
      "  598819/1500000: episode: 816, duration: 28.285s, episode steps: 823, steps per second:  29, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.029760, mae: 3.729731, mean_q: 4.495114, mean_eps: 0.431514\n",
      "  599760/1500000: episode: 817, duration: 32.364s, episode steps: 941, steps per second:  29, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.028925, mae: 3.756151, mean_q: 4.530373, mean_eps: 0.430676\n",
      "Step 600000: saving model to dqn_SpaceInvaders-v0_step_600000.h5f\n",
      "  600347/1500000: episode: 818, duration: 22.226s, episode steps: 587, steps per second:  26, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.029719, mae: 3.727879, mean_q: 4.495816, mean_eps: 0.429951\n",
      "  600967/1500000: episode: 819, duration: 22.309s, episode steps: 620, steps per second:  28, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.048 [0.000, 5.000],  loss: 0.029366, mae: 3.729605, mean_q: 4.492954, mean_eps: 0.429377\n",
      "  601476/1500000: episode: 820, duration: 18.406s, episode steps: 509, steps per second:  28, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.031153, mae: 3.757673, mean_q: 4.534702, mean_eps: 0.428841\n",
      "  602000/1500000: episode: 821, duration: 18.041s, episode steps: 524, steps per second:  29, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.027448, mae: 3.754411, mean_q: 4.526115, mean_eps: 0.428351\n",
      "  602907/1500000: episode: 822, duration: 30.758s, episode steps: 907, steps per second:  29, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.028543, mae: 3.761935, mean_q: 4.537795, mean_eps: 0.427671\n",
      "  603789/1500000: episode: 823, duration: 30.324s, episode steps: 882, steps per second:  29, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.026775, mae: 3.735014, mean_q: 4.503878, mean_eps: 0.426819\n",
      "  604317/1500000: episode: 824, duration: 18.599s, episode steps: 528, steps per second:  28, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.029403, mae: 3.756820, mean_q: 4.531052, mean_eps: 0.426149\n",
      "  605119/1500000: episode: 825, duration: 27.277s, episode steps: 802, steps per second:  29, episode reward: 23.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.025605, mae: 3.742056, mean_q: 4.514219, mean_eps: 0.425518\n",
      "  605800/1500000: episode: 826, duration: 23.288s, episode steps: 681, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.029417, mae: 3.723757, mean_q: 4.490150, mean_eps: 0.424815\n",
      "  606862/1500000: episode: 827, duration: 36.420s, episode steps: 1062, steps per second:  29, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.029157, mae: 3.763769, mean_q: 4.540350, mean_eps: 0.423986\n",
      "  607402/1500000: episode: 828, duration: 19.064s, episode steps: 540, steps per second:  28, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.026091, mae: 3.796863, mean_q: 4.575552, mean_eps: 0.423225\n",
      "  608506/1500000: episode: 829, duration: 37.757s, episode steps: 1104, steps per second:  29, episode reward: 29.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.028618, mae: 3.793792, mean_q: 4.572700, mean_eps: 0.422444\n",
      "  609214/1500000: episode: 830, duration: 25.198s, episode steps: 708, steps per second:  28, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.033268, mae: 3.788642, mean_q: 4.566128, mean_eps: 0.421583\n",
      "  610054/1500000: episode: 831, duration: 28.893s, episode steps: 840, steps per second:  29, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.032068, mae: 3.770155, mean_q: 4.542663, mean_eps: 0.420848\n",
      "  610936/1500000: episode: 832, duration: 30.016s, episode steps: 882, steps per second:  29, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.028472, mae: 3.746039, mean_q: 4.515611, mean_eps: 0.420031\n",
      "  611610/1500000: episode: 833, duration: 23.355s, episode steps: 674, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.029488, mae: 3.766430, mean_q: 4.545181, mean_eps: 0.419292\n",
      "  612236/1500000: episode: 834, duration: 21.327s, episode steps: 626, steps per second:  29, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.899 [0.000, 5.000],  loss: 0.030420, mae: 3.771286, mean_q: 4.550559, mean_eps: 0.418674\n",
      "  613130/1500000: episode: 835, duration: 31.389s, episode steps: 894, steps per second:  28, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.029415, mae: 3.793983, mean_q: 4.577042, mean_eps: 0.417952\n",
      "  613735/1500000: episode: 836, duration: 21.335s, episode steps: 605, steps per second:  28, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.873 [0.000, 5.000],  loss: 0.030888, mae: 3.775170, mean_q: 4.553491, mean_eps: 0.417240\n",
      "  614409/1500000: episode: 837, duration: 23.792s, episode steps: 674, steps per second:  28, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.033875, mae: 3.766036, mean_q: 4.541023, mean_eps: 0.416632\n",
      "  615082/1500000: episode: 838, duration: 25.086s, episode steps: 673, steps per second:  27, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.926 [0.000, 5.000],  loss: 0.028936, mae: 3.757429, mean_q: 4.529279, mean_eps: 0.415991\n",
      "  615812/1500000: episode: 839, duration: 26.782s, episode steps: 730, steps per second:  27, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.027502, mae: 3.811202, mean_q: 4.596657, mean_eps: 0.415326\n",
      "  617044/1500000: episode: 840, duration: 43.161s, episode steps: 1232, steps per second:  29, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.675 [0.000, 5.000],  loss: 0.026054, mae: 3.809599, mean_q: 4.593724, mean_eps: 0.414395\n",
      "  617585/1500000: episode: 841, duration: 19.170s, episode steps: 541, steps per second:  28, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.176 [0.000, 5.000],  loss: 0.029343, mae: 3.802674, mean_q: 4.582898, mean_eps: 0.413552\n",
      "  618100/1500000: episode: 842, duration: 17.896s, episode steps: 515, steps per second:  29, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.028487, mae: 3.786521, mean_q: 4.571409, mean_eps: 0.413050\n",
      "  618686/1500000: episode: 843, duration: 21.007s, episode steps: 586, steps per second:  28, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.029282, mae: 3.801676, mean_q: 4.582932, mean_eps: 0.412528\n",
      "  619338/1500000: episode: 844, duration: 22.688s, episode steps: 652, steps per second:  29, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.030311, mae: 3.803641, mean_q: 4.585440, mean_eps: 0.411939\n",
      "  620142/1500000: episode: 845, duration: 28.197s, episode steps: 804, steps per second:  29, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.028994, mae: 3.807972, mean_q: 4.592334, mean_eps: 0.411247\n",
      "  621183/1500000: episode: 846, duration: 36.247s, episode steps: 1041, steps per second:  29, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.029950, mae: 3.827865, mean_q: 4.613467, mean_eps: 0.410371\n",
      "  622162/1500000: episode: 847, duration: 32.987s, episode steps: 979, steps per second:  30, episode reward: 26.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.027453, mae: 3.851694, mean_q: 4.640843, mean_eps: 0.409412\n",
      "  622584/1500000: episode: 848, duration: 14.388s, episode steps: 422, steps per second:  29, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.161 [0.000, 5.000],  loss: 0.028159, mae: 3.839495, mean_q: 4.628244, mean_eps: 0.408747\n",
      "  623610/1500000: episode: 849, duration: 35.353s, episode steps: 1026, steps per second:  29, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.026306, mae: 3.840237, mean_q: 4.630700, mean_eps: 0.408059\n",
      "  624271/1500000: episode: 850, duration: 22.446s, episode steps: 661, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.027568, mae: 3.833741, mean_q: 4.622912, mean_eps: 0.407257\n",
      "  624944/1500000: episode: 851, duration: 23.116s, episode steps: 673, steps per second:  29, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.025366, mae: 3.824295, mean_q: 4.612763, mean_eps: 0.406624\n",
      "  625678/1500000: episode: 852, duration: 25.733s, episode steps: 734, steps per second:  29, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.745 [0.000, 5.000],  loss: 0.030397, mae: 3.912484, mean_q: 4.719317, mean_eps: 0.405956\n",
      "  626359/1500000: episode: 853, duration: 24.191s, episode steps: 681, steps per second:  28, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.024522, mae: 3.876518, mean_q: 4.680430, mean_eps: 0.405283\n",
      "  626729/1500000: episode: 854, duration: 12.572s, episode steps: 370, steps per second:  29, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.857 [0.000, 5.000],  loss: 0.026503, mae: 3.844319, mean_q: 4.642344, mean_eps: 0.404783\n",
      "  627717/1500000: episode: 855, duration: 33.047s, episode steps: 988, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.031335, mae: 3.864852, mean_q: 4.656710, mean_eps: 0.404137\n",
      "  628365/1500000: episode: 856, duration: 21.833s, episode steps: 648, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.029318, mae: 3.889603, mean_q: 4.689741, mean_eps: 0.403360\n",
      "  629437/1500000: episode: 857, duration: 35.800s, episode steps: 1072, steps per second:  30, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.027407, mae: 3.882979, mean_q: 4.683711, mean_eps: 0.402543\n",
      "  630113/1500000: episode: 858, duration: 22.457s, episode steps: 676, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.044 [0.000, 5.000],  loss: 0.028516, mae: 3.851453, mean_q: 4.644549, mean_eps: 0.401713\n",
      "  630828/1500000: episode: 859, duration: 23.927s, episode steps: 715, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.029255, mae: 3.863870, mean_q: 4.662391, mean_eps: 0.401053\n",
      "  631731/1500000: episode: 860, duration: 30.128s, episode steps: 903, steps per second:  30, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.027159, mae: 3.878390, mean_q: 4.676542, mean_eps: 0.400286\n",
      "  632358/1500000: episode: 861, duration: 21.213s, episode steps: 627, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.896 [0.000, 5.000],  loss: 0.025227, mae: 3.863354, mean_q: 4.658890, mean_eps: 0.399558\n",
      "  633662/1500000: episode: 862, duration: 45.770s, episode steps: 1304, steps per second:  28, episode reward: 24.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.027382, mae: 3.864248, mean_q: 4.658684, mean_eps: 0.398641\n",
      "  634475/1500000: episode: 863, duration: 28.431s, episode steps: 813, steps per second:  29, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.030378, mae: 3.863844, mean_q: 4.655110, mean_eps: 0.397635\n",
      "  635105/1500000: episode: 864, duration: 22.729s, episode steps: 630, steps per second:  28, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.026033, mae: 3.844568, mean_q: 4.634712, mean_eps: 0.396950\n",
      "  635984/1500000: episode: 865, duration: 31.217s, episode steps: 879, steps per second:  28, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.027650, mae: 3.885673, mean_q: 4.682828, mean_eps: 0.396233\n",
      "  636621/1500000: episode: 866, duration: 21.596s, episode steps: 637, steps per second:  29, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.025332, mae: 3.855927, mean_q: 4.653114, mean_eps: 0.395513\n",
      "  637547/1500000: episode: 867, duration: 31.343s, episode steps: 926, steps per second:  30, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.025306, mae: 3.879860, mean_q: 4.676578, mean_eps: 0.394770\n",
      "  638020/1500000: episode: 868, duration: 16.270s, episode steps: 473, steps per second:  29, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.619 [0.000, 5.000],  loss: 0.025236, mae: 3.845005, mean_q: 4.636013, mean_eps: 0.394107\n",
      "  639069/1500000: episode: 869, duration: 36.165s, episode steps: 1049, steps per second:  29, episode reward: 26.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.879 [0.000, 5.000],  loss: 0.029668, mae: 3.885323, mean_q: 4.684602, mean_eps: 0.393383\n",
      "  639451/1500000: episode: 870, duration: 13.425s, episode steps: 382, steps per second:  28, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.032968, mae: 3.887653, mean_q: 4.690424, mean_eps: 0.392703\n",
      "  639989/1500000: episode: 871, duration: 18.283s, episode steps: 538, steps per second:  29, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.029437, mae: 3.884823, mean_q: 4.684254, mean_eps: 0.392266\n",
      "  640892/1500000: episode: 872, duration: 30.432s, episode steps: 903, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.023797, mae: 3.918707, mean_q: 4.727695, mean_eps: 0.391582\n",
      "  642326/1500000: episode: 873, duration: 49.634s, episode steps: 1434, steps per second:  29, episode reward: 23.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.026212, mae: 3.911515, mean_q: 4.715620, mean_eps: 0.390472\n",
      "  643021/1500000: episode: 874, duration: 25.033s, episode steps: 695, steps per second:  28, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.079 [0.000, 5.000],  loss: 0.032873, mae: 3.902127, mean_q: 4.702869, mean_eps: 0.389460\n",
      "  643669/1500000: episode: 875, duration: 22.455s, episode steps: 648, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.986 [0.000, 5.000],  loss: 0.028856, mae: 3.893796, mean_q: 4.692498, mean_eps: 0.388821\n",
      "  644155/1500000: episode: 876, duration: 17.138s, episode steps: 486, steps per second:  28, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.029295, mae: 3.953080, mean_q: 4.768214, mean_eps: 0.388284\n",
      "  645156/1500000: episode: 877, duration: 33.528s, episode steps: 1001, steps per second:  30, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.029007, mae: 3.907061, mean_q: 4.712133, mean_eps: 0.387579\n",
      "  645941/1500000: episode: 878, duration: 26.379s, episode steps: 785, steps per second:  30, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.025111, mae: 3.914555, mean_q: 4.719099, mean_eps: 0.386729\n",
      "  646849/1500000: episode: 879, duration: 30.813s, episode steps: 908, steps per second:  29, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.025450, mae: 3.943858, mean_q: 4.753292, mean_eps: 0.385924\n",
      "  647670/1500000: episode: 880, duration: 28.150s, episode steps: 821, steps per second:  29, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: 0.029040, mae: 3.921153, mean_q: 4.725552, mean_eps: 0.385103\n",
      "  648179/1500000: episode: 881, duration: 17.294s, episode steps: 509, steps per second:  29, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.026898, mae: 3.927980, mean_q: 4.736639, mean_eps: 0.384472\n",
      "  648812/1500000: episode: 882, duration: 21.320s, episode steps: 633, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.019 [0.000, 5.000],  loss: 0.024635, mae: 3.944883, mean_q: 4.757733, mean_eps: 0.383931\n",
      "  649790/1500000: episode: 883, duration: 33.111s, episode steps: 978, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.031619, mae: 3.910406, mean_q: 4.710654, mean_eps: 0.383165\n",
      "  650430/1500000: episode: 884, duration: 22.371s, episode steps: 640, steps per second:  29, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.030136, mae: 3.927391, mean_q: 4.735259, mean_eps: 0.382396\n",
      "  651046/1500000: episode: 885, duration: 20.830s, episode steps: 616, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.028692, mae: 3.938201, mean_q: 4.745284, mean_eps: 0.381799\n",
      "  651553/1500000: episode: 886, duration: 17.042s, episode steps: 507, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.027535, mae: 3.947875, mean_q: 4.757755, mean_eps: 0.381265\n",
      "  652396/1500000: episode: 887, duration: 28.552s, episode steps: 843, steps per second:  30, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.076 [0.000, 5.000],  loss: 0.029839, mae: 3.948066, mean_q: 4.758430, mean_eps: 0.380625\n",
      "  653162/1500000: episode: 888, duration: 27.182s, episode steps: 766, steps per second:  28, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.029795, mae: 3.947022, mean_q: 4.757046, mean_eps: 0.379861\n",
      "  653826/1500000: episode: 889, duration: 22.475s, episode steps: 664, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.967 [0.000, 5.000],  loss: 0.028690, mae: 3.949352, mean_q: 4.759243, mean_eps: 0.379181\n",
      "  654816/1500000: episode: 890, duration: 33.785s, episode steps: 990, steps per second:  29, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.027712, mae: 3.942589, mean_q: 4.754396, mean_eps: 0.378396\n",
      "  655864/1500000: episode: 891, duration: 35.884s, episode steps: 1048, steps per second:  29, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.823 [0.000, 5.000],  loss: 0.029902, mae: 3.956824, mean_q: 4.769952, mean_eps: 0.377429\n",
      "  656984/1500000: episode: 892, duration: 38.241s, episode steps: 1120, steps per second:  29, episode reward: 29.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.029255, mae: 3.938325, mean_q: 4.744865, mean_eps: 0.376399\n",
      "  657322/1500000: episode: 893, duration: 11.784s, episode steps: 338, steps per second:  29, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.861 [0.000, 5.000],  loss: 0.022901, mae: 3.930074, mean_q: 4.732265, mean_eps: 0.375706\n",
      "  658164/1500000: episode: 894, duration: 29.114s, episode steps: 842, steps per second:  29, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.031858, mae: 3.947703, mean_q: 4.752225, mean_eps: 0.375145\n",
      "  658689/1500000: episode: 895, duration: 17.361s, episode steps: 525, steps per second:  30, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.028460, mae: 3.903009, mean_q: 4.702012, mean_eps: 0.374495\n",
      "  659329/1500000: episode: 896, duration: 21.843s, episode steps: 640, steps per second:  29, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.877 [0.000, 5.000],  loss: 0.028600, mae: 3.917354, mean_q: 4.716939, mean_eps: 0.373941\n",
      "  660494/1500000: episode: 897, duration: 39.509s, episode steps: 1165, steps per second:  29, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.028070, mae: 3.937147, mean_q: 4.744100, mean_eps: 0.373084\n",
      "  661724/1500000: episode: 898, duration: 42.434s, episode steps: 1230, steps per second:  29, episode reward: 31.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.026517, mae: 3.921420, mean_q: 4.727243, mean_eps: 0.371947\n",
      "  662533/1500000: episode: 899, duration: 28.167s, episode steps: 809, steps per second:  29, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.029533, mae: 3.939162, mean_q: 4.750820, mean_eps: 0.370978\n",
      "  663531/1500000: episode: 900, duration: 34.984s, episode steps: 998, steps per second:  29, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.029116, mae: 3.924503, mean_q: 4.731723, mean_eps: 0.370120\n",
      "  664197/1500000: episode: 901, duration: 22.537s, episode steps: 666, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.026235, mae: 3.961593, mean_q: 4.774644, mean_eps: 0.369329\n",
      "  664980/1500000: episode: 902, duration: 26.434s, episode steps: 783, steps per second:  30, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.748 [0.000, 5.000],  loss: 0.029454, mae: 3.942340, mean_q: 4.750894, mean_eps: 0.368641\n",
      "  665544/1500000: episode: 903, duration: 19.848s, episode steps: 564, steps per second:  28, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.101 [0.000, 5.000],  loss: 0.025222, mae: 3.991885, mean_q: 4.816815, mean_eps: 0.368003\n",
      "  666210/1500000: episode: 904, duration: 23.488s, episode steps: 666, steps per second:  28, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.021808, mae: 3.946733, mean_q: 4.758632, mean_eps: 0.367418\n",
      "  666752/1500000: episode: 905, duration: 19.272s, episode steps: 542, steps per second:  28, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.023295, mae: 3.958823, mean_q: 4.772454, mean_eps: 0.366844\n",
      "  667415/1500000: episode: 906, duration: 23.425s, episode steps: 663, steps per second:  28, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.026005, mae: 3.952965, mean_q: 4.767215, mean_eps: 0.366272\n",
      "  668057/1500000: episode: 907, duration: 22.631s, episode steps: 642, steps per second:  28, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.027400, mae: 3.972189, mean_q: 4.788328, mean_eps: 0.365651\n",
      "  668816/1500000: episode: 908, duration: 25.678s, episode steps: 759, steps per second:  30, episode reward: 19.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.029455, mae: 3.964418, mean_q: 4.782226, mean_eps: 0.364986\n",
      "  669432/1500000: episode: 909, duration: 21.665s, episode steps: 616, steps per second:  28, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.030690, mae: 3.980274, mean_q: 4.793642, mean_eps: 0.364334\n",
      "  670314/1500000: episode: 910, duration: 31.173s, episode steps: 882, steps per second:  28, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.026512, mae: 3.930298, mean_q: 4.735484, mean_eps: 0.363622\n",
      "  670692/1500000: episode: 911, duration: 13.200s, episode steps: 378, steps per second:  29, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.033675, mae: 3.950046, mean_q: 4.761812, mean_eps: 0.363023\n",
      "  671216/1500000: episode: 912, duration: 18.871s, episode steps: 524, steps per second:  28, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.028299, mae: 3.928960, mean_q: 4.734676, mean_eps: 0.362596\n",
      "  672225/1500000: episode: 913, duration: 35.397s, episode steps: 1009, steps per second:  29, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: 0.029052, mae: 3.946290, mean_q: 4.760580, mean_eps: 0.361866\n",
      "  673043/1500000: episode: 914, duration: 28.363s, episode steps: 818, steps per second:  29, episode reward: 24.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.027301, mae: 3.951637, mean_q: 4.760823, mean_eps: 0.360998\n",
      "  673411/1500000: episode: 915, duration: 12.818s, episode steps: 368, steps per second:  29, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.031472, mae: 3.950721, mean_q: 4.762479, mean_eps: 0.360435\n",
      "  674146/1500000: episode: 916, duration: 25.493s, episode steps: 735, steps per second:  29, episode reward: 21.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.029149, mae: 3.930310, mean_q: 4.737714, mean_eps: 0.359911\n",
      "  675116/1500000: episode: 917, duration: 33.875s, episode steps: 970, steps per second:  29, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.024689, mae: 3.934143, mean_q: 4.740455, mean_eps: 0.359102\n",
      "  675810/1500000: episode: 918, duration: 23.782s, episode steps: 694, steps per second:  29, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.752 [0.000, 5.000],  loss: 0.034603, mae: 3.895595, mean_q: 4.691129, mean_eps: 0.358311\n",
      "  676294/1500000: episode: 919, duration: 16.358s, episode steps: 484, steps per second:  30, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.025273, mae: 3.966921, mean_q: 4.781666, mean_eps: 0.357751\n",
      "  676966/1500000: episode: 920, duration: 22.666s, episode steps: 672, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.029186, mae: 3.976526, mean_q: 4.791401, mean_eps: 0.357202\n",
      "  677977/1500000: episode: 921, duration: 33.912s, episode steps: 1011, steps per second:  30, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.030955, mae: 3.960915, mean_q: 4.772402, mean_eps: 0.356402\n",
      "  678655/1500000: episode: 922, duration: 22.885s, episode steps: 678, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.532 [0.000, 5.000],  loss: 0.025497, mae: 3.947151, mean_q: 4.758688, mean_eps: 0.355600\n",
      "  679006/1500000: episode: 923, duration: 12.286s, episode steps: 351, steps per second:  29, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.866 [0.000, 5.000],  loss: 0.030877, mae: 3.977247, mean_q: 4.792947, mean_eps: 0.355112\n",
      "  679698/1500000: episode: 924, duration: 23.747s, episode steps: 692, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.831 [0.000, 5.000],  loss: 0.027616, mae: 3.976100, mean_q: 4.789704, mean_eps: 0.354616\n",
      "  680743/1500000: episode: 925, duration: 34.493s, episode steps: 1045, steps per second:  30, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.940 [0.000, 5.000],  loss: 0.027371, mae: 3.954783, mean_q: 4.766344, mean_eps: 0.353791\n",
      "  681449/1500000: episode: 926, duration: 23.394s, episode steps: 706, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.029841, mae: 3.974850, mean_q: 4.787234, mean_eps: 0.352959\n",
      "  682091/1500000: episode: 927, duration: 21.153s, episode steps: 642, steps per second:  30, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.863 [0.000, 5.000],  loss: 0.025020, mae: 3.929562, mean_q: 4.735679, mean_eps: 0.352319\n",
      "  682615/1500000: episode: 928, duration: 18.370s, episode steps: 524, steps per second:  29, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.029587, mae: 3.956304, mean_q: 4.765615, mean_eps: 0.351766\n",
      "  683173/1500000: episode: 929, duration: 18.639s, episode steps: 558, steps per second:  30, episode reward: 15.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.030170, mae: 3.972229, mean_q: 4.786719, mean_eps: 0.351251\n",
      "  684186/1500000: episode: 930, duration: 35.143s, episode steps: 1013, steps per second:  29, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.026688, mae: 3.984099, mean_q: 4.800948, mean_eps: 0.350504\n",
      "  684876/1500000: episode: 931, duration: 24.264s, episode steps: 690, steps per second:  28, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.023 [0.000, 5.000],  loss: 0.024143, mae: 4.003037, mean_q: 4.824749, mean_eps: 0.349697\n",
      "  685687/1500000: episode: 932, duration: 28.896s, episode steps: 811, steps per second:  28, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.029945, mae: 3.940996, mean_q: 4.750902, mean_eps: 0.348984\n",
      "  686391/1500000: episode: 933, duration: 24.798s, episode steps: 704, steps per second:  28, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.029783, mae: 3.949417, mean_q: 4.758844, mean_eps: 0.348264\n",
      "  687094/1500000: episode: 934, duration: 24.572s, episode steps: 703, steps per second:  29, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.182 [0.000, 5.000],  loss: 0.032235, mae: 3.936455, mean_q: 4.740715, mean_eps: 0.347595\n",
      "  688206/1500000: episode: 935, duration: 39.009s, episode steps: 1112, steps per second:  29, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.027555, mae: 3.957885, mean_q: 4.768541, mean_eps: 0.346733\n",
      "  688646/1500000: episode: 936, duration: 15.582s, episode steps: 440, steps per second:  28, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.182 [0.000, 5.000],  loss: 0.027295, mae: 3.935718, mean_q: 4.743029, mean_eps: 0.345995\n",
      "  689459/1500000: episode: 937, duration: 28.372s, episode steps: 813, steps per second:  29, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.948 [0.000, 5.000],  loss: 0.027036, mae: 3.965864, mean_q: 4.777727, mean_eps: 0.345401\n",
      "  690254/1500000: episode: 938, duration: 27.264s, episode steps: 795, steps per second:  29, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.979 [0.000, 5.000],  loss: 0.029875, mae: 3.934086, mean_q: 4.741904, mean_eps: 0.344637\n",
      "  691372/1500000: episode: 939, duration: 37.756s, episode steps: 1118, steps per second:  30, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.828 [0.000, 5.000],  loss: 0.025579, mae: 3.983288, mean_q: 4.802415, mean_eps: 0.343729\n",
      "  692279/1500000: episode: 940, duration: 31.222s, episode steps: 907, steps per second:  29, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.026966, mae: 3.955448, mean_q: 4.765277, mean_eps: 0.342767\n",
      "  693005/1500000: episode: 941, duration: 24.581s, episode steps: 726, steps per second:  30, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.027027, mae: 3.962697, mean_q: 4.771945, mean_eps: 0.341990\n",
      "  693952/1500000: episode: 942, duration: 33.037s, episode steps: 947, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.029027, mae: 3.973970, mean_q: 4.786181, mean_eps: 0.341196\n",
      "  694375/1500000: episode: 943, duration: 14.758s, episode steps: 423, steps per second:  29, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.009 [0.000, 5.000],  loss: 0.028309, mae: 3.947056, mean_q: 4.756918, mean_eps: 0.340546\n",
      "  695606/1500000: episode: 944, duration: 43.550s, episode steps: 1231, steps per second:  28, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.064 [0.000, 5.000],  loss: 0.028597, mae: 3.989180, mean_q: 4.807226, mean_eps: 0.339760\n",
      "  696106/1500000: episode: 945, duration: 17.717s, episode steps: 500, steps per second:  28, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.898 [0.000, 5.000],  loss: 0.029076, mae: 3.975500, mean_q: 4.789826, mean_eps: 0.338937\n",
      "  697087/1500000: episode: 946, duration: 34.285s, episode steps: 981, steps per second:  29, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.026860, mae: 3.987272, mean_q: 4.804130, mean_eps: 0.338234\n",
      "  697956/1500000: episode: 947, duration: 29.118s, episode steps: 869, steps per second:  30, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.025630, mae: 3.973538, mean_q: 4.789678, mean_eps: 0.337356\n",
      "  698637/1500000: episode: 948, duration: 23.908s, episode steps: 681, steps per second:  28, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.027202, mae: 3.998780, mean_q: 4.814636, mean_eps: 0.336619\n",
      "  699265/1500000: episode: 949, duration: 22.009s, episode steps: 628, steps per second:  29, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.030272, mae: 3.978067, mean_q: 4.788673, mean_eps: 0.335996\n",
      "Step 700000: saving model to dqn_SpaceInvaders-v0_step_700000.h5f\n",
      "  700031/1500000: episode: 950, duration: 26.471s, episode steps: 766, steps per second:  29, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.168 [0.000, 5.000],  loss: 0.030159, mae: 3.983034, mean_q: 4.797664, mean_eps: 0.335334\n",
      "  700668/1500000: episode: 951, duration: 22.018s, episode steps: 637, steps per second:  29, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.030127, mae: 3.998327, mean_q: 4.818215, mean_eps: 0.334669\n",
      "  701518/1500000: episode: 952, duration: 29.013s, episode steps: 850, steps per second:  29, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.018 [0.000, 5.000],  loss: 0.028341, mae: 4.027650, mean_q: 4.851037, mean_eps: 0.333963\n",
      "  702044/1500000: episode: 953, duration: 18.042s, episode steps: 526, steps per second:  29, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.033770, mae: 4.038201, mean_q: 4.868063, mean_eps: 0.333309\n",
      "  702373/1500000: episode: 954, duration: 11.574s, episode steps: 329, steps per second:  28, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.884 [0.000, 5.000],  loss: 0.032479, mae: 3.990255, mean_q: 4.807242, mean_eps: 0.332902\n",
      "  703417/1500000: episode: 955, duration: 37.882s, episode steps: 1044, steps per second:  28, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.029305, mae: 4.014084, mean_q: 4.835827, mean_eps: 0.332249\n",
      "  704138/1500000: episode: 956, duration: 26.071s, episode steps: 721, steps per second:  28, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.030767, mae: 3.993011, mean_q: 4.813810, mean_eps: 0.331411\n",
      "  704885/1500000: episode: 957, duration: 27.174s, episode steps: 747, steps per second:  27, episode reward: 19.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.030673, mae: 3.992625, mean_q: 4.814284, mean_eps: 0.330714\n",
      "  705375/1500000: episode: 958, duration: 18.669s, episode steps: 490, steps per second:  26, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.714 [0.000, 5.000],  loss: 0.025997, mae: 3.991868, mean_q: 4.811205, mean_eps: 0.330127\n",
      "  705983/1500000: episode: 959, duration: 20.944s, episode steps: 608, steps per second:  29, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.118 [0.000, 5.000],  loss: 0.031450, mae: 4.002737, mean_q: 4.822102, mean_eps: 0.329606\n",
      "  706750/1500000: episode: 960, duration: 25.179s, episode steps: 767, steps per second:  30, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.845 [0.000, 5.000],  loss: 0.028926, mae: 3.990025, mean_q: 4.804787, mean_eps: 0.328952\n",
      "  707480/1500000: episode: 961, duration: 24.731s, episode steps: 730, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.027614, mae: 4.008976, mean_q: 4.827824, mean_eps: 0.328242\n",
      "  708013/1500000: episode: 962, duration: 18.768s, episode steps: 533, steps per second:  28, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.030080, mae: 3.984763, mean_q: 4.802391, mean_eps: 0.327641\n",
      "  708778/1500000: episode: 963, duration: 25.836s, episode steps: 765, steps per second:  30, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.030083, mae: 3.976326, mean_q: 4.790641, mean_eps: 0.327024\n",
      "  709454/1500000: episode: 964, duration: 23.326s, episode steps: 676, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.031549, mae: 4.005823, mean_q: 4.822001, mean_eps: 0.326340\n",
      "  709944/1500000: episode: 965, duration: 17.130s, episode steps: 490, steps per second:  29, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.029921, mae: 3.965920, mean_q: 4.775889, mean_eps: 0.325787\n",
      "  711091/1500000: episode: 966, duration: 40.122s, episode steps: 1147, steps per second:  29, episode reward: 28.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.030363, mae: 4.004271, mean_q: 4.823954, mean_eps: 0.325010\n",
      "  711839/1500000: episode: 967, duration: 26.358s, episode steps: 748, steps per second:  28, episode reward: 22.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.031192, mae: 4.016081, mean_q: 4.835141, mean_eps: 0.324109\n",
      "  712530/1500000: episode: 968, duration: 23.837s, episode steps: 691, steps per second:  29, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.964 [0.000, 5.000],  loss: 0.030917, mae: 4.029764, mean_q: 4.854896, mean_eps: 0.323425\n",
      "  713060/1500000: episode: 969, duration: 17.730s, episode steps: 530, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.024908, mae: 4.015027, mean_q: 4.841234, mean_eps: 0.322846\n",
      "  714056/1500000: episode: 970, duration: 33.761s, episode steps: 996, steps per second:  30, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.028464, mae: 4.024896, mean_q: 4.850326, mean_eps: 0.322122\n",
      "  714714/1500000: episode: 971, duration: 22.246s, episode steps: 658, steps per second:  30, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.025810, mae: 4.046206, mean_q: 4.872962, mean_eps: 0.321335\n",
      "  715408/1500000: episode: 972, duration: 24.091s, episode steps: 694, steps per second:  29, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.027073, mae: 4.011271, mean_q: 4.831482, mean_eps: 0.320693\n",
      "  716327/1500000: episode: 973, duration: 30.916s, episode steps: 919, steps per second:  30, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.072 [0.000, 5.000],  loss: 0.029013, mae: 4.013514, mean_q: 4.832998, mean_eps: 0.319927\n",
      "  717231/1500000: episode: 974, duration: 30.484s, episode steps: 904, steps per second:  30, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.756 [0.000, 5.000],  loss: 0.025790, mae: 4.041958, mean_q: 4.872977, mean_eps: 0.319061\n",
      "  717711/1500000: episode: 975, duration: 16.219s, episode steps: 480, steps per second:  30, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.102 [0.000, 5.000],  loss: 0.028073, mae: 4.029738, mean_q: 4.854877, mean_eps: 0.318404\n",
      "  718383/1500000: episode: 976, duration: 23.722s, episode steps: 672, steps per second:  28, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.793 [0.000, 5.000],  loss: 0.026273, mae: 4.022469, mean_q: 4.848346, mean_eps: 0.317856\n",
      "  719240/1500000: episode: 977, duration: 30.355s, episode steps: 857, steps per second:  28, episode reward: 24.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.030972, mae: 4.026374, mean_q: 4.849337, mean_eps: 0.317131\n",
      "  719932/1500000: episode: 978, duration: 24.879s, episode steps: 692, steps per second:  28, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.053 [0.000, 5.000],  loss: 0.031032, mae: 4.014223, mean_q: 4.837631, mean_eps: 0.316395\n",
      "  721082/1500000: episode: 979, duration: 40.536s, episode steps: 1150, steps per second:  28, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.029074, mae: 4.033000, mean_q: 4.860935, mean_eps: 0.315519\n",
      "  722101/1500000: episode: 980, duration: 34.642s, episode steps: 1019, steps per second:  29, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.027705, mae: 4.062043, mean_q: 4.894767, mean_eps: 0.314488\n",
      "  722776/1500000: episode: 981, duration: 22.887s, episode steps: 675, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.026676, mae: 4.046106, mean_q: 4.872147, mean_eps: 0.313684\n",
      "  723684/1500000: episode: 982, duration: 30.348s, episode steps: 908, steps per second:  30, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.030009, mae: 4.030533, mean_q: 4.856751, mean_eps: 0.312933\n",
      "  724872/1500000: episode: 983, duration: 40.985s, episode steps: 1188, steps per second:  29, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.029174, mae: 4.030432, mean_q: 4.859194, mean_eps: 0.311938\n",
      "  725640/1500000: episode: 984, duration: 26.335s, episode steps: 768, steps per second:  29, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.945 [0.000, 5.000],  loss: 0.030202, mae: 4.087049, mean_q: 4.929610, mean_eps: 0.311009\n",
      "  726303/1500000: episode: 985, duration: 22.702s, episode steps: 663, steps per second:  29, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.026262, mae: 4.029502, mean_q: 4.858092, mean_eps: 0.310329\n",
      "  727037/1500000: episode: 986, duration: 25.649s, episode steps: 734, steps per second:  29, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.026930, mae: 4.038446, mean_q: 4.868803, mean_eps: 0.309664\n",
      "  727967/1500000: episode: 987, duration: 31.887s, episode steps: 930, steps per second:  29, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.852 [0.000, 5.000],  loss: 0.028143, mae: 4.070663, mean_q: 4.903739, mean_eps: 0.308873\n",
      "  728885/1500000: episode: 988, duration: 31.762s, episode steps: 918, steps per second:  29, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.026810, mae: 4.056351, mean_q: 4.891697, mean_eps: 0.307995\n",
      "  729804/1500000: episode: 989, duration: 32.589s, episode steps: 919, steps per second:  28, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.830 [0.000, 5.000],  loss: 0.029081, mae: 4.072605, mean_q: 4.907895, mean_eps: 0.307123\n",
      "  730402/1500000: episode: 990, duration: 21.336s, episode steps: 598, steps per second:  28, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.824 [0.000, 5.000],  loss: 0.027805, mae: 4.083728, mean_q: 4.923552, mean_eps: 0.306403\n",
      "  731480/1500000: episode: 991, duration: 36.961s, episode steps: 1078, steps per second:  29, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.025510, mae: 4.082709, mean_q: 4.921887, mean_eps: 0.305607\n",
      "  732195/1500000: episode: 992, duration: 24.624s, episode steps: 715, steps per second:  29, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.029521, mae: 4.073203, mean_q: 4.908765, mean_eps: 0.304756\n",
      "  732977/1500000: episode: 993, duration: 26.504s, episode steps: 782, steps per second:  30, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.029297, mae: 4.091584, mean_q: 4.928972, mean_eps: 0.304043\n",
      "  733477/1500000: episode: 994, duration: 16.293s, episode steps: 500, steps per second:  31, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.026813, mae: 4.092814, mean_q: 4.933041, mean_eps: 0.303433\n",
      "  734152/1500000: episode: 995, duration: 22.374s, episode steps: 675, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.898 [0.000, 5.000],  loss: 0.025224, mae: 4.068377, mean_q: 4.903980, mean_eps: 0.302877\n",
      "  734623/1500000: episode: 996, duration: 15.921s, episode steps: 471, steps per second:  30, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.028715, mae: 4.103990, mean_q: 4.944881, mean_eps: 0.302333\n",
      "  735471/1500000: episode: 997, duration: 28.266s, episode steps: 848, steps per second:  30, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.028221, mae: 4.066268, mean_q: 4.902769, mean_eps: 0.301706\n",
      "  736157/1500000: episode: 998, duration: 23.040s, episode steps: 686, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.027220, mae: 4.086073, mean_q: 4.921532, mean_eps: 0.300977\n",
      "  737072/1500000: episode: 999, duration: 30.773s, episode steps: 915, steps per second:  30, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.189 [0.000, 5.000],  loss: 0.026413, mae: 4.083811, mean_q: 4.923904, mean_eps: 0.300217\n",
      "  737937/1500000: episode: 1000, duration: 29.818s, episode steps: 865, steps per second:  29, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.030227, mae: 4.099334, mean_q: 4.943205, mean_eps: 0.299371\n",
      "  738499/1500000: episode: 1001, duration: 19.376s, episode steps: 562, steps per second:  29, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: 0.028772, mae: 4.081988, mean_q: 4.923627, mean_eps: 0.298693\n",
      "  738900/1500000: episode: 1002, duration: 13.633s, episode steps: 401, steps per second:  29, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.034409, mae: 4.128420, mean_q: 4.970868, mean_eps: 0.298237\n",
      "  739601/1500000: episode: 1003, duration: 24.207s, episode steps: 701, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.046 [0.000, 5.000],  loss: 0.026669, mae: 4.053598, mean_q: 4.886721, mean_eps: 0.297713\n",
      "  740087/1500000: episode: 1004, duration: 16.518s, episode steps: 486, steps per second:  29, episode reward: 12.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.026676, mae: 4.062828, mean_q: 4.898269, mean_eps: 0.297148\n",
      "  740614/1500000: episode: 1005, duration: 17.934s, episode steps: 527, steps per second:  29, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.026624, mae: 4.068969, mean_q: 4.903832, mean_eps: 0.296668\n",
      "  741306/1500000: episode: 1006, duration: 23.077s, episode steps: 692, steps per second:  30, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.026989, mae: 4.067791, mean_q: 4.904674, mean_eps: 0.296088\n",
      "  742044/1500000: episode: 1007, duration: 24.258s, episode steps: 738, steps per second:  30, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.026238, mae: 4.099616, mean_q: 4.938519, mean_eps: 0.295410\n",
      "  743424/1500000: episode: 1008, duration: 47.706s, episode steps: 1380, steps per second:  29, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.028185, mae: 4.062908, mean_q: 4.896463, mean_eps: 0.294405\n",
      "  744318/1500000: episode: 1009, duration: 30.789s, episode steps: 894, steps per second:  29, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.028567, mae: 4.087990, mean_q: 4.925151, mean_eps: 0.293324\n",
      "  744998/1500000: episode: 1010, duration: 23.557s, episode steps: 680, steps per second:  29, episode reward: 21.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.027564, mae: 4.073219, mean_q: 4.907606, mean_eps: 0.292575\n",
      "  745788/1500000: episode: 1011, duration: 27.084s, episode steps: 790, steps per second:  29, episode reward: 22.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.025593, mae: 4.097487, mean_q: 4.939846, mean_eps: 0.291878\n",
      "  746321/1500000: episode: 1012, duration: 18.542s, episode steps: 533, steps per second:  29, episode reward: 15.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.025864, mae: 4.064953, mean_q: 4.901385, mean_eps: 0.291249\n",
      "  747196/1500000: episode: 1013, duration: 30.891s, episode steps: 875, steps per second:  28, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.024940, mae: 4.100608, mean_q: 4.940392, mean_eps: 0.290580\n",
      "  747908/1500000: episode: 1014, duration: 26.102s, episode steps: 712, steps per second:  27, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.115 [0.000, 5.000],  loss: 0.033418, mae: 4.100821, mean_q: 4.940601, mean_eps: 0.289828\n",
      "  748452/1500000: episode: 1015, duration: 20.186s, episode steps: 544, steps per second:  27, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.029200, mae: 4.116165, mean_q: 4.961552, mean_eps: 0.289231\n",
      "  749343/1500000: episode: 1016, duration: 32.888s, episode steps: 891, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.029123, mae: 4.077882, mean_q: 4.914608, mean_eps: 0.288549\n",
      "  750036/1500000: episode: 1017, duration: 25.930s, episode steps: 693, steps per second:  27, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.031181, mae: 4.108473, mean_q: 4.951026, mean_eps: 0.287796\n",
      "  751411/1500000: episode: 1018, duration: 48.233s, episode steps: 1375, steps per second:  29, episode reward: 28.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.024644, mae: 4.093285, mean_q: 4.933803, mean_eps: 0.286814\n",
      "  752330/1500000: episode: 1019, duration: 32.625s, episode steps: 919, steps per second:  28, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.026219, mae: 4.079633, mean_q: 4.914921, mean_eps: 0.285724\n",
      "  753315/1500000: episode: 1020, duration: 34.409s, episode steps: 985, steps per second:  29, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.028079, mae: 4.085674, mean_q: 4.925536, mean_eps: 0.284819\n",
      "  754233/1500000: episode: 1021, duration: 32.147s, episode steps: 918, steps per second:  29, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.029098, mae: 4.089965, mean_q: 4.926099, mean_eps: 0.283915\n",
      "  755199/1500000: episode: 1022, duration: 33.024s, episode steps: 966, steps per second:  29, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.028588, mae: 4.119207, mean_q: 4.965545, mean_eps: 0.283020\n",
      "  756101/1500000: episode: 1023, duration: 31.165s, episode steps: 902, steps per second:  29, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.025245, mae: 4.152643, mean_q: 5.001725, mean_eps: 0.282133\n",
      "  756810/1500000: episode: 1024, duration: 24.835s, episode steps: 709, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.029309, mae: 4.147609, mean_q: 4.998494, mean_eps: 0.281367\n",
      "  757512/1500000: episode: 1025, duration: 25.328s, episode steps: 702, steps per second:  28, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.029963, mae: 4.145284, mean_q: 4.993197, mean_eps: 0.280698\n",
      "  758524/1500000: episode: 1026, duration: 35.417s, episode steps: 1012, steps per second:  29, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.028673, mae: 4.151028, mean_q: 4.997321, mean_eps: 0.279885\n",
      "  759459/1500000: episode: 1027, duration: 32.223s, episode steps: 935, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.029498, mae: 4.147049, mean_q: 4.994212, mean_eps: 0.278959\n",
      "  759859/1500000: episode: 1028, duration: 13.293s, episode steps: 400, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.029040, mae: 4.158901, mean_q: 5.014086, mean_eps: 0.278325\n",
      "  760842/1500000: episode: 1029, duration: 32.324s, episode steps: 983, steps per second:  30, episode reward: 28.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.027200, mae: 4.165005, mean_q: 5.018071, mean_eps: 0.277668\n",
      "  761458/1500000: episode: 1030, duration: 20.292s, episode steps: 616, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.024675, mae: 4.175963, mean_q: 5.029053, mean_eps: 0.276908\n",
      "  762191/1500000: episode: 1031, duration: 25.216s, episode steps: 733, steps per second:  29, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.026168, mae: 4.171490, mean_q: 5.025458, mean_eps: 0.276267\n",
      "  763334/1500000: episode: 1032, duration: 38.593s, episode steps: 1143, steps per second:  30, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.152 [0.000, 5.000],  loss: 0.027994, mae: 4.152228, mean_q: 5.003919, mean_eps: 0.275376\n",
      "  764061/1500000: episode: 1033, duration: 24.452s, episode steps: 727, steps per second:  30, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.027897, mae: 4.164729, mean_q: 5.017221, mean_eps: 0.274487\n",
      "  764919/1500000: episode: 1034, duration: 29.864s, episode steps: 858, steps per second:  29, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.022918, mae: 4.150730, mean_q: 5.002235, mean_eps: 0.273735\n",
      "  765819/1500000: episode: 1035, duration: 30.678s, episode steps: 900, steps per second:  29, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.030073, mae: 4.174402, mean_q: 5.033368, mean_eps: 0.272900\n",
      "  766465/1500000: episode: 1036, duration: 22.745s, episode steps: 646, steps per second:  28, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.028213, mae: 4.169311, mean_q: 5.025558, mean_eps: 0.272165\n",
      "  767110/1500000: episode: 1037, duration: 22.832s, episode steps: 645, steps per second:  28, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.030167, mae: 4.177182, mean_q: 5.032998, mean_eps: 0.271551\n",
      "  767729/1500000: episode: 1038, duration: 21.928s, episode steps: 619, steps per second:  28, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.837 [0.000, 5.000],  loss: 0.027951, mae: 4.167974, mean_q: 5.026566, mean_eps: 0.270951\n",
      "  768075/1500000: episode: 1039, duration: 12.212s, episode steps: 346, steps per second:  28, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.699 [0.000, 5.000],  loss: 0.021578, mae: 4.210576, mean_q: 5.074887, mean_eps: 0.270493\n",
      "  769023/1500000: episode: 1040, duration: 33.489s, episode steps: 948, steps per second:  28, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.975 [0.000, 5.000],  loss: 0.027252, mae: 4.194213, mean_q: 5.054886, mean_eps: 0.269879\n",
      "  769938/1500000: episode: 1041, duration: 31.286s, episode steps: 915, steps per second:  29, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.025318, mae: 4.181320, mean_q: 5.039545, mean_eps: 0.268994\n",
      "  770802/1500000: episode: 1042, duration: 29.416s, episode steps: 864, steps per second:  29, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.810 [0.000, 5.000],  loss: 0.025834, mae: 4.178379, mean_q: 5.039283, mean_eps: 0.268149\n",
      "  771839/1500000: episode: 1043, duration: 36.201s, episode steps: 1037, steps per second:  29, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.026901, mae: 4.191725, mean_q: 5.052585, mean_eps: 0.267246\n",
      "  772690/1500000: episode: 1044, duration: 28.704s, episode steps: 851, steps per second:  30, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.030007, mae: 4.195732, mean_q: 5.055685, mean_eps: 0.266349\n",
      "  773392/1500000: episode: 1045, duration: 24.560s, episode steps: 702, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.026906, mae: 4.188740, mean_q: 5.047493, mean_eps: 0.265612\n",
      "  774478/1500000: episode: 1046, duration: 36.932s, episode steps: 1086, steps per second:  29, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.908 [0.000, 5.000],  loss: 0.026984, mae: 4.194592, mean_q: 5.054345, mean_eps: 0.264763\n",
      "  775387/1500000: episode: 1047, duration: 31.007s, episode steps: 909, steps per second:  29, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.086 [0.000, 5.000],  loss: 0.030234, mae: 4.186103, mean_q: 5.044901, mean_eps: 0.263815\n",
      "  776422/1500000: episode: 1048, duration: 37.067s, episode steps: 1035, steps per second:  28, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.027651, mae: 4.183426, mean_q: 5.039839, mean_eps: 0.262891\n",
      "  777374/1500000: episode: 1049, duration: 33.000s, episode steps: 952, steps per second:  29, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.100 [0.000, 5.000],  loss: 0.028529, mae: 4.188913, mean_q: 5.042814, mean_eps: 0.261947\n",
      "  778295/1500000: episode: 1050, duration: 32.208s, episode steps: 921, steps per second:  29, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.028771, mae: 4.194983, mean_q: 5.052516, mean_eps: 0.261058\n",
      "  778891/1500000: episode: 1051, duration: 20.340s, episode steps: 596, steps per second:  29, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.028099, mae: 4.143834, mean_q: 4.992670, mean_eps: 0.260338\n",
      "  779729/1500000: episode: 1052, duration: 28.997s, episode steps: 838, steps per second:  29, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: 0.030064, mae: 4.183429, mean_q: 5.036497, mean_eps: 0.259656\n",
      "  780393/1500000: episode: 1053, duration: 21.932s, episode steps: 664, steps per second:  30, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.904 [0.000, 5.000],  loss: 0.028787, mae: 4.178450, mean_q: 5.037758, mean_eps: 0.258941\n",
      "  781314/1500000: episode: 1054, duration: 28.813s, episode steps: 921, steps per second:  32, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.029638, mae: 4.169945, mean_q: 5.025880, mean_eps: 0.258189\n",
      "  782193/1500000: episode: 1055, duration: 28.059s, episode steps: 879, steps per second:  31, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.030359, mae: 4.174404, mean_q: 5.032299, mean_eps: 0.257334\n",
      "  782980/1500000: episode: 1056, duration: 24.739s, episode steps: 787, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.027041, mae: 4.198391, mean_q: 5.058287, mean_eps: 0.256543\n",
      "  783468/1500000: episode: 1057, duration: 15.664s, episode steps: 488, steps per second:  31, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.691 [0.000, 5.000],  loss: 0.028463, mae: 4.192136, mean_q: 5.053719, mean_eps: 0.255939\n",
      "  784295/1500000: episode: 1058, duration: 26.560s, episode steps: 827, steps per second:  31, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.031070, mae: 4.188448, mean_q: 5.045982, mean_eps: 0.255314\n",
      "  785838/1500000: episode: 1059, duration: 49.382s, episode steps: 1543, steps per second:  31, episode reward: 33.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.027600, mae: 4.188828, mean_q: 5.045869, mean_eps: 0.254187\n",
      "  786478/1500000: episode: 1060, duration: 20.161s, episode steps: 640, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.997 [0.000, 5.000],  loss: 0.030641, mae: 4.157424, mean_q: 5.008322, mean_eps: 0.253150\n",
      "  787151/1500000: episode: 1061, duration: 21.606s, episode steps: 673, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.030300, mae: 4.179983, mean_q: 5.032157, mean_eps: 0.252527\n",
      "  787643/1500000: episode: 1062, duration: 16.129s, episode steps: 492, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.081 [0.000, 5.000],  loss: 0.026064, mae: 4.183194, mean_q: 5.045703, mean_eps: 0.251974\n",
      "  788514/1500000: episode: 1063, duration: 28.246s, episode steps: 871, steps per second:  31, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.025627, mae: 4.169358, mean_q: 5.024458, mean_eps: 0.251326\n",
      "  789417/1500000: episode: 1064, duration: 30.661s, episode steps: 903, steps per second:  29, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.029456, mae: 4.166133, mean_q: 5.019406, mean_eps: 0.250482\n",
      "  790467/1500000: episode: 1065, duration: 35.144s, episode steps: 1050, steps per second:  30, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.027102, mae: 4.181329, mean_q: 5.037825, mean_eps: 0.249555\n",
      "  791388/1500000: episode: 1066, duration: 30.546s, episode steps: 921, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.007 [0.000, 5.000],  loss: 0.026252, mae: 4.173963, mean_q: 5.027176, mean_eps: 0.248620\n",
      "  792289/1500000: episode: 1067, duration: 30.512s, episode steps: 901, steps per second:  30, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.023156, mae: 4.193891, mean_q: 5.050009, mean_eps: 0.247754\n",
      "  793090/1500000: episode: 1068, duration: 27.536s, episode steps: 801, steps per second:  29, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.028881, mae: 4.180686, mean_q: 5.036737, mean_eps: 0.246945\n",
      "  794052/1500000: episode: 1069, duration: 31.220s, episode steps: 962, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.027425, mae: 4.188956, mean_q: 5.045264, mean_eps: 0.246109\n",
      "  794662/1500000: episode: 1070, duration: 20.134s, episode steps: 610, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.028611, mae: 4.157326, mean_q: 5.007609, mean_eps: 0.245362\n",
      "  795947/1500000: episode: 1071, duration: 41.384s, episode steps: 1285, steps per second:  31, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.027459, mae: 4.210554, mean_q: 5.070076, mean_eps: 0.244461\n",
      "  797178/1500000: episode: 1072, duration: 39.894s, episode steps: 1231, steps per second:  31, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.027990, mae: 4.218339, mean_q: 5.080330, mean_eps: 0.243266\n",
      "  797851/1500000: episode: 1073, duration: 21.764s, episode steps: 673, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.141 [0.000, 5.000],  loss: 0.030385, mae: 4.224982, mean_q: 5.085168, mean_eps: 0.242362\n",
      "  798720/1500000: episode: 1074, duration: 28.456s, episode steps: 869, steps per second:  31, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.027993, mae: 4.222242, mean_q: 5.081344, mean_eps: 0.241630\n",
      "  799373/1500000: episode: 1075, duration: 21.310s, episode steps: 653, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.032727, mae: 4.205403, mean_q: 5.061334, mean_eps: 0.240906\n",
      "Step 800000: saving model to dqn_SpaceInvaders-v0_step_800000.h5f\n",
      "  800152/1500000: episode: 1076, duration: 25.809s, episode steps: 779, steps per second:  30, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.028290, mae: 4.211775, mean_q: 5.071495, mean_eps: 0.240226\n",
      "  801056/1500000: episode: 1077, duration: 29.323s, episode steps: 904, steps per second:  31, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.026177, mae: 4.214244, mean_q: 5.075571, mean_eps: 0.239428\n",
      "  801427/1500000: episode: 1078, duration: 12.092s, episode steps: 371, steps per second:  31, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.895 [0.000, 5.000],  loss: 0.025559, mae: 4.206850, mean_q: 5.067328, mean_eps: 0.238822\n",
      "  802350/1500000: episode: 1079, duration: 29.959s, episode steps: 923, steps per second:  31, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.246 [0.000, 5.000],  loss: 0.028730, mae: 4.210814, mean_q: 5.071162, mean_eps: 0.238206\n",
      "  803438/1500000: episode: 1080, duration: 36.568s, episode steps: 1088, steps per second:  30, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.030016, mae: 4.205220, mean_q: 5.066886, mean_eps: 0.237251\n",
      "  803957/1500000: episode: 1081, duration: 17.187s, episode steps: 519, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.023057, mae: 4.234699, mean_q: 5.100418, mean_eps: 0.236487\n",
      "  804721/1500000: episode: 1082, duration: 24.770s, episode steps: 764, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.027508, mae: 4.219705, mean_q: 5.083879, mean_eps: 0.235877\n",
      "  805601/1500000: episode: 1083, duration: 29.064s, episode steps: 880, steps per second:  30, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.160 [0.000, 5.000],  loss: 0.027905, mae: 4.207921, mean_q: 5.065699, mean_eps: 0.235096\n",
      "  806220/1500000: episode: 1084, duration: 20.291s, episode steps: 619, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.838 [0.000, 5.000],  loss: 0.030167, mae: 4.175666, mean_q: 5.031069, mean_eps: 0.234386\n",
      "  807331/1500000: episode: 1085, duration: 36.790s, episode steps: 1111, steps per second:  30, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.029566, mae: 4.198602, mean_q: 5.056260, mean_eps: 0.233565\n",
      "  808215/1500000: episode: 1086, duration: 29.607s, episode steps: 884, steps per second:  30, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.029701, mae: 4.216205, mean_q: 5.081037, mean_eps: 0.232617\n",
      "  808908/1500000: episode: 1087, duration: 23.049s, episode steps: 693, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.024030, mae: 4.180691, mean_q: 5.035556, mean_eps: 0.231868\n",
      "  809738/1500000: episode: 1088, duration: 27.607s, episode steps: 830, steps per second:  30, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.026239, mae: 4.190044, mean_q: 5.048621, mean_eps: 0.231144\n",
      "  810557/1500000: episode: 1089, duration: 27.060s, episode steps: 819, steps per second:  30, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.026825, mae: 4.214180, mean_q: 5.080127, mean_eps: 0.230359\n",
      "  811549/1500000: episode: 1090, duration: 32.655s, episode steps: 992, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.024331, mae: 4.261573, mean_q: 5.134981, mean_eps: 0.229499\n",
      "  812164/1500000: episode: 1091, duration: 21.548s, episode steps: 615, steps per second:  29, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.025590, mae: 4.226575, mean_q: 5.095607, mean_eps: 0.228737\n",
      "  813378/1500000: episode: 1092, duration: 39.264s, episode steps: 1214, steps per second:  31, episode reward: 29.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.025162, mae: 4.270425, mean_q: 5.145476, mean_eps: 0.227869\n",
      "  814315/1500000: episode: 1093, duration: 30.315s, episode steps: 937, steps per second:  31, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.026843, mae: 4.237424, mean_q: 5.103451, mean_eps: 0.226846\n",
      "  814784/1500000: episode: 1094, duration: 15.816s, episode steps: 469, steps per second:  30, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.029729, mae: 4.262488, mean_q: 5.131027, mean_eps: 0.226179\n",
      "  815703/1500000: episode: 1095, duration: 30.487s, episode steps: 919, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.027799, mae: 4.249336, mean_q: 5.117634, mean_eps: 0.225520\n",
      "  816512/1500000: episode: 1096, duration: 26.659s, episode steps: 809, steps per second:  30, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.027195, mae: 4.227383, mean_q: 5.094788, mean_eps: 0.224699\n",
      "  817294/1500000: episode: 1097, duration: 25.865s, episode steps: 782, steps per second:  30, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.968 [0.000, 5.000],  loss: 0.024073, mae: 4.253358, mean_q: 5.126076, mean_eps: 0.223943\n",
      "  818084/1500000: episode: 1098, duration: 26.386s, episode steps: 790, steps per second:  30, episode reward: 21.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.028675, mae: 4.289079, mean_q: 5.165822, mean_eps: 0.223196\n",
      "  818742/1500000: episode: 1099, duration: 22.084s, episode steps: 658, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.029672, mae: 4.243595, mean_q: 5.115987, mean_eps: 0.222509\n",
      "  819394/1500000: episode: 1100, duration: 20.828s, episode steps: 652, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.028876, mae: 4.284809, mean_q: 5.158575, mean_eps: 0.221885\n",
      "  820152/1500000: episode: 1101, duration: 23.964s, episode steps: 758, steps per second:  32, episode reward: 23.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.024961, mae: 4.280181, mean_q: 5.156653, mean_eps: 0.221217\n",
      "  820738/1500000: episode: 1102, duration: 18.532s, episode steps: 586, steps per second:  32, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.497 [0.000, 5.000],  loss: 0.030497, mae: 4.263880, mean_q: 5.134868, mean_eps: 0.220578\n",
      "  821221/1500000: episode: 1103, duration: 15.414s, episode steps: 483, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.030241, mae: 4.272938, mean_q: 5.147651, mean_eps: 0.220069\n",
      "  821891/1500000: episode: 1104, duration: 21.508s, episode steps: 670, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.026610, mae: 4.246454, mean_q: 5.115860, mean_eps: 0.219522\n",
      "  822655/1500000: episode: 1105, duration: 24.786s, episode steps: 764, steps per second:  31, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.027056, mae: 4.269695, mean_q: 5.142658, mean_eps: 0.218842\n",
      "  823347/1500000: episode: 1106, duration: 22.993s, episode steps: 692, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.049 [0.000, 5.000],  loss: 0.028172, mae: 4.268107, mean_q: 5.141082, mean_eps: 0.218150\n",
      "  824031/1500000: episode: 1107, duration: 22.597s, episode steps: 684, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.080 [0.000, 5.000],  loss: 0.025357, mae: 4.298023, mean_q: 5.180734, mean_eps: 0.217496\n",
      "  824979/1500000: episode: 1108, duration: 31.212s, episode steps: 948, steps per second:  30, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.026648, mae: 4.268159, mean_q: 5.143855, mean_eps: 0.216721\n",
      "  825624/1500000: episode: 1109, duration: 21.654s, episode steps: 645, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.025710, mae: 4.297161, mean_q: 5.176098, mean_eps: 0.215965\n",
      "  826421/1500000: episode: 1110, duration: 26.319s, episode steps: 797, steps per second:  30, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.907 [0.000, 5.000],  loss: 0.030601, mae: 4.305479, mean_q: 5.185338, mean_eps: 0.215279\n",
      "  827608/1500000: episode: 1111, duration: 38.738s, episode steps: 1187, steps per second:  31, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.026723, mae: 4.309086, mean_q: 5.192348, mean_eps: 0.214337\n",
      "  828118/1500000: episode: 1112, duration: 16.496s, episode steps: 510, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.927 [0.000, 5.000],  loss: 0.027797, mae: 4.274251, mean_q: 5.148975, mean_eps: 0.213531\n",
      "  828852/1500000: episode: 1113, duration: 24.979s, episode steps: 734, steps per second:  29, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.155 [0.000, 5.000],  loss: 0.024015, mae: 4.298329, mean_q: 5.177129, mean_eps: 0.212940\n",
      "  829733/1500000: episode: 1114, duration: 29.572s, episode steps: 881, steps per second:  30, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.030286, mae: 4.310948, mean_q: 5.192986, mean_eps: 0.212173\n",
      "  830464/1500000: episode: 1115, duration: 24.840s, episode steps: 731, steps per second:  29, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.988 [0.000, 5.000],  loss: 0.027151, mae: 4.329022, mean_q: 5.217233, mean_eps: 0.211407\n",
      "  831116/1500000: episode: 1116, duration: 21.630s, episode steps: 652, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.026198, mae: 4.347901, mean_q: 5.239298, mean_eps: 0.210751\n",
      "  832020/1500000: episode: 1117, duration: 30.400s, episode steps: 904, steps per second:  30, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.027282, mae: 4.329121, mean_q: 5.214667, mean_eps: 0.210012\n",
      "  832378/1500000: episode: 1118, duration: 12.004s, episode steps: 358, steps per second:  30, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.030169, mae: 4.303810, mean_q: 5.180370, mean_eps: 0.209412\n",
      "  833192/1500000: episode: 1119, duration: 26.951s, episode steps: 814, steps per second:  30, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.030023, mae: 4.351075, mean_q: 5.238933, mean_eps: 0.208855\n",
      "  834102/1500000: episode: 1120, duration: 29.551s, episode steps: 910, steps per second:  31, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.029635, mae: 4.298597, mean_q: 5.177690, mean_eps: 0.208036\n",
      "  834731/1500000: episode: 1121, duration: 20.636s, episode steps: 629, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.029552, mae: 4.318863, mean_q: 5.202953, mean_eps: 0.207305\n",
      "  835635/1500000: episode: 1122, duration: 30.834s, episode steps: 904, steps per second:  29, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.029617, mae: 4.364132, mean_q: 5.258828, mean_eps: 0.206577\n",
      "  836594/1500000: episode: 1123, duration: 32.610s, episode steps: 959, steps per second:  29, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.930 [0.000, 5.000],  loss: 0.029460, mae: 4.391529, mean_q: 5.293347, mean_eps: 0.205692\n",
      "  837373/1500000: episode: 1124, duration: 25.727s, episode steps: 779, steps per second:  30, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.032743, mae: 4.346703, mean_q: 5.232440, mean_eps: 0.204865\n",
      "  838274/1500000: episode: 1125, duration: 29.671s, episode steps: 901, steps per second:  30, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.028205, mae: 4.366634, mean_q: 5.257692, mean_eps: 0.204067\n",
      "  839063/1500000: episode: 1126, duration: 26.213s, episode steps: 789, steps per second:  30, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.029981, mae: 4.385952, mean_q: 5.285239, mean_eps: 0.203265\n",
      "  840205/1500000: episode: 1127, duration: 38.602s, episode steps: 1142, steps per second:  30, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.034732, mae: 4.365602, mean_q: 5.258142, mean_eps: 0.202348\n",
      "  840790/1500000: episode: 1128, duration: 18.706s, episode steps: 585, steps per second:  31, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.022148, mae: 4.380881, mean_q: 5.280363, mean_eps: 0.201527\n",
      "  841174/1500000: episode: 1129, duration: 12.553s, episode steps: 384, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.030094, mae: 4.416881, mean_q: 5.320620, mean_eps: 0.201067\n",
      "  841861/1500000: episode: 1130, duration: 21.695s, episode steps: 687, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.028491, mae: 4.382608, mean_q: 5.278047, mean_eps: 0.200558\n",
      "  842611/1500000: episode: 1131, duration: 24.156s, episode steps: 750, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.013 [0.000, 5.000],  loss: 0.029770, mae: 4.395712, mean_q: 5.294629, mean_eps: 0.199876\n",
      "  843400/1500000: episode: 1132, duration: 25.420s, episode steps: 789, steps per second:  31, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.028509, mae: 4.406671, mean_q: 5.307780, mean_eps: 0.199146\n",
      "  844140/1500000: episode: 1133, duration: 23.709s, episode steps: 740, steps per second:  31, episode reward: 22.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.028017, mae: 4.384482, mean_q: 5.279970, mean_eps: 0.198420\n",
      "  844694/1500000: episode: 1134, duration: 17.542s, episode steps: 554, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.031079, mae: 4.374527, mean_q: 5.265177, mean_eps: 0.197805\n",
      "  845325/1500000: episode: 1135, duration: 20.257s, episode steps: 631, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.876 [0.000, 5.000],  loss: 0.026855, mae: 4.376901, mean_q: 5.271411, mean_eps: 0.197241\n",
      "  845958/1500000: episode: 1136, duration: 20.368s, episode steps: 633, steps per second:  31, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: 0.028222, mae: 4.433589, mean_q: 5.335647, mean_eps: 0.196640\n",
      "  846495/1500000: episode: 1137, duration: 17.494s, episode steps: 537, steps per second:  31, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.025725, mae: 4.388104, mean_q: 5.283706, mean_eps: 0.196085\n",
      "  847230/1500000: episode: 1138, duration: 25.042s, episode steps: 735, steps per second:  29, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.028499, mae: 4.425976, mean_q: 5.323135, mean_eps: 0.195481\n",
      "  847988/1500000: episode: 1139, duration: 24.991s, episode steps: 758, steps per second:  30, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.917 [0.000, 5.000],  loss: 0.031147, mae: 4.411050, mean_q: 5.312382, mean_eps: 0.194772\n",
      "  848986/1500000: episode: 1140, duration: 33.577s, episode steps: 998, steps per second:  30, episode reward: 27.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.028042, mae: 4.408057, mean_q: 5.308325, mean_eps: 0.193938\n",
      "  850131/1500000: episode: 1141, duration: 37.291s, episode steps: 1145, steps per second:  31, episode reward: 31.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.080 [0.000, 5.000],  loss: 0.030726, mae: 4.400249, mean_q: 5.301559, mean_eps: 0.192920\n",
      "  851255/1500000: episode: 1142, duration: 36.390s, episode steps: 1124, steps per second:  31, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.031 [0.000, 5.000],  loss: 0.026257, mae: 4.414578, mean_q: 5.318649, mean_eps: 0.191843\n",
      "  852234/1500000: episode: 1143, duration: 32.526s, episode steps: 979, steps per second:  30, episode reward: 27.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.028975, mae: 4.386621, mean_q: 5.282512, mean_eps: 0.190843\n",
      "  853083/1500000: episode: 1144, duration: 30.372s, episode steps: 849, steps per second:  28, episode reward:  7.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.028221, mae: 4.413604, mean_q: 5.314912, mean_eps: 0.189975\n",
      "  854619/1500000: episode: 1145, duration: 59.468s, episode steps: 1536, steps per second:  26, episode reward: 32.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.029563, mae: 4.409319, mean_q: 5.311646, mean_eps: 0.188843\n",
      "  855657/1500000: episode: 1146, duration: 33.961s, episode steps: 1038, steps per second:  31, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.183 [0.000, 5.000],  loss: 0.026796, mae: 4.442406, mean_q: 5.349104, mean_eps: 0.187619\n",
      "  856149/1500000: episode: 1147, duration: 16.503s, episode steps: 492, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.026734, mae: 4.445523, mean_q: 5.351091, mean_eps: 0.186891\n",
      "  856826/1500000: episode: 1148, duration: 21.977s, episode steps: 677, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.027327, mae: 4.430828, mean_q: 5.338463, mean_eps: 0.186336\n",
      "  857994/1500000: episode: 1149, duration: 37.911s, episode steps: 1168, steps per second:  31, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.161 [0.000, 5.000],  loss: 0.029266, mae: 4.442412, mean_q: 5.348970, mean_eps: 0.185461\n",
      "  858885/1500000: episode: 1150, duration: 29.480s, episode steps: 891, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.835 [0.000, 5.000],  loss: 0.029396, mae: 4.431106, mean_q: 5.336889, mean_eps: 0.184482\n",
      "  860068/1500000: episode: 1151, duration: 39.907s, episode steps: 1183, steps per second:  30, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.029016, mae: 4.446172, mean_q: 5.354745, mean_eps: 0.183498\n",
      "  860717/1500000: episode: 1152, duration: 23.748s, episode steps: 649, steps per second:  27, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.025435, mae: 4.437365, mean_q: 5.343580, mean_eps: 0.182628\n",
      "  861502/1500000: episode: 1153, duration: 26.609s, episode steps: 785, steps per second:  30, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.941 [0.000, 5.000],  loss: 0.029091, mae: 4.465210, mean_q: 5.377176, mean_eps: 0.181946\n",
      "  862115/1500000: episode: 1154, duration: 20.429s, episode steps: 613, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.026824, mae: 4.441109, mean_q: 5.346110, mean_eps: 0.181282\n",
      "  863027/1500000: episode: 1155, duration: 30.462s, episode steps: 912, steps per second:  30, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.980 [0.000, 5.000],  loss: 0.028345, mae: 4.484803, mean_q: 5.399695, mean_eps: 0.180559\n",
      "  863810/1500000: episode: 1156, duration: 26.164s, episode steps: 783, steps per second:  30, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.042 [0.000, 5.000],  loss: 0.031684, mae: 4.450798, mean_q: 5.359652, mean_eps: 0.179753\n",
      "  864627/1500000: episode: 1157, duration: 27.141s, episode steps: 817, steps per second:  30, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.030488, mae: 4.478859, mean_q: 5.391667, mean_eps: 0.178993\n",
      "  865417/1500000: episode: 1158, duration: 27.748s, episode steps: 790, steps per second:  28, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.028215, mae: 4.457705, mean_q: 5.370092, mean_eps: 0.178229\n",
      "  865953/1500000: episode: 1159, duration: 17.761s, episode steps: 536, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.029027, mae: 4.527699, mean_q: 5.452405, mean_eps: 0.177598\n",
      "  866456/1500000: episode: 1160, duration: 16.987s, episode steps: 503, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.159 [0.000, 5.000],  loss: 0.026461, mae: 4.463277, mean_q: 5.373081, mean_eps: 0.177106\n",
      "  867411/1500000: episode: 1161, duration: 31.896s, episode steps: 955, steps per second:  30, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.182 [0.000, 5.000],  loss: 0.026577, mae: 4.479108, mean_q: 5.397042, mean_eps: 0.176415\n",
      "  867797/1500000: episode: 1162, duration: 12.876s, episode steps: 386, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.762 [0.000, 5.000],  loss: 0.033482, mae: 4.518996, mean_q: 5.442897, mean_eps: 0.175776\n",
      "  868454/1500000: episode: 1163, duration: 22.008s, episode steps: 657, steps per second:  30, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.811 [0.000, 5.000],  loss: 0.030162, mae: 4.499843, mean_q: 5.418996, mean_eps: 0.175280\n",
      "  868953/1500000: episode: 1164, duration: 16.808s, episode steps: 499, steps per second:  30, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.046 [0.000, 5.000],  loss: 0.033047, mae: 4.482044, mean_q: 5.396163, mean_eps: 0.174731\n",
      "  869346/1500000: episode: 1165, duration: 13.109s, episode steps: 393, steps per second:  30, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.924 [0.000, 5.000],  loss: 0.023678, mae: 4.518814, mean_q: 5.440765, mean_eps: 0.174308\n",
      "  870373/1500000: episode: 1166, duration: 34.203s, episode steps: 1027, steps per second:  30, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.027047, mae: 4.496189, mean_q: 5.412955, mean_eps: 0.173633\n",
      "  871019/1500000: episode: 1167, duration: 21.366s, episode steps: 646, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.030824, mae: 4.484525, mean_q: 5.398415, mean_eps: 0.172839\n",
      "  871526/1500000: episode: 1168, duration: 16.768s, episode steps: 507, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.031510, mae: 4.472725, mean_q: 5.384084, mean_eps: 0.172292\n",
      "  872211/1500000: episode: 1169, duration: 23.129s, episode steps: 685, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.822 [0.000, 5.000],  loss: 0.026858, mae: 4.470002, mean_q: 5.384491, mean_eps: 0.171725\n",
      "  873035/1500000: episode: 1170, duration: 28.186s, episode steps: 824, steps per second:  29, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.029038, mae: 4.491295, mean_q: 5.406428, mean_eps: 0.171009\n",
      "  873718/1500000: episode: 1171, duration: 23.806s, episode steps: 683, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.028217, mae: 4.461998, mean_q: 5.372683, mean_eps: 0.170293\n",
      "  875036/1500000: episode: 1172, duration: 44.640s, episode steps: 1318, steps per second:  30, episode reward: 29.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.033431, mae: 4.476510, mean_q: 5.388619, mean_eps: 0.169343\n",
      "  876105/1500000: episode: 1173, duration: 37.607s, episode steps: 1069, steps per second:  28, episode reward: 29.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.027179, mae: 4.484170, mean_q: 5.397764, mean_eps: 0.168209\n",
      "  877246/1500000: episode: 1174, duration: 39.625s, episode steps: 1141, steps per second:  29, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.023880, mae: 4.478278, mean_q: 5.395084, mean_eps: 0.167158\n",
      "  878214/1500000: episode: 1175, duration: 32.888s, episode steps: 968, steps per second:  29, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.845 [0.000, 5.000],  loss: 0.026577, mae: 4.517705, mean_q: 5.439225, mean_eps: 0.166157\n",
      "  878925/1500000: episode: 1176, duration: 24.424s, episode steps: 711, steps per second:  29, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.767 [0.000, 5.000],  loss: 0.029593, mae: 4.473148, mean_q: 5.381810, mean_eps: 0.165359\n",
      "  879472/1500000: episode: 1177, duration: 18.637s, episode steps: 547, steps per second:  29, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.876 [0.000, 5.000],  loss: 0.029096, mae: 4.474657, mean_q: 5.383809, mean_eps: 0.164762\n",
      "  880092/1500000: episode: 1178, duration: 21.371s, episode steps: 620, steps per second:  29, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.029843, mae: 4.538712, mean_q: 5.465487, mean_eps: 0.164209\n",
      "  881145/1500000: episode: 1179, duration: 36.231s, episode steps: 1053, steps per second:  29, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.740 [0.000, 5.000],  loss: 0.027434, mae: 4.524711, mean_q: 5.454043, mean_eps: 0.163413\n",
      "  882342/1500000: episode: 1180, duration: 41.343s, episode steps: 1197, steps per second:  29, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.845 [0.000, 5.000],  loss: 0.029942, mae: 4.516495, mean_q: 5.438673, mean_eps: 0.162343\n",
      "  883238/1500000: episode: 1181, duration: 30.333s, episode steps: 896, steps per second:  30, episode reward: 24.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.992 [0.000, 5.000],  loss: 0.030215, mae: 4.524945, mean_q: 5.450212, mean_eps: 0.161350\n",
      "  883943/1500000: episode: 1182, duration: 23.878s, episode steps: 705, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.847 [0.000, 5.000],  loss: 0.024868, mae: 4.560280, mean_q: 5.490169, mean_eps: 0.160590\n",
      "  884617/1500000: episode: 1183, duration: 22.890s, episode steps: 674, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.073 [0.000, 5.000],  loss: 0.029474, mae: 4.507493, mean_q: 5.428383, mean_eps: 0.159934\n",
      "  885509/1500000: episode: 1184, duration: 30.451s, episode steps: 892, steps per second:  29, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.029860, mae: 4.487524, mean_q: 5.403929, mean_eps: 0.159189\n",
      "  886521/1500000: episode: 1185, duration: 34.571s, episode steps: 1012, steps per second:  29, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.029914, mae: 4.514448, mean_q: 5.437752, mean_eps: 0.158285\n",
      "  887065/1500000: episode: 1186, duration: 18.590s, episode steps: 544, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.675 [0.000, 5.000],  loss: 0.026531, mae: 4.497634, mean_q: 5.413832, mean_eps: 0.157546\n",
      "  887601/1500000: episode: 1187, duration: 18.049s, episode steps: 536, steps per second:  30, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.866 [0.000, 5.000],  loss: 0.031649, mae: 4.552268, mean_q: 5.480009, mean_eps: 0.157033\n",
      "  888075/1500000: episode: 1188, duration: 15.971s, episode steps: 474, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.158 [0.000, 5.000],  loss: 0.029727, mae: 4.548896, mean_q: 5.482851, mean_eps: 0.156554\n",
      "  888685/1500000: episode: 1189, duration: 20.973s, episode steps: 610, steps per second:  29, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.098 [0.000, 5.000],  loss: 0.030583, mae: 4.544889, mean_q: 5.477707, mean_eps: 0.156039\n",
      "  889168/1500000: episode: 1190, duration: 16.668s, episode steps: 483, steps per second:  29, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.940 [0.000, 5.000],  loss: 0.033910, mae: 4.577738, mean_q: 5.510041, mean_eps: 0.155520\n",
      "  889786/1500000: episode: 1191, duration: 21.030s, episode steps: 618, steps per second:  29, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.031829, mae: 4.539859, mean_q: 5.466519, mean_eps: 0.154998\n",
      "  890456/1500000: episode: 1192, duration: 22.713s, episode steps: 670, steps per second:  29, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.029164, mae: 4.533832, mean_q: 5.461889, mean_eps: 0.154386\n",
      "  891484/1500000: episode: 1193, duration: 34.859s, episode steps: 1028, steps per second:  29, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.029384, mae: 4.550190, mean_q: 5.480217, mean_eps: 0.153580\n",
      "  892424/1500000: episode: 1194, duration: 31.852s, episode steps: 940, steps per second:  30, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.176 [0.000, 5.000],  loss: 0.029864, mae: 4.552582, mean_q: 5.485995, mean_eps: 0.152646\n",
      "  893043/1500000: episode: 1195, duration: 21.174s, episode steps: 619, steps per second:  29, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.737 [0.000, 5.000],  loss: 0.029573, mae: 4.575764, mean_q: 5.506248, mean_eps: 0.151905\n",
      "  894063/1500000: episode: 1196, duration: 35.164s, episode steps: 1020, steps per second:  29, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.029487, mae: 4.538449, mean_q: 5.464167, mean_eps: 0.151126\n",
      "  895001/1500000: episode: 1197, duration: 33.593s, episode steps: 938, steps per second:  28, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.071 [0.000, 5.000],  loss: 0.031469, mae: 4.567675, mean_q: 5.504383, mean_eps: 0.150195\n",
      "  895871/1500000: episode: 1198, duration: 31.028s, episode steps: 870, steps per second:  28, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.028777, mae: 4.550143, mean_q: 5.483535, mean_eps: 0.149336\n",
      "  896521/1500000: episode: 1199, duration: 23.445s, episode steps: 650, steps per second:  28, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.028850, mae: 4.543041, mean_q: 5.473164, mean_eps: 0.148614\n",
      "  897208/1500000: episode: 1200, duration: 24.298s, episode steps: 687, steps per second:  28, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.027865, mae: 4.553125, mean_q: 5.484660, mean_eps: 0.147979\n",
      "  898155/1500000: episode: 1201, duration: 32.852s, episode steps: 947, steps per second:  29, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.056 [0.000, 5.000],  loss: 0.027734, mae: 4.536541, mean_q: 5.460179, mean_eps: 0.147204\n",
      "  899095/1500000: episode: 1202, duration: 31.855s, episode steps: 940, steps per second:  30, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.806 [0.000, 5.000],  loss: 0.029957, mae: 4.568085, mean_q: 5.499388, mean_eps: 0.146307\n",
      "  899784/1500000: episode: 1203, duration: 23.026s, episode steps: 689, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.128 [0.000, 5.000],  loss: 0.027317, mae: 4.557730, mean_q: 5.488644, mean_eps: 0.145534\n",
      "Step 900000: saving model to dqn_SpaceInvaders-v0_step_900000.h5f\n",
      "  900239/1500000: episode: 1204, duration: 15.807s, episode steps: 455, steps per second:  29, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.028960, mae: 4.567217, mean_q: 5.503144, mean_eps: 0.144991\n",
      "  900870/1500000: episode: 1205, duration: 21.011s, episode steps: 631, steps per second:  30, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.027928, mae: 4.542802, mean_q: 5.477409, mean_eps: 0.144474\n",
      "  901374/1500000: episode: 1206, duration: 16.714s, episode steps: 504, steps per second:  30, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.029005, mae: 4.573807, mean_q: 5.513957, mean_eps: 0.143934\n",
      "  901992/1500000: episode: 1207, duration: 20.307s, episode steps: 618, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.761 [0.000, 5.000],  loss: 0.028895, mae: 4.551438, mean_q: 5.481010, mean_eps: 0.143402\n",
      "  902621/1500000: episode: 1208, duration: 20.578s, episode steps: 629, steps per second:  31, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.028827, mae: 4.548460, mean_q: 5.477449, mean_eps: 0.142809\n",
      "  903017/1500000: episode: 1209, duration: 13.128s, episode steps: 396, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.967 [0.000, 5.000],  loss: 0.029165, mae: 4.514640, mean_q: 5.439724, mean_eps: 0.142321\n",
      "  903722/1500000: episode: 1210, duration: 23.338s, episode steps: 705, steps per second:  30, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.033656, mae: 4.564788, mean_q: 5.496633, mean_eps: 0.141799\n",
      "  904247/1500000: episode: 1211, duration: 17.595s, episode steps: 525, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.033956, mae: 4.576838, mean_q: 5.513267, mean_eps: 0.141215\n",
      "  905256/1500000: episode: 1212, duration: 33.625s, episode steps: 1009, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.028311, mae: 4.569122, mean_q: 5.504017, mean_eps: 0.140488\n",
      "  905939/1500000: episode: 1213, duration: 22.688s, episode steps: 683, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.028537, mae: 4.531297, mean_q: 5.462139, mean_eps: 0.139684\n",
      "  906756/1500000: episode: 1214, duration: 27.089s, episode steps: 817, steps per second:  30, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.024877, mae: 4.557471, mean_q: 5.491197, mean_eps: 0.138971\n",
      "  907792/1500000: episode: 1215, duration: 37.288s, episode steps: 1036, steps per second:  28, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.029142, mae: 4.550779, mean_q: 5.483107, mean_eps: 0.138092\n",
      "  908352/1500000: episode: 1216, duration: 19.411s, episode steps: 560, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.027566, mae: 4.527871, mean_q: 5.455327, mean_eps: 0.137334\n",
      "  909195/1500000: episode: 1217, duration: 29.016s, episode steps: 843, steps per second:  29, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.030005, mae: 4.526827, mean_q: 5.450841, mean_eps: 0.136667\n",
      "  909604/1500000: episode: 1218, duration: 14.175s, episode steps: 409, steps per second:  29, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.032510, mae: 4.524057, mean_q: 5.447094, mean_eps: 0.136072\n",
      "  910532/1500000: episode: 1219, duration: 31.720s, episode steps: 928, steps per second:  29, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.827 [0.000, 5.000],  loss: 0.026731, mae: 4.534208, mean_q: 5.460801, mean_eps: 0.135437\n",
      "  911309/1500000: episode: 1220, duration: 25.648s, episode steps: 777, steps per second:  30, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.028485, mae: 4.524244, mean_q: 5.450815, mean_eps: 0.134626\n",
      "  912269/1500000: episode: 1221, duration: 31.374s, episode steps: 960, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.983 [0.000, 5.000],  loss: 0.027108, mae: 4.521884, mean_q: 5.445790, mean_eps: 0.133800\n",
      "  913208/1500000: episode: 1222, duration: 31.210s, episode steps: 939, steps per second:  30, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.031650, mae: 4.526238, mean_q: 5.450994, mean_eps: 0.132899\n",
      "  914184/1500000: episode: 1223, duration: 33.056s, episode steps: 976, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.027298, mae: 4.511007, mean_q: 5.432934, mean_eps: 0.131991\n",
      "  915285/1500000: episode: 1224, duration: 37.938s, episode steps: 1101, steps per second:  29, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.030685, mae: 4.523889, mean_q: 5.449616, mean_eps: 0.131003\n",
      "  915657/1500000: episode: 1225, duration: 12.537s, episode steps: 372, steps per second:  30, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.054 [0.000, 5.000],  loss: 0.028966, mae: 4.532265, mean_q: 5.463603, mean_eps: 0.130302\n",
      "  916492/1500000: episode: 1226, duration: 28.555s, episode steps: 835, steps per second:  29, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.993 [0.000, 5.000],  loss: 0.029086, mae: 4.541090, mean_q: 5.469048, mean_eps: 0.129730\n",
      "  917928/1500000: episode: 1227, duration: 49.083s, episode steps: 1436, steps per second:  29, episode reward: 25.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.942 [0.000, 5.000],  loss: 0.029336, mae: 4.538146, mean_q: 5.464627, mean_eps: 0.128652\n",
      "  918930/1500000: episode: 1228, duration: 34.277s, episode steps: 1002, steps per second:  29, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.927 [0.000, 5.000],  loss: 0.032099, mae: 4.540952, mean_q: 5.468737, mean_eps: 0.127493\n",
      "  920017/1500000: episode: 1229, duration: 37.038s, episode steps: 1087, steps per second:  29, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.016 [0.000, 5.000],  loss: 0.033366, mae: 4.542822, mean_q: 5.469947, mean_eps: 0.126500\n",
      "  920975/1500000: episode: 1230, duration: 32.497s, episode steps: 958, steps per second:  29, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.027529, mae: 4.535179, mean_q: 5.462038, mean_eps: 0.125529\n",
      "  922259/1500000: episode: 1231, duration: 43.467s, episode steps: 1284, steps per second:  30, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.857 [0.000, 5.000],  loss: 0.028331, mae: 4.565224, mean_q: 5.494907, mean_eps: 0.124465\n",
      "  923302/1500000: episode: 1232, duration: 35.402s, episode steps: 1043, steps per second:  29, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.757 [0.000, 5.000],  loss: 0.028904, mae: 4.540241, mean_q: 5.468074, mean_eps: 0.123359\n",
      "  923840/1500000: episode: 1233, duration: 18.778s, episode steps: 538, steps per second:  29, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.027544, mae: 4.593804, mean_q: 5.530598, mean_eps: 0.122609\n",
      "  924860/1500000: episode: 1234, duration: 36.679s, episode steps: 1020, steps per second:  28, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.096 [0.000, 5.000],  loss: 0.029585, mae: 4.567969, mean_q: 5.500995, mean_eps: 0.121869\n",
      "  925780/1500000: episode: 1235, duration: 32.986s, episode steps: 920, steps per second:  28, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.000 [0.000, 5.000],  loss: 0.028486, mae: 4.578618, mean_q: 5.513442, mean_eps: 0.120948\n",
      "  926597/1500000: episode: 1236, duration: 29.227s, episode steps: 817, steps per second:  28, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.969 [0.000, 5.000],  loss: 0.025123, mae: 4.560020, mean_q: 5.491115, mean_eps: 0.120121\n",
      "  927520/1500000: episode: 1237, duration: 31.878s, episode steps: 923, steps per second:  29, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.013 [0.000, 5.000],  loss: 0.028742, mae: 4.557484, mean_q: 5.486861, mean_eps: 0.119295\n",
      "  928189/1500000: episode: 1238, duration: 22.734s, episode steps: 669, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.027073, mae: 4.576807, mean_q: 5.514511, mean_eps: 0.118539\n",
      "  929271/1500000: episode: 1239, duration: 36.755s, episode steps: 1082, steps per second:  29, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.026991, mae: 4.572480, mean_q: 5.503671, mean_eps: 0.117707\n",
      "  929887/1500000: episode: 1240, duration: 21.406s, episode steps: 616, steps per second:  29, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.898 [0.000, 5.000],  loss: 0.024560, mae: 4.574581, mean_q: 5.508326, mean_eps: 0.116901\n",
      "  930507/1500000: episode: 1241, duration: 21.662s, episode steps: 620, steps per second:  29, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.131 [0.000, 5.000],  loss: 0.026169, mae: 4.585984, mean_q: 5.524971, mean_eps: 0.116314\n",
      "  931322/1500000: episode: 1242, duration: 27.797s, episode steps: 815, steps per second:  29, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.029776, mae: 4.563376, mean_q: 5.498925, mean_eps: 0.115632\n",
      "  931858/1500000: episode: 1243, duration: 18.667s, episode steps: 536, steps per second:  29, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.991 [0.000, 5.000],  loss: 0.023040, mae: 4.527676, mean_q: 5.456468, mean_eps: 0.114990\n",
      "  932438/1500000: episode: 1244, duration: 20.619s, episode steps: 580, steps per second:  28, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.027729, mae: 4.550755, mean_q: 5.484509, mean_eps: 0.114459\n",
      "  933179/1500000: episode: 1245, duration: 26.256s, episode steps: 741, steps per second:  28, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.879 [0.000, 5.000],  loss: 0.028347, mae: 4.562113, mean_q: 5.492214, mean_eps: 0.113832\n",
      "  934226/1500000: episode: 1246, duration: 36.636s, episode steps: 1047, steps per second:  29, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.025919, mae: 4.545980, mean_q: 5.473948, mean_eps: 0.112983\n",
      "  934911/1500000: episode: 1247, duration: 24.043s, episode steps: 685, steps per second:  28, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.028861, mae: 4.563927, mean_q: 5.500262, mean_eps: 0.112160\n",
      "  935823/1500000: episode: 1248, duration: 32.071s, episode steps: 912, steps per second:  28, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.027022, mae: 4.597120, mean_q: 5.538855, mean_eps: 0.111402\n",
      "  936504/1500000: episode: 1249, duration: 23.389s, episode steps: 681, steps per second:  29, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.027060, mae: 4.586442, mean_q: 5.523560, mean_eps: 0.110646\n",
      "  937471/1500000: episode: 1250, duration: 34.132s, episode steps: 967, steps per second:  28, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.028788, mae: 4.599371, mean_q: 5.538193, mean_eps: 0.109863\n",
      "  938573/1500000: episode: 1251, duration: 39.114s, episode steps: 1102, steps per second:  28, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.982 [0.000, 5.000],  loss: 0.028901, mae: 4.581951, mean_q: 5.516070, mean_eps: 0.108879\n",
      "  939092/1500000: episode: 1252, duration: 18.147s, episode steps: 519, steps per second:  29, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.613 [0.000, 5.000],  loss: 0.029833, mae: 4.595958, mean_q: 5.531973, mean_eps: 0.108110\n",
      "  940065/1500000: episode: 1253, duration: 34.488s, episode steps: 973, steps per second:  28, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.027207, mae: 4.589772, mean_q: 5.527310, mean_eps: 0.107401\n",
      "  941040/1500000: episode: 1254, duration: 33.346s, episode steps: 975, steps per second:  29, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.027282, mae: 4.632840, mean_q: 5.584114, mean_eps: 0.106476\n",
      "  941787/1500000: episode: 1255, duration: 25.416s, episode steps: 747, steps per second:  29, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.021937, mae: 4.640244, mean_q: 5.590524, mean_eps: 0.105659\n",
      "  942439/1500000: episode: 1256, duration: 22.162s, episode steps: 652, steps per second:  29, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: 0.028290, mae: 4.629023, mean_q: 5.573157, mean_eps: 0.104994\n",
      "  943468/1500000: episode: 1257, duration: 35.823s, episode steps: 1029, steps per second:  29, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.028029, mae: 4.620804, mean_q: 5.564645, mean_eps: 0.104196\n",
      "  944588/1500000: episode: 1258, duration: 37.758s, episode steps: 1120, steps per second:  30, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.028305, mae: 4.617145, mean_q: 5.558534, mean_eps: 0.103175\n",
      "  945142/1500000: episode: 1259, duration: 18.753s, episode steps: 554, steps per second:  30, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.736 [0.000, 5.000],  loss: 0.031103, mae: 4.625158, mean_q: 5.570343, mean_eps: 0.102379\n",
      "  945768/1500000: episode: 1260, duration: 21.393s, episode steps: 626, steps per second:  29, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.027841, mae: 4.611967, mean_q: 5.557577, mean_eps: 0.101819\n",
      "  946642/1500000: episode: 1261, duration: 31.051s, episode steps: 874, steps per second:  28, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.881 [0.000, 5.000],  loss: 0.028091, mae: 4.650998, mean_q: 5.602119, mean_eps: 0.101106\n",
      "  947625/1500000: episode: 1262, duration: 32.843s, episode steps: 983, steps per second:  30, episode reward: 25.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.027403, mae: 4.613367, mean_q: 5.558410, mean_eps: 0.100223\n",
      "  948722/1500000: episode: 1263, duration: 36.108s, episode steps: 1097, steps per second:  30, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.843 [0.000, 5.000],  loss: 0.029912, mae: 4.619140, mean_q: 5.560244, mean_eps: 0.099235\n",
      "  949531/1500000: episode: 1264, duration: 30.850s, episode steps: 809, steps per second:  26, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.026651, mae: 4.628798, mean_q: 5.572492, mean_eps: 0.098330\n",
      "  950508/1500000: episode: 1265, duration: 38.471s, episode steps: 977, steps per second:  25, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.640 [0.000, 5.000],  loss: 0.022499, mae: 4.618296, mean_q: 5.562056, mean_eps: 0.097483\n",
      "  951511/1500000: episode: 1266, duration: 36.641s, episode steps: 1003, steps per second:  27, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.964 [0.000, 5.000],  loss: 0.025575, mae: 4.649713, mean_q: 5.603035, mean_eps: 0.096542\n",
      "  952102/1500000: episode: 1267, duration: 22.626s, episode steps: 591, steps per second:  26, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.028260, mae: 4.654792, mean_q: 5.611131, mean_eps: 0.095784\n",
      "  952590/1500000: episode: 1268, duration: 15.827s, episode steps: 488, steps per second:  31, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.029628, mae: 4.652679, mean_q: 5.605888, mean_eps: 0.095271\n",
      "  953374/1500000: episode: 1269, duration: 26.221s, episode steps: 784, steps per second:  30, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.024398, mae: 4.661558, mean_q: 5.617784, mean_eps: 0.094667\n",
      "  954332/1500000: episode: 1270, duration: 32.760s, episode steps: 958, steps per second:  29, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.848 [0.000, 5.000],  loss: 0.027278, mae: 4.669832, mean_q: 5.624986, mean_eps: 0.093841\n",
      "  954998/1500000: episode: 1271, duration: 22.701s, episode steps: 666, steps per second:  29, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.028681, mae: 4.663287, mean_q: 5.620780, mean_eps: 0.093069\n",
      "  955855/1500000: episode: 1272, duration: 28.565s, episode steps: 857, steps per second:  30, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 3.121 [0.000, 5.000],  loss: 0.028509, mae: 4.680102, mean_q: 5.639654, mean_eps: 0.092345\n",
      "  957003/1500000: episode: 1273, duration: 38.436s, episode steps: 1148, steps per second:  30, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.029520, mae: 4.702178, mean_q: 5.667259, mean_eps: 0.091393\n",
      "  957693/1500000: episode: 1274, duration: 23.452s, episode steps: 690, steps per second:  29, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.028252, mae: 4.661006, mean_q: 5.615466, mean_eps: 0.090519\n",
      "  958301/1500000: episode: 1275, duration: 20.623s, episode steps: 608, steps per second:  29, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.026169, mae: 4.688526, mean_q: 5.648848, mean_eps: 0.089902\n",
      "  958974/1500000: episode: 1276, duration: 22.976s, episode steps: 673, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.028521, mae: 4.676302, mean_q: 5.633919, mean_eps: 0.089294\n",
      "  960046/1500000: episode: 1277, duration: 39.273s, episode steps: 1072, steps per second:  27, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.029043, mae: 4.693208, mean_q: 5.649733, mean_eps: 0.088466\n",
      "  960902/1500000: episode: 1278, duration: 29.215s, episode steps: 856, steps per second:  29, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.028456, mae: 4.697151, mean_q: 5.657196, mean_eps: 0.087550\n",
      "  961967/1500000: episode: 1279, duration: 36.241s, episode steps: 1065, steps per second:  29, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.754 [0.000, 5.000],  loss: 0.029428, mae: 4.683990, mean_q: 5.639442, mean_eps: 0.086638\n",
      "  962605/1500000: episode: 1280, duration: 22.410s, episode steps: 638, steps per second:  28, episode reward: 17.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.027673, mae: 4.678048, mean_q: 5.634712, mean_eps: 0.085828\n",
      "  963319/1500000: episode: 1281, duration: 24.031s, episode steps: 714, steps per second:  30, episode reward: 20.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.030725, mae: 4.697524, mean_q: 5.658766, mean_eps: 0.085186\n",
      "  964240/1500000: episode: 1282, duration: 31.715s, episode steps: 921, steps per second:  29, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.032912, mae: 4.682696, mean_q: 5.640949, mean_eps: 0.084411\n",
      "  964984/1500000: episode: 1283, duration: 25.456s, episode steps: 744, steps per second:  29, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.032823, mae: 4.663175, mean_q: 5.614797, mean_eps: 0.083621\n",
      "  965639/1500000: episode: 1284, duration: 22.749s, episode steps: 655, steps per second:  29, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.025268, mae: 4.736382, mean_q: 5.706822, mean_eps: 0.082956\n",
      "  966505/1500000: episode: 1285, duration: 29.730s, episode steps: 866, steps per second:  29, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.027362, mae: 4.734850, mean_q: 5.706310, mean_eps: 0.082232\n",
      "  967026/1500000: episode: 1286, duration: 17.828s, episode steps: 521, steps per second:  29, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.027624, mae: 4.699719, mean_q: 5.664733, mean_eps: 0.081572\n",
      "  968048/1500000: episode: 1287, duration: 34.048s, episode steps: 1022, steps per second:  30, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.028681, mae: 4.731310, mean_q: 5.696622, mean_eps: 0.080841\n",
      "  968892/1500000: episode: 1288, duration: 28.088s, episode steps: 844, steps per second:  30, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.802 [0.000, 5.000],  loss: 0.028813, mae: 4.731740, mean_q: 5.701574, mean_eps: 0.079955\n",
      "  969545/1500000: episode: 1289, duration: 21.980s, episode steps: 653, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.812 [0.000, 5.000],  loss: 0.024916, mae: 4.737848, mean_q: 5.706883, mean_eps: 0.079243\n",
      "  970690/1500000: episode: 1290, duration: 38.409s, episode steps: 1145, steps per second:  30, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.024788, mae: 4.686484, mean_q: 5.643567, mean_eps: 0.078388\n",
      "  971223/1500000: episode: 1291, duration: 17.560s, episode steps: 533, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.024476, mae: 4.669192, mean_q: 5.627083, mean_eps: 0.077592\n",
      "  972121/1500000: episode: 1292, duration: 32.107s, episode steps: 898, steps per second:  28, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.023 [0.000, 5.000],  loss: 0.025703, mae: 4.710782, mean_q: 5.674680, mean_eps: 0.076912\n",
      "  972930/1500000: episode: 1293, duration: 28.446s, episode steps: 809, steps per second:  28, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.371 [0.000, 5.000],  loss: 0.025040, mae: 4.714625, mean_q: 5.678667, mean_eps: 0.076100\n",
      "  973320/1500000: episode: 1294, duration: 13.673s, episode steps: 390, steps per second:  29, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.818 [0.000, 5.000],  loss: 0.028592, mae: 4.716848, mean_q: 5.681894, mean_eps: 0.075532\n",
      "  974215/1500000: episode: 1295, duration: 31.710s, episode steps: 895, steps per second:  28, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.027907, mae: 4.706119, mean_q: 5.669063, mean_eps: 0.074922\n",
      "  975119/1500000: episode: 1296, duration: 32.320s, episode steps: 904, steps per second:  28, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.878 [0.000, 5.000],  loss: 0.029081, mae: 4.722551, mean_q: 5.687392, mean_eps: 0.074067\n",
      "  975609/1500000: episode: 1297, duration: 16.513s, episode steps: 490, steps per second:  30, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.027695, mae: 4.739889, mean_q: 5.710327, mean_eps: 0.073404\n",
      "  975970/1500000: episode: 1298, duration: 12.359s, episode steps: 361, steps per second:  29, episode reward:  1.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.029630, mae: 4.730601, mean_q: 5.693925, mean_eps: 0.073000\n",
      "  976986/1500000: episode: 1299, duration: 36.489s, episode steps: 1016, steps per second:  28, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.026951, mae: 4.730938, mean_q: 5.698857, mean_eps: 0.072346\n",
      "  977610/1500000: episode: 1300, duration: 26.112s, episode steps: 624, steps per second:  24, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.023765, mae: 4.738141, mean_q: 5.707766, mean_eps: 0.071567\n",
      "  978518/1500000: episode: 1301, duration: 33.425s, episode steps: 908, steps per second:  27, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.026625, mae: 4.731389, mean_q: 5.698609, mean_eps: 0.070839\n",
      "  979525/1500000: episode: 1302, duration: 49.124s, episode steps: 1007, steps per second:  20, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.029635, mae: 4.746844, mean_q: 5.713467, mean_eps: 0.069929\n",
      "  980457/1500000: episode: 1303, duration: 78.626s, episode steps: 932, steps per second:  12, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.026840, mae: 4.745108, mean_q: 5.714987, mean_eps: 0.069008\n",
      "  981846/1500000: episode: 1304, duration: 114.021s, episode steps: 1389, steps per second:  12, episode reward: 31.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.027171, mae: 4.775092, mean_q: 5.747885, mean_eps: 0.067906\n",
      "  982226/1500000: episode: 1305, duration: 30.260s, episode steps: 380, steps per second:  13, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 3.450 [0.000, 5.000],  loss: 0.026809, mae: 4.757466, mean_q: 5.726692, mean_eps: 0.067066\n",
      "  982936/1500000: episode: 1306, duration: 57.940s, episode steps: 710, steps per second:  12, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.035 [0.000, 5.000],  loss: 0.029021, mae: 4.773539, mean_q: 5.750411, mean_eps: 0.066549\n",
      "  983296/1500000: episode: 1307, duration: 28.743s, episode steps: 360, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.750 [0.000, 5.000],  loss: 0.026087, mae: 4.752733, mean_q: 5.723502, mean_eps: 0.066042\n",
      "  984167/1500000: episode: 1308, duration: 70.917s, episode steps: 871, steps per second:  12, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.839 [0.000, 5.000],  loss: 0.024664, mae: 4.752800, mean_q: 5.719764, mean_eps: 0.065457\n",
      "  984926/1500000: episode: 1309, duration: 66.551s, episode steps: 759, steps per second:  11, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.028776, mae: 4.757819, mean_q: 5.724458, mean_eps: 0.064681\n",
      "  985588/1500000: episode: 1310, duration: 61.839s, episode steps: 662, steps per second:  11, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.024385, mae: 4.777530, mean_q: 5.754901, mean_eps: 0.064007\n",
      "  986457/1500000: episode: 1311, duration: 73.584s, episode steps: 869, steps per second:  12, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.827 [0.000, 5.000],  loss: 0.027574, mae: 4.763244, mean_q: 5.735754, mean_eps: 0.063279\n",
      "  987133/1500000: episode: 1312, duration: 56.806s, episode steps: 676, steps per second:  12, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.026904, mae: 4.765163, mean_q: 5.735080, mean_eps: 0.062544\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# ENTRENAMIENTO CONTINUADO (1.5M pasos adicionales)\n",
    "# ================================\n",
    "\n",
    "# Cargar pesos previos del modelo entrenado hasta 500k pasos\n",
    "dqn.load_weights('dqn_SpaceInvaders-v0_final_weights_600k.h5f')\n",
    "\n",
    "# Ajuste de hiperparámetros antes de continuar (opcional)\n",
    "dqn.target_model_update = 5000  # Actualizar target model más frecuentemente\n",
    "\n",
    "# Redefinir callbacks para guardado y logging\n",
    "checkpoint_callback = ModelIntervalCheckpoint(\n",
    "    filepath='dqn_SpaceInvaders-v0_step_{step}.h5f',\n",
    "    interval=100000,  # Guarda cada 100k pasos\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "log_callback = FileLogger('dqn_SpaceInvaders-v0_log_continued.json', interval=10000)\n",
    "\n",
    "# Entrenamiento adicional\n",
    "print(\"Entrenando modelo desde paso 500k hasta 2M...\")\n",
    "dqn.fit(env, nb_steps=1500000, visualize=False, verbose=2, callbacks=[checkpoint_callback, log_callback])\n",
    "\n",
    "# Guardar pesos finales tras entrenamiento extendido\n",
    "final_weights_extended = 'dqn_SpaceInvaders-v0_final_weights_extendido.h5f'\n",
    "dqn.save_weights(final_weights_extended, overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dqn_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
