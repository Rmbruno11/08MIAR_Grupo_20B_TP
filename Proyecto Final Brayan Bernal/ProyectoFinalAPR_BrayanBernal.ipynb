{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d558e66d",
   "metadata": {},
   "source": [
    "# Actividad - Proyecto práctico\n",
    "\n",
    "\n",
    "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
    "*   Alumno 1: **Brayan Alexander Bernal**\n",
    "*   Alumno 2:\n",
    "*   Alumno 3: \n",
    "*   Alumno 4: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867045bf",
   "metadata": {},
   "source": [
    "---\n",
    "## **PARTE 1** - Instalación y requisitos previos\n",
    "\n",
    "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
    "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
    "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
    "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
    "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169aeac",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.1. Preparar enviroment (solo local)\n",
    "\n",
    "\n",
    "\n",
    "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
    "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
    "2. Instalar Anaconda\n",
    "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
    "\n",
    "\n",
    "```\n",
    "conda create --name miar_rl python=3.8\n",
    "conda activate miar_rl\n",
    "cd \"PATH_TO_FOLDER\"\n",
    "conda install git\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "\n",
    "4. Abrir la notebook con *jupyter-notebook*.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "jupyter-notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5124ea2",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2. Localizar entorno de trabajo: Google colab o local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa45899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
    "mount='/content/gdrive'\n",
    "drive_root = mount + \"/My Drive/08_MIAR_AprendizajePorRefuerzo/ProyectoPractico\"\n",
    "\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428a267",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.3. Montar carpeta de datos local (solo Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669092dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local c:\\Users\\Windows\\Documents\\Universidad VIU\\Apredizaje por refuerzo\\ProyectoFinal\n",
      "Archivos en el directorio: \n",
      "['ProyectoFinalAPR_BrayanBernal.ipynb', 'Proyecto_práctico_AprendizajePorRefuerzo.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# Switch to the directory on the Google Drive that you want to use\n",
    "import os\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "  if IN_COLAB:\n",
    "    # Mount the Google Drive at mount\n",
    "    print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "    drive.mount(mount)\n",
    "\n",
    "    # Create drive_root if it doesn't exist\n",
    "    create_drive_root = True\n",
    "    if create_drive_root:\n",
    "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
    "      os.makedirs(drive_root, exist_ok=True)\n",
    "\n",
    "    # Change to the directory\n",
    "    print(\"\\nColab: Changing directory to \", drive_root)\n",
    "    %cd $drive_root\n",
    "else:\n",
    "    print(\"Running in local\", os.getcwd())\n",
    "# Verify we're in the correct working directory\n",
    "%pwd\n",
    "print(\"Archivos en el directorio: \")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b856c8",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.4. Instalar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a46512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.17.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.24.3)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym==0.17.3) (1.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/Kojoley/atari-py.git\n",
      "  Cloning https://github.com/Kojoley/atari-py.git to c:\\users\\windows\\appdata\\local\\temp\\pip-req-build-66qnqxf4\n",
      "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from atari-py==1.2.2) (1.24.3)\n",
      "Building wheels for collected packages: atari-py\n",
      "  Building wheel for atari-py (setup.py): started\n",
      "  Building wheel for atari-py (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for atari-py\n",
      "Failed to build atari-py\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git 'C:\\Users\\Windows\\AppData\\Local\\Temp\\pip-req-build-66qnqxf4'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [75 lines of output]\n",
      "      c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'tests_require'\n",
      "        warnings.warn(msg)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-38\\atari_py\n",
      "      copying atari_py\\ale_python_interface.py -> build\\lib.win-amd64-cpython-38\\atari_py\n",
      "      copying atari_py\\__init__.py -> build\\lib.win-amd64-cpython-38\\atari_py\n",
      "      creating build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\adventure.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\air_raid.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\alien.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\amidar.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\assault.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\asterix.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\asteroids.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\atlantis.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\bank_heist.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\battle_zone.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\beam_rider.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\berzerk.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\bowling.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\boxing.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\breakout.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\carnival.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\centipede.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\chopper_command.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\crazy_climber.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\defender.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\demon_attack.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\double_dunk.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\elevator_action.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\enduro.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\fishing_derby.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\freeway.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\frostbite.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\gopher.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\gravitar.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\hero.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\ice_hockey.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\jamesbond.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\journey_escape.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\kaboom.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\kangaroo.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\krull.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\kung_fu_master.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\montezuma_revenge.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\ms_pacman.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\name_this_game.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\phoenix.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\pitfall.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\pong.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\pooyan.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\private_eye.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\qbert.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\riverraid.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\road_runner.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\robotank.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\seaquest.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\skiing.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\solaris.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\space_invaders.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\star_gunner.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\tennis.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\time_pilot.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\tutankham.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\up_n_down.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\venture.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\video_pinball.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\wizard_of_wor.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\yars_revenge.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      copying atari_py\\atari_roms\\zaxxon.bin -> build\\lib.win-amd64-cpython-38\\atari_py\\atari_roms\n",
      "      running build_ext\n",
      "      building 'ale_c' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for atari-py\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (atari-py)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyglet==1.5.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: future in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyglet==1.5.0) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: h5py==3.1.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from h5py==3.1.0) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow==9.5.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (9.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras-rl2==1.0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from keras-rl2==1.0.5) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->keras-rl2==1.0.5) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.32.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (7.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2==1.0.5) (3.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting Keras==2.2.4\n",
      "  Using cached Keras-2.2.4-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from Keras==2.2.4) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from Keras==2.2.4) (1.10.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from Keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from Keras==2.2.4) (6.0.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from Keras==2.2.4) (3.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from Keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from Keras==2.2.4) (1.1.2)\n",
      "Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "Installing collected packages: Keras\n",
      "  Attempting uninstall: Keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "Successfully installed Keras-2.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.2.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.5.3\n",
      "  Using cached tensorflow-2.5.3-cp38-cp38-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting numpy~=1.19.2 (from tensorflow==2.5.3)\n",
      "  Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting absl-py~=0.10 (from tensorflow==2.5.3)\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.6.3)\n",
      "Collecting flatbuffers~=1.12.0 (from tensorflow==2.5.3)\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (2.13.0)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0 (from tensorflow==2.5.3)\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow==2.5.3) (2.5.0.dev2021032900)\n",
      "Collecting grpcio~=1.34.0 (from tensorflow==2.5.3)\n",
      "  Using cached grpcio-1.34.1-cp38-cp38-win_amd64.whl.metadata (4.0 kB)\n",
      "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboard~=2.5 (from tensorflow==2.5.3)\n",
      "  Using cached tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.40.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard~=2.5->tensorflow==2.5.3)\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (75.1.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard~=2.5->tensorflow==2.5.3)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (7.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.3) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3) (3.3.1)\n",
      "Using cached tensorflow-2.5.3-cp38-cp38-win_amd64.whl (428.2 MB)\n",
      "Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Using cached grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorflow-estimator, flatbuffers, tensorboard-data-server, numpy, grpcio, absl-py, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.13.0\n",
      "    Uninstalling tensorflow-estimator-2.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 25.2.10\n",
      "    Uninstalling flatbuffers-25.2.10:\n",
      "      Successfully uninstalled flatbuffers-25.2.10\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.70.0\n",
      "    Uninstalling grpcio-1.70.0:\n",
      "      Successfully uninstalled grpcio-1.70.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.3.1\n",
      "    Uninstalling absl-py-2.3.1:\n",
      "      Successfully uninstalled absl-py-2.3.1\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.0.0\n",
      "    Uninstalling google-auth-oauthlib-1.0.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.13.0\n",
      "    Uninstalling tensorflow-2.13.0:\n",
      "      Successfully uninstalled tensorflow-2.13.0\n",
      "Successfully installed absl-py-0.15.0 flatbuffers-1.12 google-auth-oauthlib-0.4.6 grpcio-1.34.1 numpy-1.19.5 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.5.3 tensorflow-estimator-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires flatbuffers>=23.1.21, but you have flatbuffers 1.12 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.2.4 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.19.5 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.11.2 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires tensorflow-estimator<2.14,>=2.13.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from torch==2.0.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from torch==2.0.1) (3.7.4.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from torch==2.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: agents==1.4.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from agents==1.4.0) (2.5.3)\n",
      "Requirement already satisfied: gym in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from agents==1.4.0) (0.17.3)\n",
      "Requirement already satisfied: ruamel.yaml in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from agents==1.4.0) (0.18.14)\n",
      "Requirement already satisfied: scipy in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym->agents==1.4.0) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym->agents==1.4.0) (1.19.5)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym->agents==1.4.0) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym->agents==1.4.0) (1.6.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from ruamel.yaml->agents==1.4.0) (0.2.8)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.44.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorflow->agents==1.4.0) (1.34.1)\n",
      "Requirement already satisfied: future in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym->agents==1.4.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (75.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from tensorboard~=2.5->tensorflow->agents==1.4.0) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->agents==1.4.0) (7.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->agents==1.4.0) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow->agents==1.4.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->agents==1.4.0) (3.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install tensorflow==2.12\n",
    "else:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install pyglet==1.5.0\n",
    "  %pip install h5py==3.1.0\n",
    "  %pip install Pillow==9.5.0\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install Keras==2.2.4\n",
    "  %pip install tensorflow==2.5.3\n",
    "  %pip install torch==2.0.1\n",
    "  %pip install agents==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c123c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (0.17.3)\n",
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 721.7/721.7 kB 30.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym) (1.6.0)\n",
      "Collecting gym-notices>=0.0.4 (from gym)\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.20.2)\n",
      "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827630 sha256=df5bbc787dc4eba3fb927615bb65cfe5af1b56ff0cf0ed5ca5b3fb08c6788782\n",
      "  Stored in directory: c:\\users\\windows\\appdata\\local\\pip\\cache\\wheels\\17\\79\\65\\7afedc162d858b02708a3b8f7a6dd5b1000dcd5b0f894f7cc1\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.17.3\n",
      "    Uninstalling gym-0.17.3:\n",
      "      Successfully uninstalled gym-0.17.3\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8\n",
      "Requirement already satisfied: gym[atari] in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym[atari]) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym[atari]) (1.6.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym[atari]) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from gym[atari]) (7.0.1)\n",
      "Collecting ale-py~=0.8.0 (from gym[atari])\n",
      "  Downloading ale_py-0.8.1-cp38-cp38-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting importlib-resources (from ale-py~=0.8.0->gym[atari])\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from ale-py~=0.8.0->gym[atari]) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\windows\\anaconda3\\envs\\miar_rl\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[atari]) (3.20.2)\n",
      "Downloading ale_py-0.8.1-cp38-cp38-win_amd64.whl (952 kB)\n",
      "   ---------------------------------------- 0.0/952.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 952.0/952.0 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: importlib-resources, ale-py\n",
      "Successfully installed ale-py-0.8.1 importlib-resources-6.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gym\n",
    "!pip install gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7042d212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando instalación completa...\n",
      "✓ TensorFlow: 2.5.3\n",
      "  - Test tensor: OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Keras: 2.2.4\n",
      "  - Keras components: OK\n",
      "\n",
      "Verificando keras-rl2 paso a paso...\n",
      "✓ Módulo rl importado\n",
      "✓ rl.core importado\n",
      "✓ rl.memory importado\n",
      "✓ rl.policy importado\n",
      "✓ rl.agents.dqn importado\n",
      "✓ Objetos básicos creados\n",
      "✓ keras-rl2: TOTALMENTE FUNCIONAL\n",
      "✓ Gym: 0.26.2\n",
      "✓ NumPy: 1.19.5\n",
      "✓ Pillow: OK\n",
      "✓ h5py: 3.1.0\n",
      "\n",
      "============================================================\n",
      "INSTALACIÓN COMPLETAMENTE VERIFICADA - LISTA PARA USAR\n",
      "============================================================\n",
      "Python: 3.8.20\n"
     ]
    }
   ],
   "source": [
    "def verificar_instalacion_completa():\n",
    "    \"\"\"Verificación completa de todas las dependencias\"\"\"\n",
    "    print(\"Verificando instalación completa...\")\n",
    "    \n",
    "    # Verificar TensorFlow\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        print(f\"✓ TensorFlow: {tf.__version__}\")\n",
    "        \n",
    "        # Verificar que TensorFlow funcione\n",
    "        test_tensor = tf.constant([1, 2, 3])\n",
    "        print(f\"  - Test tensor: OK\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ TensorFlow: Error - {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Verificar Keras\n",
    "    try:\n",
    "        import keras\n",
    "        print(f\"✓ Keras: {keras.__version__}\")\n",
    "        \n",
    "        # Verificar componentes específicos que usa keras-rl2\n",
    "        from tensorflow.keras.models import Sequential, Model\n",
    "        from tensorflow.keras.layers import Dense, Input\n",
    "        print(f\"  - Keras components: OK\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Keras: Error - {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Verificar keras-rl2 paso a paso\n",
    "    print(\"\\nVerificando keras-rl2 paso a paso...\")\n",
    "    \n",
    "    try:\n",
    "        # Test 1: Importar módulo principal\n",
    "        import rl\n",
    "        print(\"✓ Módulo rl importado\")\n",
    "        \n",
    "        # Test 2: Importar core\n",
    "        from rl.core import Agent\n",
    "        print(\"✓ rl.core importado\")\n",
    "        \n",
    "        # Test 3: Importar memory\n",
    "        from rl.memory import SequentialMemory\n",
    "        print(\"✓ rl.memory importado\")\n",
    "        \n",
    "        # Test 4: Importar policy\n",
    "        from rl.policy import EpsGreedyQPolicy\n",
    "        print(\"✓ rl.policy importado\")\n",
    "        \n",
    "        # Test 5: Importar agents\n",
    "        from rl.agents.dqn import DQNAgent\n",
    "        print(\"✓ rl.agents.dqn importado\")\n",
    "        \n",
    "        # Test 6: Crear objetos básicos\n",
    "        memory = SequentialMemory(limit=1000, window_length=1)\n",
    "        policy = EpsGreedyQPolicy()\n",
    "        print(\"✓ Objetos básicos creados\")\n",
    "        \n",
    "        print(\"✓ keras-rl2: TOTALMENTE FUNCIONAL\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"✗ keras-rl2: ImportError - {e}\")\n",
    "        print(\"\\nDiagnóstico detallado:\")\n",
    "        \n",
    "        # Diagnóstico específico\n",
    "        if \"model_from_config\" in str(e):\n",
    "            print(\"- Problema: model_from_config no encontrado\")\n",
    "            print(\"- Solución: Aplicar parche o usar TensorFlow 2.6.x\")\n",
    "        elif \"callbacks\" in str(e):\n",
    "            print(\"- Problema: Callbacks incompatibles\")\n",
    "            print(\"- Solución: Verificar versión de protobuf\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"✗ keras-rl2: Error general - {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Verificar otras dependencias\n",
    "    try:\n",
    "        import gym\n",
    "        print(f\"✓ Gym: {gym.__version__}\")\n",
    "        \n",
    "        import numpy as np\n",
    "        print(f\"✓ NumPy: {np.__version__}\")\n",
    "        \n",
    "        from PIL import Image\n",
    "        print(\"✓ Pillow: OK\")\n",
    "        \n",
    "        import h5py\n",
    "        print(f\"✓ h5py: {h5py.__version__}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Otras dependencias: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INSTALACIÓN COMPLETAMENTE VERIFICADA - LISTA PARA USAR\")\n",
    "    print(\"=\"*60)\n",
    "    return True\n",
    "\n",
    "# Ejecutar verificación completa\n",
    "verificar_instalacion_completa()\n",
    "# Mostrar versión de Python\n",
    "import sys; print(f\"Python: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288dd0f3",
   "metadata": {},
   "source": [
    "---\n",
    "## **PARTE 2**. Enunciado\n",
    "\n",
    "Consideraciones a tener en cuenta:\n",
    "\n",
    "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
    "\n",
    "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
    "\n",
    "Este proyecto práctico consta de tres partes:\n",
    "\n",
    "1.   Implementar la red neuronal que se usará en la solución\n",
    "2.   Implementar las distintas piezas de la solución DQN\n",
    "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
    "\n",
    "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
    "\n",
    "IMPORTANTE:\n",
    "\n",
    "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
    "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
    "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
    "* Cada alumno deberá de subir la solución de forma individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d6db6",
   "metadata": {},
   "source": [
    "---\n",
    "## **PARTE 3**. Desarrollo y preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1dfce",
   "metadata": {},
   "source": [
    "#### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686af9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment SpaceInvaders-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 250000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    404/250000: episode: 1, duration: 2.672s, episode steps: 404, steps per second: 151, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   1043/250000: episode: 2, duration: 4.163s, episode steps: 639, steps per second: 153, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   1636/250000: episode: 3, duration: 3.354s, episode steps: 593, steps per second: 177, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   2158/250000: episode: 4, duration: 3.449s, episode steps: 522, steps per second: 151, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   2655/250000: episode: 5, duration: 3.109s, episode steps: 497, steps per second: 160, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   3034/250000: episode: 6, duration: 2.154s, episode steps: 379, steps per second: 176, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   3582/250000: episode: 7, duration: 3.187s, episode steps: 548, steps per second: 172, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   3981/250000: episode: 8, duration: 2.262s, episode steps: 399, steps per second: 176, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   4795/250000: episode: 9, duration: 4.773s, episode steps: 814, steps per second: 171, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   5554/250000: episode: 10, duration: 4.571s, episode steps: 759, steps per second: 166, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   6704/250000: episode: 11, duration: 7.729s, episode steps: 1150, steps per second: 149, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   7240/250000: episode: 12, duration: 3.255s, episode steps: 536, steps per second: 165, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   7689/250000: episode: 13, duration: 2.713s, episode steps: 449, steps per second: 165, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   8310/250000: episode: 14, duration: 3.537s, episode steps: 621, steps per second: 176, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   8918/250000: episode: 15, duration: 4.491s, episode steps: 608, steps per second: 135, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "   9445/250000: episode: 16, duration: 3.031s, episode steps: 527, steps per second: 174, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  10151/250000: episode: 17, duration: 4.014s, episode steps: 706, steps per second: 176, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  10637/250000: episode: 18, duration: 2.737s, episode steps: 486, steps per second: 178, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  11929/250000: episode: 19, duration: 8.208s, episode steps: 1292, steps per second: 157, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  12438/250000: episode: 20, duration: 3.515s, episode steps: 509, steps per second: 145, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  13275/250000: episode: 21, duration: 5.162s, episode steps: 837, steps per second: 162, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  14065/250000: episode: 22, duration: 4.709s, episode steps: 790, steps per second: 168, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  15036/250000: episode: 23, duration: 5.818s, episode steps: 971, steps per second: 167, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  15769/250000: episode: 24, duration: 4.364s, episode steps: 733, steps per second: 168, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  16165/250000: episode: 25, duration: 2.390s, episode steps: 396, steps per second: 166, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  17132/250000: episode: 26, duration: 6.030s, episode steps: 967, steps per second: 160, episode reward:  7.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  17688/250000: episode: 27, duration: 3.884s, episode steps: 556, steps per second: 143, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  18676/250000: episode: 28, duration: 5.672s, episode steps: 988, steps per second: 174, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  19807/250000: episode: 29, duration: 6.437s, episode steps: 1131, steps per second: 176, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  20567/250000: episode: 30, duration: 4.219s, episode steps: 760, steps per second: 180, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  21061/250000: episode: 31, duration: 2.773s, episode steps: 494, steps per second: 178, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  21751/250000: episode: 32, duration: 3.956s, episode steps: 690, steps per second: 174, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  22174/250000: episode: 33, duration: 2.864s, episode steps: 423, steps per second: 148, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  23159/250000: episode: 34, duration: 6.377s, episode steps: 985, steps per second: 154, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  23625/250000: episode: 35, duration: 3.085s, episode steps: 466, steps per second: 151, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  24766/250000: episode: 36, duration: 6.512s, episode steps: 1141, steps per second: 175, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  25748/250000: episode: 37, duration: 5.637s, episode steps: 982, steps per second: 174, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  26323/250000: episode: 38, duration: 3.384s, episode steps: 575, steps per second: 170, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  26753/250000: episode: 39, duration: 2.556s, episode steps: 430, steps per second: 168, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  28049/250000: episode: 40, duration: 7.701s, episode steps: 1296, steps per second: 168, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  28991/250000: episode: 41, duration: 6.840s, episode steps: 942, steps per second: 138, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  29391/250000: episode: 42, duration: 2.363s, episode steps: 400, steps per second: 169, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  29955/250000: episode: 43, duration: 3.486s, episode steps: 564, steps per second: 162, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  30800/250000: episode: 44, duration: 5.092s, episode steps: 845, steps per second: 166, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  31300/250000: episode: 45, duration: 2.852s, episode steps: 500, steps per second: 175, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  32575/250000: episode: 46, duration: 7.971s, episode steps: 1275, steps per second: 160, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  33391/250000: episode: 47, duration: 4.979s, episode steps: 816, steps per second: 164, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  34398/250000: episode: 48, duration: 6.843s, episode steps: 1007, steps per second: 147, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  34997/250000: episode: 49, duration: 3.707s, episode steps: 599, steps per second: 162, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  35491/250000: episode: 50, duration: 2.984s, episode steps: 494, steps per second: 166, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  36005/250000: episode: 51, duration: 2.986s, episode steps: 514, steps per second: 172, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  36806/250000: episode: 52, duration: 4.739s, episode steps: 801, steps per second: 169, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  37333/250000: episode: 53, duration: 3.147s, episode steps: 527, steps per second: 167, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  37787/250000: episode: 54, duration: 2.672s, episode steps: 454, steps per second: 170, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  38483/250000: episode: 55, duration: 3.943s, episode steps: 696, steps per second: 177, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  39335/250000: episode: 56, duration: 4.915s, episode steps: 852, steps per second: 173, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  40294/250000: episode: 57, duration: 6.222s, episode steps: 959, steps per second: 154, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  41219/250000: episode: 58, duration: 5.625s, episode steps: 925, steps per second: 164, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  41769/250000: episode: 59, duration: 3.850s, episode steps: 550, steps per second: 143, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  42661/250000: episode: 60, duration: 5.154s, episode steps: 892, steps per second: 173, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  43460/250000: episode: 61, duration: 4.816s, episode steps: 799, steps per second: 166, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  44228/250000: episode: 62, duration: 4.565s, episode steps: 768, steps per second: 168, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  44909/250000: episode: 63, duration: 4.118s, episode steps: 681, steps per second: 165, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  45254/250000: episode: 64, duration: 2.872s, episode steps: 345, steps per second: 120, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  45895/250000: episode: 65, duration: 4.628s, episode steps: 641, steps per second: 139, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  46765/250000: episode: 66, duration: 6.066s, episode steps: 870, steps per second: 143, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  47686/250000: episode: 67, duration: 5.887s, episode steps: 921, steps per second: 156, episode reward:  8.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  48500/250000: episode: 68, duration: 4.786s, episode steps: 814, steps per second: 170, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  49413/250000: episode: 69, duration: 5.186s, episode steps: 913, steps per second: 176, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
      "  49861/250000: episode: 70, duration: 2.833s, episode steps: 448, steps per second: 158, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50520/250000: episode: 71, duration: 28.752s, episode steps: 659, steps per second:  23, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.009363, mae: 0.039732, mean_q: 0.064435, mean_eps: 0.954766\n",
      "  51088/250000: episode: 72, duration: 30.131s, episode steps: 568, steps per second:  19, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.008832, mae: 0.040068, mean_q: 0.056424, mean_eps: 0.954278\n",
      "  51584/250000: episode: 73, duration: 25.874s, episode steps: 496, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.005526, mae: 0.033534, mean_q: 0.046015, mean_eps: 0.953799\n",
      "  52710/250000: episode: 74, duration: 55.968s, episode steps: 1126, steps per second:  20, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007083, mae: 0.036698, mean_q: 0.051057, mean_eps: 0.953069\n",
      "  53372/250000: episode: 75, duration: 33.713s, episode steps: 662, steps per second:  20, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.006109, mae: 0.035482, mean_q: 0.048499, mean_eps: 0.952264\n",
      "  53902/250000: episode: 76, duration: 26.414s, episode steps: 530, steps per second:  20, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.005334, mae: 0.034325, mean_q: 0.047049, mean_eps: 0.951728\n",
      "  54521/250000: episode: 77, duration: 29.191s, episode steps: 619, steps per second:  21, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.008219, mae: 0.039467, mean_q: 0.055433, mean_eps: 0.951209\n",
      "  55361/250000: episode: 78, duration: 39.965s, episode steps: 840, steps per second:  21, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.005912, mae: 0.035905, mean_q: 0.050792, mean_eps: 0.950552\n",
      "  56023/250000: episode: 79, duration: 31.474s, episode steps: 662, steps per second:  21, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006548, mae: 0.036159, mean_q: 0.051051, mean_eps: 0.949877\n",
      "  57438/250000: episode: 80, duration: 64.489s, episode steps: 1415, steps per second:  22, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007050, mae: 0.037648, mean_q: 0.050733, mean_eps: 0.948943\n",
      "  58343/250000: episode: 81, duration: 41.708s, episode steps: 905, steps per second:  22, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006818, mae: 0.037077, mean_q: 0.050118, mean_eps: 0.947899\n",
      "  58725/250000: episode: 82, duration: 17.797s, episode steps: 382, steps per second:  21, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.006589, mae: 0.037549, mean_q: 0.049492, mean_eps: 0.947319\n",
      "  59331/250000: episode: 83, duration: 27.513s, episode steps: 606, steps per second:  22, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.006239, mae: 0.035832, mean_q: 0.047138, mean_eps: 0.946875\n",
      "  60217/250000: episode: 84, duration: 41.076s, episode steps: 886, steps per second:  22, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.006663, mae: 0.039700, mean_q: 0.052677, mean_eps: 0.946203\n",
      "  61494/250000: episode: 85, duration: 57.462s, episode steps: 1277, steps per second:  22, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.006057, mae: 0.050444, mean_q: 0.064093, mean_eps: 0.945230\n",
      "  62113/250000: episode: 86, duration: 30.538s, episode steps: 619, steps per second:  20, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.007063, mae: 0.052964, mean_q: 0.069435, mean_eps: 0.944376\n",
      "  62690/250000: episode: 87, duration: 26.901s, episode steps: 577, steps per second:  21, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.007040, mae: 0.053084, mean_q: 0.067073, mean_eps: 0.943838\n",
      "  63486/250000: episode: 88, duration: 38.117s, episode steps: 796, steps per second:  21, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.007708, mae: 0.055526, mean_q: 0.073866, mean_eps: 0.943221\n",
      "  64172/250000: episode: 89, duration: 33.256s, episode steps: 686, steps per second:  21, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.008667, mae: 0.056701, mean_q: 0.074028, mean_eps: 0.942555\n",
      "  65069/250000: episode: 90, duration: 42.789s, episode steps: 897, steps per second:  21, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.005903, mae: 0.051425, mean_q: 0.066317, mean_eps: 0.941842\n",
      "  65589/250000: episode: 91, duration: 24.613s, episode steps: 520, steps per second:  21, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.006371, mae: 0.051462, mean_q: 0.068994, mean_eps: 0.941203\n",
      "  66417/250000: episode: 92, duration: 40.285s, episode steps: 828, steps per second:  21, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006166, mae: 0.052286, mean_q: 0.069284, mean_eps: 0.940596\n",
      "  66965/250000: episode: 93, duration: 24.098s, episode steps: 548, steps per second:  23, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.007997, mae: 0.054970, mean_q: 0.071906, mean_eps: 0.939977\n",
      "  67576/250000: episode: 94, duration: 27.704s, episode steps: 611, steps per second:  22, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.006653, mae: 0.053626, mean_q: 0.070522, mean_eps: 0.939457\n",
      "  68150/250000: episode: 95, duration: 25.721s, episode steps: 574, steps per second:  22, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.005871, mae: 0.050242, mean_q: 0.067948, mean_eps: 0.938924\n",
      "  68574/250000: episode: 96, duration: 18.754s, episode steps: 424, steps per second:  23, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.005668, mae: 0.050598, mean_q: 0.067161, mean_eps: 0.938474\n",
      "  69407/250000: episode: 97, duration: 37.679s, episode steps: 833, steps per second:  22, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.700 [0.000, 5.000],  loss: 0.007124, mae: 0.053573, mean_q: 0.072405, mean_eps: 0.937909\n",
      "  70197/250000: episode: 98, duration: 34.946s, episode steps: 790, steps per second:  23, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005669, mae: 0.055004, mean_q: 0.074166, mean_eps: 0.937178\n",
      "  70845/250000: episode: 99, duration: 29.611s, episode steps: 648, steps per second:  22, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007552, mae: 0.074755, mean_q: 0.094927, mean_eps: 0.936530\n",
      "  71507/250000: episode: 100, duration: 30.429s, episode steps: 662, steps per second:  22, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.007368, mae: 0.075106, mean_q: 0.096736, mean_eps: 0.935942\n",
      "  71895/250000: episode: 101, duration: 20.211s, episode steps: 388, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.005876, mae: 0.072779, mean_q: 0.094941, mean_eps: 0.935470\n",
      "  72474/250000: episode: 102, duration: 28.423s, episode steps: 579, steps per second:  20, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.005969, mae: 0.072835, mean_q: 0.095397, mean_eps: 0.935034\n",
      "  73086/250000: episode: 103, duration: 29.880s, episode steps: 612, steps per second:  20, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006214, mae: 0.073164, mean_q: 0.094594, mean_eps: 0.934498\n",
      "  74215/250000: episode: 104, duration: 56.976s, episode steps: 1129, steps per second:  20, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.005767, mae: 0.071904, mean_q: 0.092702, mean_eps: 0.933715\n",
      "  74615/250000: episode: 105, duration: 19.220s, episode steps: 400, steps per second:  21, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.005415, mae: 0.072109, mean_q: 0.092972, mean_eps: 0.933027\n",
      "  75305/250000: episode: 106, duration: 31.624s, episode steps: 690, steps per second:  22, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007516, mae: 0.076737, mean_q: 0.098798, mean_eps: 0.932536\n",
      "  75977/250000: episode: 107, duration: 30.777s, episode steps: 672, steps per second:  22, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007172, mae: 0.074645, mean_q: 0.095744, mean_eps: 0.931922\n",
      "  77006/250000: episode: 108, duration: 48.841s, episode steps: 1029, steps per second:  21, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006408, mae: 0.074120, mean_q: 0.095085, mean_eps: 0.931157\n",
      "  78081/250000: episode: 109, duration: 49.248s, episode steps: 1075, steps per second:  22, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.007132, mae: 0.075199, mean_q: 0.094117, mean_eps: 0.930210\n",
      "  78907/250000: episode: 110, duration: 36.820s, episode steps: 826, steps per second:  22, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.006378, mae: 0.074020, mean_q: 0.095132, mean_eps: 0.929355\n",
      "  79411/250000: episode: 111, duration: 23.862s, episode steps: 504, steps per second:  21, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.007633, mae: 0.076372, mean_q: 0.095815, mean_eps: 0.928758\n",
      "  80105/250000: episode: 112, duration: 30.958s, episode steps: 694, steps per second:  22, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.005661, mae: 0.073205, mean_q: 0.095686, mean_eps: 0.928218\n",
      "  80788/250000: episode: 113, duration: 30.693s, episode steps: 683, steps per second:  22, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007952, mae: 0.090630, mean_q: 0.115674, mean_eps: 0.927599\n",
      "  81339/250000: episode: 114, duration: 24.463s, episode steps: 551, steps per second:  23, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006944, mae: 0.087858, mean_q: 0.111550, mean_eps: 0.927044\n",
      "  82030/250000: episode: 115, duration: 30.885s, episode steps: 691, steps per second:  22, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.007255, mae: 0.090606, mean_q: 0.117623, mean_eps: 0.926484\n",
      "  82946/250000: episode: 116, duration: 43.152s, episode steps: 916, steps per second:  21, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.007344, mae: 0.088506, mean_q: 0.111855, mean_eps: 0.925761\n",
      "  83412/250000: episode: 117, duration: 21.513s, episode steps: 466, steps per second:  22, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.005910, mae: 0.087626, mean_q: 0.113418, mean_eps: 0.925140\n",
      "  83794/250000: episode: 118, duration: 18.571s, episode steps: 382, steps per second:  21, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.005316, mae: 0.083806, mean_q: 0.106913, mean_eps: 0.924758\n",
      "  84793/250000: episode: 119, duration: 47.812s, episode steps: 999, steps per second:  21, episode reward:  7.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.007439, mae: 0.089542, mean_q: 0.113633, mean_eps: 0.924135\n",
      "  85564/250000: episode: 120, duration: 37.195s, episode steps: 771, steps per second:  21, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.007433, mae: 0.090138, mean_q: 0.113750, mean_eps: 0.923340\n",
      "  86570/250000: episode: 121, duration: 45.496s, episode steps: 1006, steps per second:  22, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006723, mae: 0.088002, mean_q: 0.111581, mean_eps: 0.922541\n",
      "  87071/250000: episode: 122, duration: 21.189s, episode steps: 501, steps per second:  24, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.007317, mae: 0.089933, mean_q: 0.115498, mean_eps: 0.921862\n",
      "  87576/250000: episode: 123, duration: 22.077s, episode steps: 505, steps per second:  23, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.006324, mae: 0.087244, mean_q: 0.114572, mean_eps: 0.921410\n",
      "  88344/250000: episode: 124, duration: 33.947s, episode steps: 768, steps per second:  23, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.007334, mae: 0.089482, mean_q: 0.116453, mean_eps: 0.920838\n",
      "  89254/250000: episode: 125, duration: 40.335s, episode steps: 910, steps per second:  23, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006803, mae: 0.087613, mean_q: 0.112858, mean_eps: 0.920082\n",
      "  90422/250000: episode: 126, duration: 50.824s, episode steps: 1168, steps per second:  23, episode reward: 29.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.007164, mae: 0.097154, mean_q: 0.126878, mean_eps: 0.919146\n",
      "  91601/250000: episode: 127, duration: 55.238s, episode steps: 1179, steps per second:  21, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.006557, mae: 0.110904, mean_q: 0.143197, mean_eps: 0.918089\n",
      "  92259/250000: episode: 128, duration: 30.280s, episode steps: 658, steps per second:  22, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006995, mae: 0.112011, mean_q: 0.144030, mean_eps: 0.917263\n",
      "  92775/250000: episode: 129, duration: 23.501s, episode steps: 516, steps per second:  22, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.007066, mae: 0.114432, mean_q: 0.145858, mean_eps: 0.916736\n",
      "  93965/250000: episode: 130, duration: 54.852s, episode steps: 1190, steps per second:  22, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.007290, mae: 0.113479, mean_q: 0.145423, mean_eps: 0.915967\n",
      "  94581/250000: episode: 131, duration: 28.467s, episode steps: 616, steps per second:  22, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007046, mae: 0.111898, mean_q: 0.142420, mean_eps: 0.915153\n",
      "  95172/250000: episode: 132, duration: 26.336s, episode steps: 591, steps per second:  22, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.007174, mae: 0.113645, mean_q: 0.144386, mean_eps: 0.914612\n",
      "  95572/250000: episode: 133, duration: 18.605s, episode steps: 400, steps per second:  21, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.008002, mae: 0.117339, mean_q: 0.147801, mean_eps: 0.914167\n",
      "  96053/250000: episode: 134, duration: 22.561s, episode steps: 481, steps per second:  21, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.006644, mae: 0.111530, mean_q: 0.144841, mean_eps: 0.913769\n",
      "  96580/250000: episode: 135, duration: 23.483s, episode steps: 527, steps per second:  22, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.006210, mae: 0.112769, mean_q: 0.144425, mean_eps: 0.913316\n",
      "  97414/250000: episode: 136, duration: 37.974s, episode steps: 834, steps per second:  22, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.005901, mae: 0.110776, mean_q: 0.143197, mean_eps: 0.912704\n",
      "  97798/250000: episode: 137, duration: 18.796s, episode steps: 384, steps per second:  20, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006829, mae: 0.113719, mean_q: 0.145497, mean_eps: 0.912155\n",
      "  98463/250000: episode: 138, duration: 30.489s, episode steps: 665, steps per second:  22, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006937, mae: 0.112989, mean_q: 0.144802, mean_eps: 0.911683\n",
      "  99397/250000: episode: 139, duration: 42.242s, episode steps: 934, steps per second:  22, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.006412, mae: 0.112223, mean_q: 0.142830, mean_eps: 0.910963\n",
      "  99740/250000: episode: 140, duration: 15.461s, episode steps: 343, steps per second:  22, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.007034, mae: 0.113373, mean_q: 0.144966, mean_eps: 0.910389\n",
      " 100503/250000: episode: 141, duration: 33.705s, episode steps: 763, steps per second:  23, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006151, mae: 0.120009, mean_q: 0.153375, mean_eps: 0.909892\n",
      " 100894/250000: episode: 142, duration: 17.288s, episode steps: 391, steps per second:  23, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.005285, mae: 0.125839, mean_q: 0.163052, mean_eps: 0.909372\n",
      " 101546/250000: episode: 143, duration: 28.575s, episode steps: 652, steps per second:  23, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.007705, mae: 0.129794, mean_q: 0.166070, mean_eps: 0.908902\n",
      " 102073/250000: episode: 144, duration: 23.463s, episode steps: 527, steps per second:  22, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.007724, mae: 0.129954, mean_q: 0.167537, mean_eps: 0.908371\n",
      " 102788/250000: episode: 145, duration: 32.719s, episode steps: 715, steps per second:  22, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006734, mae: 0.129005, mean_q: 0.164880, mean_eps: 0.907813\n",
      " 103378/250000: episode: 146, duration: 28.242s, episode steps: 590, steps per second:  21, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.006728, mae: 0.129143, mean_q: 0.165215, mean_eps: 0.907226\n",
      " 104158/250000: episode: 147, duration: 36.026s, episode steps: 780, steps per second:  22, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.006520, mae: 0.129107, mean_q: 0.164940, mean_eps: 0.906609\n",
      " 105585/250000: episode: 148, duration: 68.654s, episode steps: 1427, steps per second:  21, episode reward: 24.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006739, mae: 0.128030, mean_q: 0.163434, mean_eps: 0.905615\n",
      " 105957/250000: episode: 149, duration: 16.494s, episode steps: 372, steps per second:  23, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007815, mae: 0.130208, mean_q: 0.166815, mean_eps: 0.904805\n",
      " 106573/250000: episode: 150, duration: 28.317s, episode steps: 616, steps per second:  22, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.006276, mae: 0.126101, mean_q: 0.161618, mean_eps: 0.904361\n",
      " 107776/250000: episode: 151, duration: 54.792s, episode steps: 1203, steps per second:  22, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.006081, mae: 0.127572, mean_q: 0.161579, mean_eps: 0.903543\n",
      " 108481/250000: episode: 152, duration: 31.736s, episode steps: 705, steps per second:  22, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.005748, mae: 0.124633, mean_q: 0.159386, mean_eps: 0.902685\n",
      " 109265/250000: episode: 153, duration: 36.856s, episode steps: 784, steps per second:  21, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.005336, mae: 0.125376, mean_q: 0.160406, mean_eps: 0.902013\n",
      " 110044/250000: episode: 154, duration: 38.536s, episode steps: 779, steps per second:  20, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.005722, mae: 0.125817, mean_q: 0.161002, mean_eps: 0.901311\n",
      " 110622/250000: episode: 155, duration: 29.017s, episode steps: 578, steps per second:  20, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.006828, mae: 0.153311, mean_q: 0.194432, mean_eps: 0.900701\n",
      " 111341/250000: episode: 156, duration: 39.167s, episode steps: 719, steps per second:  18, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.007010, mae: 0.154902, mean_q: 0.197612, mean_eps: 0.900116\n",
      " 112259/250000: episode: 157, duration: 44.124s, episode steps: 918, steps per second:  21, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.006630, mae: 0.152730, mean_q: 0.196012, mean_eps: 0.899380\n",
      " 112682/250000: episode: 158, duration: 23.431s, episode steps: 423, steps per second:  18, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.004973, mae: 0.154200, mean_q: 0.197040, mean_eps: 0.898777\n",
      " 113627/250000: episode: 159, duration: 44.543s, episode steps: 945, steps per second:  21, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007032, mae: 0.155429, mean_q: 0.196536, mean_eps: 0.898161\n",
      " 114129/250000: episode: 160, duration: 22.310s, episode steps: 502, steps per second:  23, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.006446, mae: 0.152229, mean_q: 0.192378, mean_eps: 0.897510\n",
      " 114888/250000: episode: 161, duration: 34.668s, episode steps: 759, steps per second:  22, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.006567, mae: 0.153753, mean_q: 0.194269, mean_eps: 0.896943\n",
      " 116358/250000: episode: 162, duration: 72.657s, episode steps: 1470, steps per second:  20, episode reward: 29.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.005915, mae: 0.151744, mean_q: 0.191723, mean_eps: 0.895940\n",
      " 117386/250000: episode: 163, duration: 48.018s, episode steps: 1028, steps per second:  21, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.006706, mae: 0.155406, mean_q: 0.197191, mean_eps: 0.894815\n",
      " 117754/250000: episode: 164, duration: 18.521s, episode steps: 368, steps per second:  20, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.004484, mae: 0.146997, mean_q: 0.185901, mean_eps: 0.894187\n",
      " 118387/250000: episode: 165, duration: 29.684s, episode steps: 633, steps per second:  21, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.006992, mae: 0.155176, mean_q: 0.196248, mean_eps: 0.893737\n",
      " 119062/250000: episode: 166, duration: 32.226s, episode steps: 675, steps per second:  21, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.006324, mae: 0.154270, mean_q: 0.194088, mean_eps: 0.893148\n",
      " 119712/250000: episode: 167, duration: 29.914s, episode steps: 650, steps per second:  22, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.006069, mae: 0.153780, mean_q: 0.192716, mean_eps: 0.892553\n",
      " 120203/250000: episode: 168, duration: 23.624s, episode steps: 491, steps per second:  21, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.007269, mae: 0.166305, mean_q: 0.210579, mean_eps: 0.892040\n",
      " 120711/250000: episode: 169, duration: 23.571s, episode steps: 508, steps per second:  22, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006327, mae: 0.176210, mean_q: 0.221468, mean_eps: 0.891590\n",
      " 121456/250000: episode: 170, duration: 35.888s, episode steps: 745, steps per second:  21, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.006664, mae: 0.179823, mean_q: 0.227273, mean_eps: 0.891026\n",
      " 121966/250000: episode: 171, duration: 26.012s, episode steps: 510, steps per second:  20, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.006779, mae: 0.184640, mean_q: 0.231963, mean_eps: 0.890461\n",
      " 122545/250000: episode: 172, duration: 28.720s, episode steps: 579, steps per second:  20, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.006720, mae: 0.183822, mean_q: 0.232247, mean_eps: 0.889970\n",
      " 123227/250000: episode: 173, duration: 36.075s, episode steps: 682, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.007134, mae: 0.187377, mean_q: 0.233770, mean_eps: 0.889403\n",
      " 124560/250000: episode: 174, duration: 66.652s, episode steps: 1333, steps per second:  20, episode reward: 20.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.007156, mae: 0.183926, mean_q: 0.232018, mean_eps: 0.888497\n",
      " 125491/250000: episode: 175, duration: 42.558s, episode steps: 931, steps per second:  22, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006880, mae: 0.184604, mean_q: 0.231475, mean_eps: 0.887478\n",
      " 126248/250000: episode: 176, duration: 36.833s, episode steps: 757, steps per second:  21, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006788, mae: 0.183249, mean_q: 0.230604, mean_eps: 0.886719\n",
      " 127355/250000: episode: 177, duration: 51.941s, episode steps: 1107, steps per second:  21, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.007316, mae: 0.186432, mean_q: 0.233917, mean_eps: 0.885880\n",
      " 127978/250000: episode: 178, duration: 29.156s, episode steps: 623, steps per second:  21, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.006293, mae: 0.183282, mean_q: 0.231450, mean_eps: 0.885101\n",
      " 128816/250000: episode: 179, duration: 41.945s, episode steps: 838, steps per second:  20, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.006267, mae: 0.182572, mean_q: 0.229936, mean_eps: 0.884444\n",
      " 129924/250000: episode: 180, duration: 51.235s, episode steps: 1108, steps per second:  22, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.006321, mae: 0.182792, mean_q: 0.232009, mean_eps: 0.883569\n",
      " 130573/250000: episode: 181, duration: 31.236s, episode steps: 649, steps per second:  21, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.007091, mae: 0.203943, mean_q: 0.256789, mean_eps: 0.882777\n",
      " 131130/250000: episode: 182, duration: 27.243s, episode steps: 557, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.007384, mae: 0.211606, mean_q: 0.267427, mean_eps: 0.882233\n",
      " 131744/250000: episode: 183, duration: 29.627s, episode steps: 614, steps per second:  21, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.005874, mae: 0.207636, mean_q: 0.260636, mean_eps: 0.881708\n",
      " 132376/250000: episode: 184, duration: 29.212s, episode steps: 632, steps per second:  22, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.006799, mae: 0.210228, mean_q: 0.264353, mean_eps: 0.881148\n",
      " 133057/250000: episode: 185, duration: 32.688s, episode steps: 681, steps per second:  21, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.007533, mae: 0.211775, mean_q: 0.267376, mean_eps: 0.880556\n",
      " 133874/250000: episode: 186, duration: 38.855s, episode steps: 817, steps per second:  21, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.007253, mae: 0.208829, mean_q: 0.263469, mean_eps: 0.879881\n",
      " 134559/250000: episode: 187, duration: 34.176s, episode steps: 685, steps per second:  20, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006037, mae: 0.210377, mean_q: 0.264822, mean_eps: 0.879206\n",
      " 135318/250000: episode: 188, duration: 35.311s, episode steps: 759, steps per second:  21, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.007455, mae: 0.210959, mean_q: 0.266505, mean_eps: 0.878556\n",
      " 135959/250000: episode: 189, duration: 30.726s, episode steps: 641, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.006367, mae: 0.206041, mean_q: 0.258787, mean_eps: 0.877926\n",
      " 136356/250000: episode: 190, duration: 23.501s, episode steps: 397, steps per second:  17, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.006328, mae: 0.208223, mean_q: 0.262481, mean_eps: 0.877460\n",
      " 136809/250000: episode: 191, duration: 25.246s, episode steps: 453, steps per second:  18, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.006011, mae: 0.210592, mean_q: 0.265568, mean_eps: 0.877076\n",
      " 137198/250000: episode: 192, duration: 18.735s, episode steps: 389, steps per second:  21, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.006730, mae: 0.211425, mean_q: 0.263794, mean_eps: 0.876696\n",
      " 137825/250000: episode: 193, duration: 30.144s, episode steps: 627, steps per second:  21, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.007614, mae: 0.216289, mean_q: 0.270813, mean_eps: 0.876239\n",
      " 138341/250000: episode: 194, duration: 23.863s, episode steps: 516, steps per second:  22, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006481, mae: 0.207462, mean_q: 0.259968, mean_eps: 0.875724\n",
      " 139016/250000: episode: 195, duration: 34.023s, episode steps: 675, steps per second:  20, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.007468, mae: 0.214091, mean_q: 0.268691, mean_eps: 0.875190\n",
      " 139511/250000: episode: 196, duration: 24.254s, episode steps: 495, steps per second:  20, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.005886, mae: 0.209252, mean_q: 0.262361, mean_eps: 0.874664\n",
      " 140214/250000: episode: 197, duration: 35.613s, episode steps: 703, steps per second:  20, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.007305, mae: 0.220890, mean_q: 0.276805, mean_eps: 0.874124\n",
      " 140835/250000: episode: 198, duration: 30.716s, episode steps: 621, steps per second:  20, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.007178, mae: 0.245013, mean_q: 0.306687, mean_eps: 0.873528\n",
      " 141869/250000: episode: 199, duration: 52.373s, episode steps: 1034, steps per second:  20, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006621, mae: 0.244878, mean_q: 0.307137, mean_eps: 0.872783\n",
      " 142963/250000: episode: 200, duration: 54.335s, episode steps: 1094, steps per second:  20, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006483, mae: 0.244884, mean_q: 0.306723, mean_eps: 0.871826\n",
      " 143545/250000: episode: 201, duration: 29.304s, episode steps: 582, steps per second:  20, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.007459, mae: 0.250438, mean_q: 0.314311, mean_eps: 0.871071\n",
      " 144343/250000: episode: 202, duration: 39.232s, episode steps: 798, steps per second:  20, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.005890, mae: 0.246004, mean_q: 0.306882, mean_eps: 0.870450\n",
      " 144841/250000: episode: 203, duration: 23.842s, episode steps: 498, steps per second:  21, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.009386, mae: 0.257484, mean_q: 0.320312, mean_eps: 0.869867\n",
      " 145563/250000: episode: 204, duration: 34.295s, episode steps: 722, steps per second:  21, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006991, mae: 0.247587, mean_q: 0.310891, mean_eps: 0.869318\n",
      " 146178/250000: episode: 205, duration: 29.627s, episode steps: 615, steps per second:  21, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.006987, mae: 0.249450, mean_q: 0.312288, mean_eps: 0.868717\n",
      " 146954/250000: episode: 206, duration: 38.692s, episode steps: 776, steps per second:  20, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.006836, mae: 0.249141, mean_q: 0.311584, mean_eps: 0.868091\n",
      " 147524/250000: episode: 207, duration: 25.715s, episode steps: 570, steps per second:  22, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.006510, mae: 0.252332, mean_q: 0.313861, mean_eps: 0.867486\n",
      " 148412/250000: episode: 208, duration: 44.518s, episode steps: 888, steps per second:  20, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.006658, mae: 0.246839, mean_q: 0.308670, mean_eps: 0.866831\n",
      " 148783/250000: episode: 209, duration: 16.821s, episode steps: 371, steps per second:  22, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.006475, mae: 0.249381, mean_q: 0.310776, mean_eps: 0.866264\n",
      " 149193/250000: episode: 210, duration: 21.861s, episode steps: 410, steps per second:  19, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006121, mae: 0.244390, mean_q: 0.305252, mean_eps: 0.865911\n",
      " 150229/250000: episode: 211, duration: 60.400s, episode steps: 1036, steps per second:  17, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006072, mae: 0.248342, mean_q: 0.310982, mean_eps: 0.865259\n",
      " 151164/250000: episode: 212, duration: 46.284s, episode steps: 935, steps per second:  20, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006869, mae: 0.268424, mean_q: 0.335707, mean_eps: 0.864374\n",
      " 151709/250000: episode: 213, duration: 27.367s, episode steps: 545, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.681 [0.000, 5.000],  loss: 0.006421, mae: 0.262723, mean_q: 0.326790, mean_eps: 0.863708\n",
      " 152339/250000: episode: 214, duration: 31.245s, episode steps: 630, steps per second:  20, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006641, mae: 0.262641, mean_q: 0.328646, mean_eps: 0.863178\n",
      " 153270/250000: episode: 215, duration: 45.673s, episode steps: 931, steps per second:  20, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006572, mae: 0.266817, mean_q: 0.333623, mean_eps: 0.862476\n",
      " 154384/250000: episode: 216, duration: 53.350s, episode steps: 1114, steps per second:  21, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.007570, mae: 0.269832, mean_q: 0.335827, mean_eps: 0.861557\n",
      " 154894/250000: episode: 217, duration: 25.825s, episode steps: 510, steps per second:  20, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006990, mae: 0.274720, mean_q: 0.344021, mean_eps: 0.860826\n",
      " 155683/250000: episode: 218, duration: 39.092s, episode steps: 789, steps per second:  20, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.007228, mae: 0.265709, mean_q: 0.330944, mean_eps: 0.860241\n",
      " 156240/250000: episode: 219, duration: 26.516s, episode steps: 557, steps per second:  21, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.007190, mae: 0.264747, mean_q: 0.328461, mean_eps: 0.859636\n",
      " 156776/250000: episode: 220, duration: 27.645s, episode steps: 536, steps per second:  19, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.007146, mae: 0.272625, mean_q: 0.338706, mean_eps: 0.859145\n",
      " 157538/250000: episode: 221, duration: 35.416s, episode steps: 762, steps per second:  22, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.007373, mae: 0.267555, mean_q: 0.332922, mean_eps: 0.858560\n",
      " 158314/250000: episode: 222, duration: 37.688s, episode steps: 776, steps per second:  21, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.007624, mae: 0.264079, mean_q: 0.328973, mean_eps: 0.857867\n",
      " 158851/250000: episode: 223, duration: 23.757s, episode steps: 537, steps per second:  23, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.008301, mae: 0.271183, mean_q: 0.337817, mean_eps: 0.857276\n",
      " 159478/250000: episode: 224, duration: 30.407s, episode steps: 627, steps per second:  21, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.007013, mae: 0.262483, mean_q: 0.326082, mean_eps: 0.856752\n",
      " 160215/250000: episode: 225, duration: 33.635s, episode steps: 737, steps per second:  22, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.006729, mae: 0.275789, mean_q: 0.343303, mean_eps: 0.856139\n",
      " 160781/250000: episode: 226, duration: 28.235s, episode steps: 566, steps per second:  20, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.007975, mae: 0.303453, mean_q: 0.381969, mean_eps: 0.855552\n",
      " 161537/250000: episode: 227, duration: 35.610s, episode steps: 756, steps per second:  21, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.007207, mae: 0.293884, mean_q: 0.366871, mean_eps: 0.854956\n",
      " 162202/250000: episode: 228, duration: 31.681s, episode steps: 665, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007962, mae: 0.300910, mean_q: 0.375243, mean_eps: 0.854317\n",
      " 163146/250000: episode: 229, duration: 45.457s, episode steps: 944, steps per second:  21, episode reward: 26.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.007414, mae: 0.295721, mean_q: 0.369392, mean_eps: 0.853593\n",
      " 163902/250000: episode: 230, duration: 35.194s, episode steps: 756, steps per second:  21, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.008395, mae: 0.300113, mean_q: 0.375537, mean_eps: 0.852828\n",
      " 164439/250000: episode: 231, duration: 24.882s, episode steps: 537, steps per second:  22, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.006950, mae: 0.298983, mean_q: 0.372656, mean_eps: 0.852247\n",
      " 165000/250000: episode: 232, duration: 28.301s, episode steps: 561, steps per second:  20, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.007181, mae: 0.300920, mean_q: 0.373062, mean_eps: 0.851754\n",
      " 165904/250000: episode: 233, duration: 42.617s, episode steps: 904, steps per second:  21, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.007029, mae: 0.301948, mean_q: 0.374099, mean_eps: 0.851095\n",
      " 166803/250000: episode: 234, duration: 44.899s, episode steps: 899, steps per second:  20, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.007134, mae: 0.295474, mean_q: 0.365885, mean_eps: 0.850283\n",
      " 167190/250000: episode: 235, duration: 20.675s, episode steps: 387, steps per second:  19, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.007624, mae: 0.296026, mean_q: 0.368294, mean_eps: 0.849704\n",
      " 168182/250000: episode: 236, duration: 47.025s, episode steps: 992, steps per second:  21, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007459, mae: 0.296611, mean_q: 0.368965, mean_eps: 0.849083\n",
      " 168732/250000: episode: 237, duration: 25.682s, episode steps: 550, steps per second:  21, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.007669, mae: 0.301055, mean_q: 0.374638, mean_eps: 0.848390\n",
      " 169415/250000: episode: 238, duration: 30.995s, episode steps: 683, steps per second:  22, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007961, mae: 0.298505, mean_q: 0.372669, mean_eps: 0.847835\n",
      " 170085/250000: episode: 239, duration: 33.046s, episode steps: 670, steps per second:  20, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006769, mae: 0.304876, mean_q: 0.379712, mean_eps: 0.847225\n",
      " 170900/250000: episode: 240, duration: 37.605s, episode steps: 815, steps per second:  22, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.007991, mae: 0.316665, mean_q: 0.395028, mean_eps: 0.846557\n",
      " 171414/250000: episode: 241, duration: 25.623s, episode steps: 514, steps per second:  20, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.007255, mae: 0.315549, mean_q: 0.390964, mean_eps: 0.845960\n",
      " 172293/250000: episode: 242, duration: 42.431s, episode steps: 879, steps per second:  21, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.007348, mae: 0.324862, mean_q: 0.403056, mean_eps: 0.845331\n",
      " 172803/250000: episode: 243, duration: 23.918s, episode steps: 510, steps per second:  21, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.007284, mae: 0.320742, mean_q: 0.399735, mean_eps: 0.844707\n",
      " 173510/250000: episode: 244, duration: 34.513s, episode steps: 707, steps per second:  20, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.007426, mae: 0.321683, mean_q: 0.400108, mean_eps: 0.844160\n",
      " 174477/250000: episode: 245, duration: 48.696s, episode steps: 967, steps per second:  20, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.008335, mae: 0.323989, mean_q: 0.402671, mean_eps: 0.843405\n",
      " 174947/250000: episode: 246, duration: 21.854s, episode steps: 470, steps per second:  22, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.007469, mae: 0.327730, mean_q: 0.408431, mean_eps: 0.842759\n",
      " 175794/250000: episode: 247, duration: 40.724s, episode steps: 847, steps per second:  21, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.008130, mae: 0.323876, mean_q: 0.402547, mean_eps: 0.842167\n",
      " 176234/250000: episode: 248, duration: 20.576s, episode steps: 440, steps per second:  21, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.008513, mae: 0.324091, mean_q: 0.403606, mean_eps: 0.841587\n",
      " 176696/250000: episode: 249, duration: 21.870s, episode steps: 462, steps per second:  21, episode reward: 10.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.006324, mae: 0.322612, mean_q: 0.402271, mean_eps: 0.841182\n",
      " 177390/250000: episode: 250, duration: 35.713s, episode steps: 694, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.007140, mae: 0.319793, mean_q: 0.398533, mean_eps: 0.840662\n",
      " 178027/250000: episode: 251, duration: 29.826s, episode steps: 637, steps per second:  21, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007381, mae: 0.325773, mean_q: 0.404470, mean_eps: 0.840063\n",
      " 178686/250000: episode: 252, duration: 32.040s, episode steps: 659, steps per second:  21, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.007529, mae: 0.324306, mean_q: 0.402204, mean_eps: 0.839480\n",
      " 179360/250000: episode: 253, duration: 34.298s, episode steps: 674, steps per second:  20, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007623, mae: 0.321144, mean_q: 0.399807, mean_eps: 0.838880\n",
      " 179983/250000: episode: 254, duration: 32.878s, episode steps: 623, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.006079, mae: 0.328700, mean_q: 0.412043, mean_eps: 0.838297\n",
      " 180781/250000: episode: 255, duration: 37.526s, episode steps: 798, steps per second:  21, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.008466, mae: 0.349450, mean_q: 0.436918, mean_eps: 0.837656\n",
      " 181410/250000: episode: 256, duration: 32.275s, episode steps: 629, steps per second:  19, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.008311, mae: 0.345271, mean_q: 0.429364, mean_eps: 0.837014\n",
      " 181914/250000: episode: 257, duration: 23.904s, episode steps: 504, steps per second:  21, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.006942, mae: 0.342622, mean_q: 0.427077, mean_eps: 0.836504\n",
      " 182557/250000: episode: 258, duration: 32.317s, episode steps: 643, steps per second:  20, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.007997, mae: 0.344597, mean_q: 0.429240, mean_eps: 0.835988\n",
      " 183333/250000: episode: 259, duration: 35.700s, episode steps: 776, steps per second:  22, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.008156, mae: 0.348778, mean_q: 0.433338, mean_eps: 0.835349\n",
      " 184330/250000: episode: 260, duration: 48.986s, episode steps: 997, steps per second:  20, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.007212, mae: 0.343410, mean_q: 0.427603, mean_eps: 0.834551\n",
      " 184977/250000: episode: 261, duration: 30.440s, episode steps: 647, steps per second:  21, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.007860, mae: 0.346622, mean_q: 0.430159, mean_eps: 0.833811\n",
      " 185707/250000: episode: 262, duration: 37.123s, episode steps: 730, steps per second:  20, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.008152, mae: 0.345827, mean_q: 0.429271, mean_eps: 0.833192\n",
      " 186584/250000: episode: 263, duration: 46.498s, episode steps: 877, steps per second:  19, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007034, mae: 0.349535, mean_q: 0.434305, mean_eps: 0.832470\n",
      " 187057/250000: episode: 264, duration: 22.118s, episode steps: 473, steps per second:  21, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.007902, mae: 0.342950, mean_q: 0.425127, mean_eps: 0.831862\n",
      " 187603/250000: episode: 265, duration: 28.102s, episode steps: 546, steps per second:  19, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.007459, mae: 0.346252, mean_q: 0.430932, mean_eps: 0.831403\n",
      " 187996/250000: episode: 266, duration: 19.346s, episode steps: 393, steps per second:  20, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.007551, mae: 0.345496, mean_q: 0.430221, mean_eps: 0.830982\n",
      " 188520/250000: episode: 267, duration: 25.737s, episode steps: 524, steps per second:  20, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.007705, mae: 0.344585, mean_q: 0.428209, mean_eps: 0.830570\n",
      " 189277/250000: episode: 268, duration: 39.843s, episode steps: 757, steps per second:  19, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.008223, mae: 0.338550, mean_q: 0.421326, mean_eps: 0.829992\n",
      " 189840/250000: episode: 269, duration: 28.946s, episode steps: 563, steps per second:  19, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007790, mae: 0.346280, mean_q: 0.428951, mean_eps: 0.829398\n",
      " 190855/250000: episode: 270, duration: 51.946s, episode steps: 1015, steps per second:  20, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.008585, mae: 0.380648, mean_q: 0.472932, mean_eps: 0.828689\n",
      " 191690/250000: episode: 271, duration: 43.958s, episode steps: 835, steps per second:  19, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.008905, mae: 0.390737, mean_q: 0.484863, mean_eps: 0.827855\n",
      " 192367/250000: episode: 272, duration: 34.250s, episode steps: 677, steps per second:  20, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.008293, mae: 0.381540, mean_q: 0.472425, mean_eps: 0.827175\n",
      " 193287/250000: episode: 273, duration: 42.801s, episode steps: 920, steps per second:  21, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.008732, mae: 0.381170, mean_q: 0.471270, mean_eps: 0.826457\n",
      " 194232/250000: episode: 274, duration: 47.697s, episode steps: 945, steps per second:  20, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.008098, mae: 0.381532, mean_q: 0.472801, mean_eps: 0.825618\n",
      " 194789/250000: episode: 275, duration: 28.183s, episode steps: 557, steps per second:  20, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.008674, mae: 0.384381, mean_q: 0.475575, mean_eps: 0.824941\n",
      " 195811/250000: episode: 276, duration: 52.874s, episode steps: 1022, steps per second:  19, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.007778, mae: 0.381875, mean_q: 0.475382, mean_eps: 0.824230\n",
      " 196478/250000: episode: 277, duration: 34.774s, episode steps: 667, steps per second:  19, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007698, mae: 0.377367, mean_q: 0.468243, mean_eps: 0.823470\n",
      " 197116/250000: episode: 278, duration: 29.354s, episode steps: 638, steps per second:  22, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.008942, mae: 0.383278, mean_q: 0.474115, mean_eps: 0.822884\n",
      " 197902/250000: episode: 279, duration: 39.648s, episode steps: 786, steps per second:  20, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.007823, mae: 0.384545, mean_q: 0.476832, mean_eps: 0.822243\n",
      " 198327/250000: episode: 280, duration: 18.729s, episode steps: 425, steps per second:  23, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.008970, mae: 0.390774, mean_q: 0.484136, mean_eps: 0.821697\n",
      " 198831/250000: episode: 281, duration: 24.033s, episode steps: 504, steps per second:  21, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.007158, mae: 0.377872, mean_q: 0.469479, mean_eps: 0.821280\n",
      " 199489/250000: episode: 282, duration: 32.755s, episode steps: 658, steps per second:  20, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.007058, mae: 0.380965, mean_q: 0.473126, mean_eps: 0.820756\n",
      " 200220/250000: episode: 283, duration: 35.115s, episode steps: 731, steps per second:  21, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.007998, mae: 0.389599, mean_q: 0.480917, mean_eps: 0.820131\n",
      " 200830/250000: episode: 284, duration: 28.360s, episode steps: 610, steps per second:  22, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.007976, mae: 0.412855, mean_q: 0.509875, mean_eps: 0.819528\n",
      " 201798/250000: episode: 285, duration: 49.597s, episode steps: 968, steps per second:  20, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.008961, mae: 0.411482, mean_q: 0.509629, mean_eps: 0.818817\n",
      " 202211/250000: episode: 286, duration: 21.343s, episode steps: 413, steps per second:  19, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.007204, mae: 0.403144, mean_q: 0.499888, mean_eps: 0.818196\n",
      " 202895/250000: episode: 287, duration: 34.925s, episode steps: 684, steps per second:  20, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.007895, mae: 0.416707, mean_q: 0.516610, mean_eps: 0.817703\n",
      " 203283/250000: episode: 288, duration: 19.554s, episode steps: 388, steps per second:  20, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007972, mae: 0.415912, mean_q: 0.514544, mean_eps: 0.817221\n",
      " 203791/250000: episode: 289, duration: 26.767s, episode steps: 508, steps per second:  19, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.008269, mae: 0.409735, mean_q: 0.507164, mean_eps: 0.816818\n",
      " 204181/250000: episode: 290, duration: 18.639s, episode steps: 390, steps per second:  21, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.008280, mae: 0.415916, mean_q: 0.514228, mean_eps: 0.816413\n",
      " 205323/250000: episode: 291, duration: 54.337s, episode steps: 1142, steps per second:  21, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.008770, mae: 0.412734, mean_q: 0.510722, mean_eps: 0.815723\n",
      " 206030/250000: episode: 292, duration: 35.180s, episode steps: 707, steps per second:  20, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.009212, mae: 0.412768, mean_q: 0.510247, mean_eps: 0.814892\n",
      " 207391/250000: episode: 293, duration: 72.015s, episode steps: 1361, steps per second:  19, episode reward: 13.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.007977, mae: 0.410114, mean_q: 0.507171, mean_eps: 0.813961\n",
      " 207916/250000: episode: 294, duration: 27.140s, episode steps: 525, steps per second:  19, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.008274, mae: 0.406001, mean_q: 0.504029, mean_eps: 0.813113\n",
      " 208382/250000: episode: 295, duration: 22.549s, episode steps: 466, steps per second:  21, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.008950, mae: 0.413302, mean_q: 0.511108, mean_eps: 0.812667\n",
      " 208963/250000: episode: 296, duration: 29.191s, episode steps: 581, steps per second:  20, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.008705, mae: 0.405201, mean_q: 0.502329, mean_eps: 0.812195\n",
      " 209313/250000: episode: 297, duration: 17.140s, episode steps: 350, steps per second:  20, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.009968, mae: 0.413528, mean_q: 0.511847, mean_eps: 0.811776\n",
      " 209706/250000: episode: 298, duration: 17.779s, episode steps: 393, steps per second:  22, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.007301, mae: 0.408785, mean_q: 0.508265, mean_eps: 0.811441\n",
      " 210374/250000: episode: 299, duration: 34.300s, episode steps: 668, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.008928, mae: 0.432362, mean_q: 0.535899, mean_eps: 0.810964\n",
      " 211275/250000: episode: 300, duration: 41.705s, episode steps: 901, steps per second:  22, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.008428, mae: 0.443389, mean_q: 0.550431, mean_eps: 0.810258\n",
      " 211822/250000: episode: 301, duration: 26.731s, episode steps: 547, steps per second:  20, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007962, mae: 0.446944, mean_q: 0.555451, mean_eps: 0.809607\n",
      " 212262/250000: episode: 302, duration: 20.800s, episode steps: 440, steps per second:  21, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.008898, mae: 0.451665, mean_q: 0.557809, mean_eps: 0.809162\n",
      " 213083/250000: episode: 303, duration: 40.965s, episode steps: 821, steps per second:  20, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.008500, mae: 0.441300, mean_q: 0.545776, mean_eps: 0.808595\n",
      " 213798/250000: episode: 304, duration: 35.161s, episode steps: 715, steps per second:  20, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.009280, mae: 0.455520, mean_q: 0.561917, mean_eps: 0.807904\n",
      " 214367/250000: episode: 305, duration: 28.287s, episode steps: 569, steps per second:  20, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.009062, mae: 0.446823, mean_q: 0.552322, mean_eps: 0.807326\n",
      " 215502/250000: episode: 306, duration: 58.150s, episode steps: 1135, steps per second:  20, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.008941, mae: 0.446442, mean_q: 0.551705, mean_eps: 0.806559\n",
      " 215906/250000: episode: 307, duration: 20.386s, episode steps: 404, steps per second:  20, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.008114, mae: 0.457989, mean_q: 0.567230, mean_eps: 0.805866\n",
      " 216293/250000: episode: 308, duration: 19.214s, episode steps: 387, steps per second:  20, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.007990, mae: 0.440402, mean_q: 0.544552, mean_eps: 0.805510\n",
      " 216889/250000: episode: 309, duration: 28.596s, episode steps: 596, steps per second:  21, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.008156, mae: 0.448251, mean_q: 0.554241, mean_eps: 0.805067\n",
      " 217500/250000: episode: 310, duration: 32.520s, episode steps: 611, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.008072, mae: 0.447901, mean_q: 0.553223, mean_eps: 0.804525\n",
      " 218274/250000: episode: 311, duration: 38.858s, episode steps: 774, steps per second:  20, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.009143, mae: 0.451056, mean_q: 0.558348, mean_eps: 0.803903\n",
      " 219642/250000: episode: 312, duration: 70.042s, episode steps: 1368, steps per second:  20, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.008247, mae: 0.446731, mean_q: 0.553463, mean_eps: 0.802938\n",
      " 220293/250000: episode: 313, duration: 34.719s, episode steps: 651, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.008753, mae: 0.449836, mean_q: 0.555477, mean_eps: 0.802029\n",
      " 221280/250000: episode: 314, duration: 52.626s, episode steps: 987, steps per second:  19, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.009338, mae: 0.471574, mean_q: 0.584431, mean_eps: 0.801293\n",
      " 221729/250000: episode: 315, duration: 22.990s, episode steps: 449, steps per second:  20, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.009133, mae: 0.470211, mean_q: 0.584984, mean_eps: 0.800646\n",
      " 222414/250000: episode: 316, duration: 40.083s, episode steps: 685, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.008044, mae: 0.454419, mean_q: 0.562622, mean_eps: 0.800135\n",
      " 223284/250000: episode: 317, duration: 45.852s, episode steps: 870, steps per second:  19, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.008185, mae: 0.460331, mean_q: 0.569760, mean_eps: 0.799437\n",
      " 223856/250000: episode: 318, duration: 31.279s, episode steps: 572, steps per second:  18, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.008751, mae: 0.466565, mean_q: 0.578718, mean_eps: 0.798789\n",
      " 224493/250000: episode: 319, duration: 33.583s, episode steps: 637, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.009129, mae: 0.471745, mean_q: 0.583365, mean_eps: 0.798243\n",
      " 225060/250000: episode: 320, duration: 30.382s, episode steps: 567, steps per second:  19, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.008016, mae: 0.459309, mean_q: 0.567895, mean_eps: 0.797702\n",
      " 225686/250000: episode: 321, duration: 32.714s, episode steps: 626, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.008513, mae: 0.468797, mean_q: 0.579755, mean_eps: 0.797165\n",
      " 226271/250000: episode: 322, duration: 31.064s, episode steps: 585, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.009304, mae: 0.467370, mean_q: 0.581860, mean_eps: 0.796620\n",
      " 226768/250000: episode: 323, duration: 25.738s, episode steps: 497, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.009239, mae: 0.470833, mean_q: 0.582419, mean_eps: 0.796134\n",
      " 227409/250000: episode: 324, duration: 34.338s, episode steps: 641, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.008193, mae: 0.455267, mean_q: 0.561530, mean_eps: 0.795621\n",
      " 228044/250000: episode: 325, duration: 32.118s, episode steps: 635, steps per second:  20, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.008781, mae: 0.465289, mean_q: 0.574903, mean_eps: 0.795047\n",
      " 228920/250000: episode: 326, duration: 43.651s, episode steps: 876, steps per second:  20, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.009083, mae: 0.473999, mean_q: 0.586445, mean_eps: 0.794368\n",
      " 229846/250000: episode: 327, duration: 48.374s, episode steps: 926, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007945, mae: 0.466700, mean_q: 0.577491, mean_eps: 0.793556\n",
      " 230490/250000: episode: 328, duration: 33.971s, episode steps: 644, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.007953, mae: 0.470026, mean_q: 0.583556, mean_eps: 0.792849\n",
      " 231120/250000: episode: 329, duration: 30.614s, episode steps: 630, steps per second:  21, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.008580, mae: 0.485191, mean_q: 0.599937, mean_eps: 0.792276\n",
      " 231909/250000: episode: 330, duration: 40.451s, episode steps: 789, steps per second:  20, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.009330, mae: 0.482154, mean_q: 0.598046, mean_eps: 0.791637\n",
      " 232658/250000: episode: 331, duration: 35.923s, episode steps: 749, steps per second:  21, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.008900, mae: 0.484330, mean_q: 0.601600, mean_eps: 0.790944\n",
      " 233585/250000: episode: 332, duration: 48.569s, episode steps: 927, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.009432, mae: 0.484925, mean_q: 0.599136, mean_eps: 0.790190\n",
      " 234197/250000: episode: 333, duration: 32.753s, episode steps: 612, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.008955, mae: 0.479770, mean_q: 0.591564, mean_eps: 0.789497\n",
      " 234920/250000: episode: 334, duration: 36.521s, episode steps: 723, steps per second:  20, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.009104, mae: 0.483373, mean_q: 0.594659, mean_eps: 0.788898\n",
      " 235575/250000: episode: 335, duration: 34.704s, episode steps: 655, steps per second:  19, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.007661, mae: 0.477847, mean_q: 0.590679, mean_eps: 0.788279\n",
      " 236202/250000: episode: 336, duration: 31.755s, episode steps: 627, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.008283, mae: 0.481876, mean_q: 0.596009, mean_eps: 0.787701\n",
      " 236757/250000: episode: 337, duration: 31.433s, episode steps: 555, steps per second:  18, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008704, mae: 0.481491, mean_q: 0.596985, mean_eps: 0.787168\n",
      " 237576/250000: episode: 338, duration: 42.661s, episode steps: 819, steps per second:  19, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.009227, mae: 0.489996, mean_q: 0.605264, mean_eps: 0.786551\n",
      " 237939/250000: episode: 339, duration: 17.011s, episode steps: 363, steps per second:  21, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.005968, mae: 0.467802, mean_q: 0.578404, mean_eps: 0.786020\n",
      " 238823/250000: episode: 340, duration: 56.294s, episode steps: 884, steps per second:  16, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.008203, mae: 0.480621, mean_q: 0.593719, mean_eps: 0.785458\n",
      " 239422/250000: episode: 341, duration: 44.809s, episode steps: 599, steps per second:  13, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.006766, mae: 0.476200, mean_q: 0.588549, mean_eps: 0.784790\n",
      " 240274/250000: episode: 342, duration: 57.658s, episode steps: 852, steps per second:  15, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.009168, mae: 0.485901, mean_q: 0.600192, mean_eps: 0.784137\n",
      " 240847/250000: episode: 343, duration: 42.369s, episode steps: 573, steps per second:  14, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.009130, mae: 0.520227, mean_q: 0.643197, mean_eps: 0.783496\n",
      " 241519/250000: episode: 344, duration: 50.943s, episode steps: 672, steps per second:  13, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007935, mae: 0.508092, mean_q: 0.627644, mean_eps: 0.782936\n",
      " 242180/250000: episode: 345, duration: 48.053s, episode steps: 661, steps per second:  14, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.008190, mae: 0.519066, mean_q: 0.640332, mean_eps: 0.782337\n",
      " 242677/250000: episode: 346, duration: 34.789s, episode steps: 497, steps per second:  14, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.008452, mae: 0.515575, mean_q: 0.635971, mean_eps: 0.781815\n",
      " 243367/250000: episode: 347, duration: 49.447s, episode steps: 690, steps per second:  14, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.007962, mae: 0.512910, mean_q: 0.633984, mean_eps: 0.781280\n",
      " 243742/250000: episode: 348, duration: 25.724s, episode steps: 375, steps per second:  15, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.007511, mae: 0.509668, mean_q: 0.630425, mean_eps: 0.780801\n",
      " 244075/250000: episode: 349, duration: 22.415s, episode steps: 333, steps per second:  15, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.008299, mae: 0.508330, mean_q: 0.626932, mean_eps: 0.780483\n",
      " 244447/250000: episode: 350, duration: 27.423s, episode steps: 372, steps per second:  14, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.007150, mae: 0.510807, mean_q: 0.630466, mean_eps: 0.780166\n",
      " 245090/250000: episode: 351, duration: 47.383s, episode steps: 643, steps per second:  14, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.009727, mae: 0.524909, mean_q: 0.647601, mean_eps: 0.779709\n",
      " 245772/250000: episode: 352, duration: 51.648s, episode steps: 682, steps per second:  13, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.008791, mae: 0.524397, mean_q: 0.646479, mean_eps: 0.779113\n",
      " 246291/250000: episode: 353, duration: 37.429s, episode steps: 519, steps per second:  14, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.008259, mae: 0.516925, mean_q: 0.636916, mean_eps: 0.778573\n",
      " 246899/250000: episode: 354, duration: 44.267s, episode steps: 608, steps per second:  14, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.008353, mae: 0.514014, mean_q: 0.632206, mean_eps: 0.778065\n",
      " 247553/250000: episode: 355, duration: 48.303s, episode steps: 654, steps per second:  14, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: 0.009034, mae: 0.512530, mean_q: 0.632538, mean_eps: 0.777497\n",
      " 248091/250000: episode: 356, duration: 36.162s, episode steps: 538, steps per second:  15, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.009398, mae: 0.515894, mean_q: 0.638611, mean_eps: 0.776960\n",
      " 248800/250000: episode: 357, duration: 50.687s, episode steps: 709, steps per second:  14, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.008821, mae: 0.513276, mean_q: 0.632910, mean_eps: 0.776400\n",
      " 249328/250000: episode: 358, duration: 39.257s, episode steps: 528, steps per second:  13, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.008591, mae: 0.520924, mean_q: 0.641650, mean_eps: 0.775844\n",
      " 249721/250000: episode: 359, duration: 27.711s, episode steps: 393, steps per second:  14, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.008582, mae: 0.512562, mean_q: 0.632296, mean_eps: 0.775428\n",
      "done, took 10308.873 seconds\n",
      "Testing for 10 episodes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AtariEnv.render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m dqn\u001b[38;5;241m.\u001b[39mfit(env, nb_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250000\u001b[39m, visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Evaluación\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m test_history \u001b[38;5;241m=\u001b[39m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Analizar resultados\u001b[39;00m\n\u001b[0;32m     96\u001b[0m episode_rewards \u001b[38;5;241m=\u001b[39m test_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_reward\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\rl\\core.py:352\u001b[0m, in \u001b[0;36mAgent.test\u001b[1;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m     observation, r, d, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mprocess_step(observation, r, d, info)\n\u001b[1;32m--> 352\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_action_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\rl\\callbacks.py:98\u001b[0m, in \u001b[0;36mCallbackList.on_action_end\u001b[1;34m(self, action, logs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(callback, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_action_end\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m---> 98\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_action_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\rl\\callbacks.py:360\u001b[0m, in \u001b[0;36mVisualizer.on_action_end\u001b[1;34m(self, action, logs)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_action_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, action, logs):\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Render environment at the end of each action \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\gym\\core.py:329\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    327\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[0;32m    328\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:51\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m     )\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\gym\\wrappers\\env_checker.py:53\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\Anaconda3\\envs\\miar_rl\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:316\u001b[0m, in \u001b[0;36menv_render_passive_checker\u001b[1;34m(env, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01min\u001b[39;00m render_modes, (\n\u001b[0;32m    312\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment was initialized successfully however with an unsupported render mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    313\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, modes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_modes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m         )\n\u001b[1;32m--> 316\u001b[0m result \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# TODO: Check that the result is correct\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mTypeError\u001b[0m: AtariEnv.render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Permute\n",
    "from keras.optimizers import Adam\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "import gym\n",
    "\n",
    "class GymCompatibilityWrapper(gym.Wrapper):\n",
    "    def step(self, action):\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        done = terminated or truncated\n",
    "        return observation, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "\n",
    "# Parámetros\n",
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "ENV_NAME = 'SpaceInvaders-v0'\n",
    "\n",
    "# Procesador personalizado\n",
    "class AtariProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        # Si es tupla, extrae el primer elemento (obs, info)\n",
    "        if isinstance(observation, tuple):\n",
    "            observation = observation[0]\n",
    "        assert observation.ndim == 3  # (H, W, C)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize(INPUT_SHAPE).convert('L')\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == INPUT_SHAPE\n",
    "        return processed_observation.astype('uint8')\n",
    "    \n",
    "    def process_state_batch(self, batch):\n",
    "        return batch.astype('float32') / 255.\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)\n",
    "\n",
    "# Creacion de entorno\n",
    "env = gym.make(ENV_NAME, render_mode='rgb_array')\n",
    "env = GymCompatibilityWrapper(env)\n",
    "env.render = lambda mode=None: env.unwrapped.render()  \n",
    "np.random.seed(123)\n",
    "env.reset(seed=123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Memoria\n",
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
    "\n",
    "# Política epsilon-greedy\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
    "                              value_max=1.0, value_min=0.1,\n",
    "                              value_test=0.05, nb_steps=1000000)\n",
    "\n",
    "# Modelo de red CNN (DeepMind style)\n",
    "def build_model(window_length, input_shape, nb_actions):\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 3, 1), input_shape=(window_length,) + input_shape))\n",
    "    model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu'))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(nb_actions, activation='linear'))\n",
    "    return model\n",
    "\n",
    "model = build_model(WINDOW_LENGTH, INPUT_SHAPE, nb_actions)\n",
    "\n",
    "# Agente DQN\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions,\n",
    "               policy=policy, memory=memory,\n",
    "               processor=AtariProcessor(),\n",
    "               nb_steps_warmup=50000,\n",
    "               gamma=0.99, target_model_update=10000,\n",
    "               train_interval=4, delta_clip=1.0)\n",
    "\n",
    "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n",
    "\n",
    "# Entrenamiento (puedes cambiar nb_steps según tus recursos)\n",
    "dqn.fit(env, nb_steps=250000, visualize=False, verbose=2)\n",
    "\n",
    "# Evaluación\n",
    "test_history = dqn.test(env, nb_episodes=10, visualize=True)\n",
    "\n",
    "# Analizar resultados\n",
    "episode_rewards = test_history.history['episode_reward']\n",
    "print(\"\\n🎯 RESULTADOS DE PRUEBA\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"🏁 Episodios probados: {len(episode_rewards)}\")\n",
    "print(f\"💯 Recompensas por episodio: {episode_rewards}\")\n",
    "print(f\"📈 Recompensa media: {np.mean(episode_rewards):.2f}\")\n",
    "print(f\"📉 Recompensa mínima: {np.min(episode_rewards)}\")\n",
    "print(f\"🏆 Recompensa máxima: {np.max(episode_rewards)}\")\n",
    "print(f\"📊 Desviación estándar: {np.std(episode_rewards):.2f}\")\n",
    "print(\"=\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704e702",
   "metadata": {},
   "source": [
    "#### Nota: El modelo se entrenó correctamente pero hubo un error en el testeo, el cual ya fue corregido con \"env.render = lambda mode=None: env.unwrapped.render()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights(f'dqn_{ENV_NAME}2_weights.h5f', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9600e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('dqn_SpaceInvaders-v02_weights.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14d34b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 21.000, steps: 1115\n",
      "Episode 2: reward: 9.000, steps: 784\n",
      "Episode 3: reward: 15.000, steps: 821\n",
      "Episode 4: reward: 10.000, steps: 781\n",
      "Episode 5: reward: 14.000, steps: 836\n",
      "Episode 6: reward: 13.000, steps: 918\n",
      "Episode 7: reward: 21.000, steps: 1006\n",
      "Episode 8: reward: 5.000, steps: 532\n",
      "Episode 9: reward: 16.000, steps: 922\n",
      "Episode 10: reward: 13.000, steps: 677\n",
      "\n",
      "🎯 RESULTADOS DE PRUEBA\n",
      "==============================\n",
      "🏁 Episodios probados: 10\n",
      "💯 Recompensas por episodio: [21.0, 9.0, 15.0, 10.0, 14.0, 13.0, 21.0, 5.0, 16.0, 13.0]\n",
      "📈 Recompensa media: 13.70\n",
      "📉 Recompensa mínima: 5.0\n",
      "🏆 Recompensa máxima: 21.0\n",
      "📊 Desviación estándar: 4.75\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "test_history = dqn.test(env, nb_episodes=10, visualize=True)  # Ahora debería funcionar\n",
    "\n",
    "# Analizar resultados\n",
    "episode_rewards = test_history.history['episode_reward']\n",
    "print(\"\\n🎯 RESULTADOS DE PRUEBA\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"🏁 Episodios probados: {len(episode_rewards)}\")\n",
    "print(f\"💯 Recompensas por episodio: {episode_rewards}\")\n",
    "print(f\"📈 Recompensa media: {np.mean(episode_rewards):.2f}\")\n",
    "print(f\"📉 Recompensa mínima: {np.min(episode_rewards)}\")\n",
    "print(f\"🏆 Recompensa máxima: {np.max(episode_rewards)}\")\n",
    "print(f\"📊 Desviación estándar: {np.std(episode_rewards):.2f}\")\n",
    "print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "605e0691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 100 episodes ...\n",
      "Episode 1: reward: 7.000, steps: 385\n",
      "Episode 2: reward: 8.000, steps: 459\n",
      "Episode 3: reward: 5.000, steps: 597\n",
      "Episode 4: reward: 4.000, steps: 633\n",
      "Episode 5: reward: 25.000, steps: 1545\n",
      "Episode 6: reward: 20.000, steps: 1114\n",
      "Episode 7: reward: 6.000, steps: 539\n",
      "Episode 8: reward: 9.000, steps: 500\n",
      "Episode 9: reward: 14.000, steps: 874\n",
      "Episode 10: reward: 14.000, steps: 600\n",
      "Episode 11: reward: 8.000, steps: 593\n",
      "Episode 12: reward: 13.000, steps: 721\n",
      "Episode 13: reward: 24.000, steps: 1450\n",
      "Episode 14: reward: 11.000, steps: 770\n",
      "Episode 15: reward: 11.000, steps: 537\n",
      "Episode 16: reward: 17.000, steps: 940\n",
      "Episode 17: reward: 10.000, steps: 593\n",
      "Episode 18: reward: 8.000, steps: 613\n",
      "Episode 19: reward: 5.000, steps: 558\n",
      "Episode 20: reward: 11.000, steps: 877\n",
      "Episode 21: reward: 13.000, steps: 676\n",
      "Episode 22: reward: 8.000, steps: 637\n",
      "Episode 23: reward: 18.000, steps: 1043\n",
      "Episode 24: reward: 17.000, steps: 889\n",
      "Episode 25: reward: 3.000, steps: 613\n",
      "Episode 26: reward: 15.000, steps: 1074\n",
      "Episode 27: reward: 10.000, steps: 463\n",
      "Episode 28: reward: 13.000, steps: 676\n",
      "Episode 29: reward: 16.000, steps: 952\n",
      "Episode 30: reward: 14.000, steps: 895\n",
      "Episode 31: reward: 7.000, steps: 653\n",
      "Episode 32: reward: 5.000, steps: 516\n",
      "Episode 33: reward: 18.000, steps: 1024\n",
      "Episode 34: reward: 8.000, steps: 621\n",
      "Episode 35: reward: 13.000, steps: 528\n",
      "Episode 36: reward: 5.000, steps: 513\n",
      "Episode 37: reward: 8.000, steps: 693\n",
      "Episode 38: reward: 8.000, steps: 753\n",
      "Episode 39: reward: 4.000, steps: 566\n",
      "Episode 40: reward: 24.000, steps: 1167\n",
      "Episode 41: reward: 8.000, steps: 518\n",
      "Episode 42: reward: 12.000, steps: 661\n",
      "Episode 43: reward: 22.000, steps: 1076\n",
      "Episode 44: reward: 11.000, steps: 683\n",
      "Episode 45: reward: 5.000, steps: 504\n",
      "Episode 46: reward: 16.000, steps: 692\n",
      "Episode 47: reward: 5.000, steps: 411\n",
      "Episode 48: reward: 1.000, steps: 617\n",
      "Episode 49: reward: 6.000, steps: 557\n",
      "Episode 50: reward: 17.000, steps: 791\n",
      "Episode 51: reward: 13.000, steps: 663\n",
      "Episode 52: reward: 15.000, steps: 1095\n",
      "Episode 53: reward: 12.000, steps: 710\n",
      "Episode 54: reward: 12.000, steps: 777\n",
      "Episode 55: reward: 10.000, steps: 588\n",
      "Episode 56: reward: 15.000, steps: 1105\n",
      "Episode 57: reward: 19.000, steps: 772\n",
      "Episode 58: reward: 11.000, steps: 894\n",
      "Episode 59: reward: 3.000, steps: 539\n",
      "Episode 60: reward: 5.000, steps: 485\n",
      "Episode 61: reward: 8.000, steps: 559\n",
      "Episode 62: reward: 10.000, steps: 959\n",
      "Episode 63: reward: 22.000, steps: 1153\n",
      "Episode 64: reward: 2.000, steps: 445\n",
      "Episode 65: reward: 7.000, steps: 657\n",
      "Episode 66: reward: 14.000, steps: 803\n",
      "Episode 67: reward: 15.000, steps: 650\n",
      "Episode 68: reward: 8.000, steps: 813\n",
      "Episode 69: reward: 14.000, steps: 956\n",
      "Episode 70: reward: 19.000, steps: 1053\n",
      "Episode 71: reward: 15.000, steps: 790\n",
      "Episode 72: reward: 17.000, steps: 931\n",
      "Episode 73: reward: 12.000, steps: 701\n",
      "Episode 74: reward: 16.000, steps: 1059\n",
      "Episode 75: reward: 6.000, steps: 531\n",
      "Episode 76: reward: 16.000, steps: 1297\n",
      "Episode 77: reward: 18.000, steps: 1200\n",
      "Episode 78: reward: 6.000, steps: 389\n",
      "Episode 79: reward: 5.000, steps: 512\n",
      "Episode 80: reward: 21.000, steps: 1002\n",
      "Episode 81: reward: 20.000, steps: 895\n",
      "Episode 82: reward: 3.000, steps: 332\n",
      "Episode 83: reward: 13.000, steps: 650\n",
      "Episode 84: reward: 12.000, steps: 635\n",
      "Episode 85: reward: 8.000, steps: 592\n",
      "Episode 86: reward: 6.000, steps: 566\n",
      "Episode 87: reward: 6.000, steps: 395\n",
      "Episode 88: reward: 14.000, steps: 693\n",
      "Episode 89: reward: 19.000, steps: 885\n",
      "Episode 90: reward: 11.000, steps: 729\n",
      "Episode 91: reward: 21.000, steps: 1125\n",
      "Episode 92: reward: 7.000, steps: 656\n",
      "Episode 93: reward: 7.000, steps: 622\n",
      "Episode 94: reward: 11.000, steps: 842\n",
      "Episode 95: reward: 15.000, steps: 927\n",
      "Episode 96: reward: 19.000, steps: 1330\n",
      "Episode 97: reward: 19.000, steps: 1356\n",
      "Episode 98: reward: 7.000, steps: 696\n",
      "Episode 99: reward: 19.000, steps: 1038\n",
      "Episode 100: reward: 5.000, steps: 483\n"
     ]
    }
   ],
   "source": [
    "# test evaluacion de modelo \n",
    "\n",
    "test_history = dqn.test(env, nb_episodes=100, visualize=True) \n",
    "episode_rewards = test_history.history['episode_reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82ce4cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(episode_rewards, 'b-o', label='Recompensa por episodio')\n",
    "plt.axhline(y=np.mean(episode_rewards), \n",
    "            color='r', \n",
    "            linestyle='--', \n",
    "            label=f'Media: {np.mean(episode_rewards):.1f}')  # ¡Corregido!\n",
    "plt.xlabel(\"Episodio\")\n",
    "plt.ylabel(\"Recompensa\")\n",
    "plt.title(\"Desempeño del DQN en SpaceInvaders\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdc718",
   "metadata": {},
   "source": [
    "Se observa la recompensa obtenida en cada episodio (línea azul) junto con su media (línea roja discontinua en 11.7). La variabilidad en las recompensas y la media cercana al valor mínimo (10) indican que el agente aún no domina el juego, ya que en SpaceInvaders las recompensas suelen ser significativamente más altas cuando la estrategia es efectiva. Los metadatos adicionales, como \"Día 0\" y \"Fecha 15\", sugieren que podría tratarse de una fase inicial de entrenamiento o de una ejecución específica, pero el bajo rendimiento promedio señala la necesidad de ajustar parámetros o ampliar el entrenamiento para mejorar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40a756c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datos (usamos tus 100 valores en episode_rewards)\n",
    "rewards = np.array(episode_rewards)\n",
    "target = 20  # Línea de objetivo (ajústala si es diferente)\n",
    "mean_val = np.mean(rewards)\n",
    "\n",
    "# --- Crear histograma ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histograma principal\n",
    "n, bins, patches = plt.hist(rewards, \n",
    "                           bins=12, \n",
    "                           color='skyblue', \n",
    "                           edgecolor='white', \n",
    "                           alpha=0.8,\n",
    "                           label='Distribución')\n",
    "\n",
    "# Líneas de referencia\n",
    "plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Media ({mean_val:.1f})')\n",
    "plt.axvline(target, color='green', linestyle=':', linewidth=2, \n",
    "            label=f'Objetivo ({target})')\n",
    "\n",
    "# Ajustes estéticos\n",
    "plt.xlabel('Recompensa', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.title('Distribución de Recompensas (100 episodios)', fontsize=14, pad=20)\n",
    "\n",
    "# Leyenda y grid\n",
    "plt.legend(loc='upper right', frameon=True)\n",
    "plt.grid(axis='y', alpha=0.4)\n",
    "\n",
    "# Eje X desde 0 hasta el máximo + margen\n",
    "plt.xlim(0, max(rewards)*1.1)\n",
    "\n",
    "# Mostrar valores enteros en eje X si las recompensas son enteras\n",
    "if all(isinstance(x, int) for x in rewards):\n",
    "    plt.xticks(np.arange(0, max(rewards)+5, 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00233a",
   "metadata": {},
   "source": [
    "Se muestra con qué frecuencia el agente alcanzó ciertos rangos de recompensa, destacando la media real y el objetivo deseado. La concentración de recompensas por debajo del objetivo indica que el agente aún no logra un rendimiento óptimo, ya que la mayoría de episodios generaron recompensas inferiores a la meta establecida. Esto sugiere que se deberían cambiar los hiperparámetros o aumentar el tiempo de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miar_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
